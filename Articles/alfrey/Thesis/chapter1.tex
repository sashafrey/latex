\chapter[Теория статистического обучения]{Теория статистического обучения}
\label{chap:1}

В данной главе приводится обзор общепринятого подхода к~оценке обобщающей способности,
который основан на~классическом определении вероятности~\cite{boucheron05theory,bousquet2004introduction}.
Настоящий обзор не~претендует на~полноту изложения.
Основное внимание будет уделено
оценкам, использующим понятие VC"=размерности,
локальным оценкам избыточного риска
и~PAC-Bayes оценкам переобучения,
применимым к~линейным решающим правилам.

\section{Основные определения SLT}

%В данном разделе мы будем придерживаться следующих обозначений.
В данном разделе мы будем придерживаться обозначений, введенных в~\cite{koltchinskii11oracle}.
Пусть $(\Omega, \Sigma, \cP)$ "--- вероятностное пространство,
а~$X, X_1, \dots, X_n$ "--- одинаково распределенные случайные величины,
принимающие значения в~измеримом пространстве $(S, \cA)$
с~общим распределением $P$.
Через $P_n$ обозначим эмпирическое распределение, построенное по~$n$ наблюдениям:
\[
    P_n = \frac 1n \sum_{j=1}^n \delta_{X_j},
\]
где $\delta_x$, $x \in S$ "--- дельта-функция Дирака.
Пусть $\mathscr{F} = \{ f \colon S \rightarrow [0, 1]\}$ "--- класс измеримых функций.
В дальнейшем мы будем интерпретировать значения функций $f \in \cF$ как <<потери>>,
а~математическое ожидание $f(X)$,
\[
    \Expect f(X) =  \int_S f d P = P f,
\]
как риск, связанный с~определенным <<решающим правилом>>.

\begin{Example}
Рассмотрим задачу классификации.
Пусть $\XX$ "--- множество объектов, а~$\YY$ "--- множество вещественных (или целочисленных) ответов.
Положим $S = \XX \times \YY$.
Для произвольного алгоритма классификации $g \colon \XX \rightarrow \YY$
и~прецедента $(x, y) \in S$ определим величину потерь как $f(x, y) = (g(x) - y)^2$.
После нормировки эти потери можно рассматривать как функцию $f \colon S \rightarrow [0, 1]$.
Тогда класс функций потерь $\mathscr{F}$ получится, если перебрать все классификаторы $g$ из~определенного семейства
(например, из семейства всех линейных классификаторов в~исходном признаковом пространстве задачи).
В дальнейшем для краткости обозначений нам будет удобнее забыть об этой структуре множеств $S$ и~$\mathscr{F}$.
\end{Example}

Нас будет интересовать \emph{задача минимизации риска}
\begin{equation}
    \label{trueRiskMinimizationProblem}
    P f \rightarrow \min, f \in \cF,
\end{equation}
в~условиях неизвестного распределения $P$.
Поэтому вместе с~задачей~\eqref{trueRiskMinimizationProblem} будет также рассматриваться \emph{задача минимизации эмпирического риска}
\begin{equation}
    \label{empiricalRiskMinimizationProblem}
    \frac 1n \sum_{j=1}^nf(X_j) = \int_S f d P_n = P_n f \rightarrow \min, f \in \cF.
\end{equation}
\begin{Def}
Избыточным риском функции $f \in \cF$ назовем величину
\[
    \cE (f) = P f - \inf_{g \in \cF} P g.
\]
\end{Def}
Обозначим через $\hat f = \hat f_n \in \Argmin_{f \in \cF} P_n f$
решение задачи минимизации эмпирического риска~\eqref{empiricalRiskMinimizationProblem}.
Функция $\hat f_n$ используется как приближенное решение задачи минимизации истинного риска~\eqref{trueRiskMinimizationProblem},
а~значит, избыточный риск $\cE (\hat f_n)$ является естественной мерой ошибки приближенного решения.
Кроме избыточного риска полезно рассматривать уклонение $P f - P_n f$,
показывающее, как точно эмпирический риск приближает истинный риск.

Семейство случайных величин $\{(P - P_n)f\}_{f \in \cF}$ называют \emph{эмпирическим процессом, индексированным классом $\cF$}.
Нормой эмпирического процесса называют величину $|| P - P_n ||_\cF \equiv \sup\limits_{f \in \cF} |(P - P_n) f|$.
%Отметим, что данная величина хорошо изучена в~теории эмпирических процессов.

В дальнейшем нас будут интересовать оценки следующего вида:
\begin{equation}
\label{boundDefinition}
\begin{aligned}
    &\Prob^n \big\{ \cE (\hat f_n) \geq \eps \big\} \leq B_1(\eps, n, \cF), \\
    &\Prob^n \big\{ P \hat f_n - P_n \hat f_n \geq \eps \big\} \leq B_2(\eps, n, \cF),
\end{aligned}
\end{equation}
а~также доверительные интервалы при заданном уровне надежности $\eta$:
\begin{equation}
\label{invBoundDefinition}
\begin{aligned}
    &\Prob^n \big\{ \cE (\hat f_n) \geq \eps_1(\eta, n , \cF) \big\} \leq \eta, \\
    &\Prob^n \big\{ P \hat f_n - P_n \hat f_n \geq \eps_2(\eta, n , \cF) \big\} \leq \eta.
\end{aligned}
\end{equation}
Во всех оценках~\eqref{boundDefinition} и~\eqref{invBoundDefinition} вероятность $\Prob^n \equiv P^{\otimes n}$ соответствует
реализациям выборки $(X_1, \dots, X_n) \subset S$.

\section{Неравенства концентрации меры}
Неравенства концентрации меры~\cite{boucheron02concentration,bousquet02concentration,lugosi98concentrationmeasure}
играют большую роль при выводе оценок вида~\eqref{boundDefinition} и~\eqref{invBoundDefinition}.
В данном параграфе мы рассмотрим простейший случай (класс $\cF$, состоящий лишь из~одной функции $f$)
и~покажем, как в~этой ситуации применить неравенство Хевдинга.
Случай $|\cF| = 1$ означает, что всякое обучение отсутствует,
а~различия между истинным риском $P f$ и~эмпирическим риском $P_n f$
возникают лишь из-за нашей вероятностной модели данных.

Заметим, что $P f - P_n f = \Expect f(X) - \frac 1n \sum\limits_{j=1}^n f(X_j)$.
Следовательно, по~закону больших чисел эмпирический риск хорошо аппроксимирует истинный риск при больших значениях $n$:
\[
    \Prob^n \Big\{ \lim_{n \rightarrow \infty} \frac 1n \sum_{j=1}^n f(X_j) - \Expect f(X) = 0\Big\} = 1.
\]
Неравенство Хевдинга дает количественную оценку на~скорость этой сходимости.

\begin{Theorem}[Хевдинг]
\label{th:hoeffding-ineq}
Пусть $X_1, \dots, X_n$ "--- независимые одинаково распределенные случайные величины, принимающие значения на~отрезке $[a, b]$.
Тогда для всех $\eps > 0$ выполнено
\begin{equation}
    \label{eq:hoeffding-ineq}
    \Prob^n \Big\{ \Expect f(X) - \frac 1n \sum_{j=1}^n f(X_j) \geq \epsilon \Big\} \leq
        \exp \Big( - \frac{2 n \epsilon^2 }{(b - a)^2}\Big).
\end{equation}
\end{Theorem}
Обозначим правую часть \eqref{eq:hoeffding-ineq} через $\delta$ и~выразим $\eps$ через $\delta$. Получим, что с~вероятностью не~менее $1 - \delta$
выполнено следующее:
\begin{equation}
    \label{hoefdingInv}
    P f - P_n f \leq (b - a) \sqrt{\frac{\log \frac 1 \delta}{2 n}}.
\end{equation}

Более точную оценку можно получить из~неравенства Бернштейна.
Оно уточняет неравенство Хевдинга благодаря учету дисперсии случайных величин $X_1, \dots, X_n$.
\begin{Theorem}[Бернштейн]
Пусть $X_1, \dots, X_n$ "--- независимые (но не~обязательно одинаково распределенные) случайные величины
с~нулевым математическим ожиданием, принимающие значения на~отрезке $[-c, c]$.
Пусть
\[
    \sigma^2 = \frac 1n \sum_{j=1}^n \Var{X_j}.
\]
Тогда для любого $\epsilon > 0$ выполнено
\[
    \Prob^n \Big\{\frac 1n \sum_{j=1}^n X_j > \epsilon \Big\} \leq \exp\Big(- \frac{n \epsilon^2}{2 \sigma^2 + 2 c \epsilon / 3}\Big).
\]
\end{Theorem}
При использовании неравенства Бернштейна получим следующую оценку, выполненную с~вероятностью не~менее $1 - \delta$:
\begin{equation}
    \label{bernsteinInv}
    P f - P_n f \leq \sqrt{\frac{2 \sigma^2 \log {\frac 1 \delta}}{n}} + \frac{2 \log {\frac 1 \delta}}{3 n},
\end{equation}
где $\sigma^2 = \Var f(X)$.

К сожалению, неравенства~\eqref{hoefdingInv} и~\eqref{bernsteinInv} оказываются верными лишь для фиксированной функции $f$,
и~оказываются неверными, если функция выбирается из~класса $\cF$ по~данным $(X_1, \dots, X_n)$.

\section{Теория Вапника-Червоненкиса}

Чтобы справиться с~ситуацией $|\cF| > 1$, величину $P \hat f_n - P_n \hat f_n$ для функции $\hat f \in \cF$
ограничивают сверху супремумом по~всему классу функций~\cite{vapnik68dan,vapnik71uniform}:
\[
    P \hat f_n - P_n \hat f_n \leq \sup\limits_{f \in \cF} P f - P_n f.
\]
Для конечного класса функций $|\cF| < \infty$ эту величину легко оценить с~помощью неравенства Буля.
Действительно, пусть $\cF = \{f_1, \dots, f_N\}$.
Тогда для каждой функции $f_i$ рассмотрим множество
\[
    C_i =  \{(X_1, \dots, X_n) \in S^n \colon P f_i(X) - P_n f_i(X) > \eps\}
\]
"--- множество тех выборок, для которых $f_i$ оказалась преобученной.
Тогда по~неравенству Буля выполнено
\[
    \Prob^n \{C_1 \cup \dots \cup C_N\} \leq \sum_{i = 1}^N \Prob^n \{C_i\}.
\]
Применяя для каждой $f_i$ неравенство Хевдинга, получим
\[
    \Prob^n \Big \{ \sup_{f \in \cF} P f - P_n f \geq \epsilon \Big \} \leq N \eps(-2 n \eps^2).
\]
Это значит, с~вероятностью не~менее $1 - \delta$ выполнено
\[
    P \hat f_n - P_n \hat f_n \leq \sqrt {\frac{\log N + \log{\frac 1 \delta}}{2 n}}.
\]

Теория Вапника-Червоненкиса~\cite{vapnik74rus,vapnik98stat} позволяет справиться даже с~бесконечным классом функций $\cF$
в~важном частном случае бинарной функции потерь ($f \colon S \rightarrow \{0, 1\}$).
Для этого класс функций $\cF$ <<проецируется>> на~конечную выборку.
Более строго, рассмотрим выборку $(X_1, \dots, X_n)$,
и~пусть
\[
    \cF_{X_1, \dots, X_n} = \{(f(X_1), \dots, f(X_n) \colon f \in \cF\}.
\]
Мощность этого множества называют \emph{коэффициентом разнообразия}.
Коэффициент разнообразия зависит и~от семейства функций $\cF$,
и~от~выборки $(X_1, \dots, X_n)$.
\begin{Def}
\emph{Функцией роста} $S_\cF(n)$ называют максимальное число способов, которым $n$ объектов могут быть классифицированы
функциями из~$\cF$:
\[
    S_\cF(n) = \sup_{(X_1, \dots, X_n)} |\cF_{X_1, \dots, X_n}|.
\]
\end{Def}
\begin{Theorem}[Вапник, Червоненкис,~\cite{vapnik74rus}]
\label{vcTeorem}
Для всех $\delta > 0$ с~вероятностью не~менее $1-\delta$ выполнено
\[
    P \hat f_n - P_n \hat f_n \leq 2 \sqrt{2 \frac{\log S_\cF(2n) + \log{\frac{2}{\delta}}}{n}}.
\]
\end{Theorem}
Очевидно, что для бинарной функции потерь функция роста не~превосходит $2^n$.
\begin{Def}
Пусть $h$ "--- минимальное число, такое что $S_\cF(h) < 2^h$.
Тогда $h$ называют \emph{размерностью Вапника-Червоненкиса} (или $VC$-размерностью) для семейства $\cF$.
\end{Def}
Оказывается, что для многих реальных семейств алгоритмов $h < \infty$,
а~функция роста при $n \geq h$ растет полиномиально:
\[
    S_\cF(h) \leq \sum_{i=0}^h C_n^i \leq \Big(\frac{e n}{h}\Big)^h.
\]
Следовательно, выполнена оценка
\begin{equation}
    \label{vcBoundProb}
    P \hat f_n - P_n \hat f_n \leq 2 \sqrt{2 \frac{h \log \frac{2 e n}{h} + \log{\frac{2}{\delta}}}{n}}.
\end{equation}
Таким образом, в~случае конечной $VC$-размерности
эмпирический риск сходится к~истинному риску равномерно по~классу функций $\cF$.
Это доказывает состоятельность методов машинного обучения по~конечным выборкам данных.
Вместе с~тем, оценка~\eqref{vcBoundProb} не~применима на~практике из-за ее высокой завышенности,
возникающей при использовании супремума по~всему классу функций.

\paragraph{Композиции алгоритмов.}
Дальнейшее увеличение точности VC-оценок шло по~пути учета структуры семейства алгоритмов и~специфических свойств метода обучения.
Отметим, что большинство применяемых на~практике методов обучения 
(в частности, 
метод $k$ ближайших соседей, 
метод парзеновского окна, 
метод потенциальных функций~\cite{braverman70potential}, 
линейные классификаторы, и другие)
фактически являются композицией более простых алгоритмов.
В~работах~\cite{zhuravlev77correct1,zhuravlev77correct2,zhuravlev78correct3,zhuravlev78prob33}
изучается широкий класс корректных линейных и~алгебраических композиций алгоритмов вычисления оценок.
Для таких композиций были получены нетривиальные оценки
вероятности ошибки~\cite{matrosov80dan,matrosov84capacity,matrosov85poly},
а~также разработана теория универсальных и~локальных ограничений~\cite{rudakov87universal,rudakov88rkp,rudvoron99dan},
которая позволила унифицировать как~методику построения алгебраических композиций,
так~и~приёмы доказательства их~ключевых свойств
(таких как регулярность и~полнота).
Другим широким направлением в~области алгоритмических композиций является комитетный метод формирования алгоритмов
распознавания~\cite{mazurov71committee,mazurov90committee},
для которого также удалось получить оценки емкости класса решающих правил
и~найти достаточное условие равномерной сходимости частот к~вероятностям по~классу комитетных событий~\cite{khachai2000length,khachay06np,pytkeev2012topology}.

\section{Радемахеровский процесс}
Радемахеровский процесс~\cite{koltchinskii99rademacher,koltchinskii01rademacher}
позволяет получать оценки, вычислимые по~наблюдаемой выборке
и~не~зависящие от~неизвестных вероятностных распределений.
Кроме этого, радемахеровский процесс является крайне полезным математическим инструментом,
удобным при доказательстве некоторых утверждений (например, теоремы~\ref{vcTeorem}).

\begin{Def}
Пусть $\eps_1, \dots, \eps_n$ "--- независимые случайные величины,
такие что $P(\eps_i = {+}1) = P(\eps_i = {-}1) = \frac {1}{2}$.
Тогда \emph{радемахеровским процессом} называют следующий эмпирический процесс:
\[
    R_n(f) = \frac{1}{n}\sum_{j=1}^n \eps_j f(X_j), \;\; f \in \cF.
\]
Среднюю норму этого процесса $\Expect_\eps ||R_n||_\cF = \Expect_\eps \sup \limits_{f\in \cF}|R_n(f)|$ называют \emph{радемахеровской сложностью} семейства $\cF$,
где $\Expect_\eps$ обозначает усреднение по~радемахеровским случайным величинам $\eps_1, \dots, \eps_n$.
\end{Def}

Большая радемахеровская сложность семейства $\cF$ означает, что
для каждой реализации вектора шума $(\eps_i)_{i=1}^n$ в~семействе найдется функция, хорошо коррелирующая с~этим вектором.

Радемахеровский процесс обладает рядом полезных математических свойств. В~частности, он ограничивает
величину $\Expect^n || P - P_n ||_\cF$, где $\Expect^n$ означает усреднение по~всем реализациям выборки $(X_1, \dots, X_n)$.
Этот результат часто называют <<симметризацией>> благодаря интересному приему доказательства, основанному на~искусственном введении дополнительной выборки
$(X'_1, \dots, X'_n)$.

\begin{Lemma}(Симметризация)
\label{simmetrizationLemma}
\[
    \frac 1 2 \Expect^n \Expect_\eps || R_n ||_{\cF_c} \leq \Expect^n || P - P_n ||_\cF \leq 2 \Expect^n \Expect_\eps || R_n ||_{\cF},
\]
где $\cF_c = \{f - P f, f \in \cF\}$.
\end{Lemma}

Следующее неравенство является еще одним часто используемым приемом при работе с~радемахеровскими процессами:
\begin{Lemma}(Неравенство сжатия)
    Пусть функции класса $\cF$ принимают значения из~$[{-}1, 1]$.
    Пусть функция $\phi \colon [{-}1, 1] \rightarrow \RR$ "--- липшецева с~константой~$L$,
    и~$\phi(0) = 0$. Тогда для класса функций $\phi \circ \cF = \{\phi \circ f \colon f \in \cF\}$ справедливо неравенство
    \[
        \Expect_\eps || R_n ||_{\phi \circ \cF} \leq 2 L \Expect_\eps || R_n ||_{\cF}.
    \]
    В частности, при $\phi(t) = t^2$ выполнено следующее:
    \begin{equation}
        \label{contractionIneq}
        \Expect_\eps \sup_{f \in \cF} \Big| \sum_{j = 1}^n \eps_j f^2(X_j) \Big|
            \leq
        4 \Expect_\eps \sup_{f \in \cF} \Big| \sum_{j = 1}^n \eps_j f(X_j) \Big|
    \end{equation}
\end{Lemma}

Рассмотрим еще одно неравенство концентрации, обобщающее неравенство Хевдинга.
\begin{Theorem}[МакДиармид]
\label{thMacDiarmid}
Пусть функция $F \colon S^n \rightarrow \RR$ для всех $i = 1, \dots, n$ и~фиксированного $c > 0$ удовлетворяет условию ограниченной вариации:
\[
    \sup_{z_1, \dots, z_n, z'_i} | F(z_1, \dots, z_i, \dots, z_n) - F(z_1, \dots, z'_i, \dots, z_n) | \leq c,
\]
и~пусть $X_1, \dots, X_n$ "--- независимые одинаково распределенные случайные величины.
Тогда для произвольного $\eps > 0$ выполнено
\begin{equation}
    \label{eq:macDiarmid}
    \Prob^n \Big\{ | F(X_1, \dots, X_n) - \Expect^n F(X_1, \dots, X_n)| > \epsilon \Big\} \leq 2 \exp \Big(- \frac{2 \eps^2}{n c^2} \Big).
\end{equation}
\end{Theorem}

Заметим, что оба выражения $|| P - P_n ||_\cF$ и~$||R_n||_{\cF}$ являются функциями от~$(X_1, \dots, X_n)$,
удовлетворяющими условию ограниченной вариации с~константой $c = \frac 1 n$.
Это позволяет применить оценку~\eqref{eq:macDiarmid} к~$|| P - P_n ||_\cF$,
затем воспользоваться леммой симметризации~\ref{simmetrizationLemma},
после чего вновь применить~\eqref{eq:macDiarmid}, но для $||R_n||_{\cF}$.
Итоговое неравенство дает верхнюю оценку на~избыточный риск, в~которой правая часть зависит лишь от~наблюдаемой выборки
и~не~содержит неизвестных вероятностных распределений.

Обратив оценку \eqref{eq:macDiarmid}, получим, что для любого $\delta > 0$ с~вероятностью не~менее $1 - \delta$ выполнено
\begin{equation}
    \label{eq:MacDiarminBound}
    P \hat f - P_n \hat f \leq 2 \Expect_\epsilon \sup_{f \in \cF} | R_n f | + \sqrt{\frac{2 \log {\frac 2 \delta}}{n}}.
\end{equation}
Данная оценка, как и~неравенство Хевдинга \eqref{eq:hoeffding-ineq},
не~учитывает дисперсию класса функций.
Соответствующее обобщение неравенства Бернштейна, учитывающего дисперсии, оказалось намного более трудной задачей,
решенной с~помощью неравенства Талаграна.

\section{Неравенство Талаграна}
В статистической теории обучения используется следующая формулировка неравенства Талаграна:
\begin{Theorem}[Талагран, \cite{talagrand1996new}]
Пусть $(X_1, \dots, X_n)$ "--- независимые случайные величины,
пусть $\cF$ "--- класс функций, равномерно ограниченных константой $U > 0$.
Тогда для любого $\eps > 0$
\[
    \Prob^n \Big\{ \Big| || P_n f ||_\cF - \Expect^n || P_n f ||_\cF \Big| > \eps \Big \} \leq
        K \exp \Big\{ -\frac 1 K \frac {\eps}{n U} \log \Big(1 + \frac{\eps U}{n V}\Big) \Big\},
\]
где $P_n f = \frac{1}{n}\sum\limits_{j=1}^n f(X_j)$,
$K$ "--- некоторая константа,
$V$ "--- любое число, удовлетворяющее условию
\[
    V \geq \Expect^n \sup_{f \in \cF} \sum_{j = 1}^n f^2(X_j).
\]
\end{Theorem}
В этой теореме константу $V$ следует интерпретировать как дисперсию класса функций $\cF$.
Более конструктивное выражение для $V$ можно получить, применив лемму~\ref{simmetrizationLemma} о симметризации, а~затем неравенство сжатия~\eqref{contractionIneq}:
\[
    \Expect^n \sup_{f \in \cF} \sum_{j = 1}^n f^2(X_j) \leq n \sup_{f \in \cF} P f^2 + 8 n U \Expect_\eps || R_n ||_\cF \equiv V.
\]
Аналогичные неравенства, но с~более строгими константами, были доказаны в~\cite{bousquet2002bennett} и~\cite{klein2002}.
\[
\Prob^n \Big\{ || P_n - P ||_\cF \geq \Expect^n || P_n - P ||_\cF + \sqrt{2 \frac t n \big(\sigma_P^2(\cF) + 2 \Expect^n || P_n - P ||_\cF \big) } + \frac {t}{3n} \Big\} \leq e^{-t};
\]
\[
\Prob^n \Big\{ || P_n - P ||_\cF \leq \Expect^n || P_n - P ||_\cF - \sqrt{2 \frac t n \big(\sigma_P^2(\cF) + 2 \Expect^n || P_n - P ||_\cF \big) } - \frac {t}{n} \Big\} \leq e^{-t};
\]
где
\[
    \sigma_P^2(\cF) \equiv \sup_{f \in \cF} \Big(P f^2 - (P f)^2 \Big).
\]
Благодаря учету дисперсии функций класса $\cF$,
неравенство Талаграна позволяет существенно повысить точность оценок на~избыточный риск.

\section{Локальные оценки избыточного риска}
Все оценки избыточного риска, приведенные в~прошлых параграфах, основывались на~следующем неравенстве:
\[
    P \hat f_n - P_n \hat f_n \leq \sup_{f \in \cF} P f - P_n f,
\]
где супремум берется по~всему классу функций $\cF$.
Это приводит к~завышенности оценок,
поскольку на~практике методы обучения перебирают не~все функции из~$\cF$, а~лишь малую часть алгоритмов классификации,
расположенных в~окрестности лучшего решения.

В работах~\cite{bartlett02localized,bartlett04local,bartlett05local,koltchinskii2006local} эта проблема решена следующим образом.
Для произвольного $\delta > 0$ из~семейства $\cF$ выделяется \emph{$\delta$-минимальное множество}, у~функций которого истинный риск не~превосходит $\delta$:
\[
    \cF(\delta) = \cF_P(\delta) = \{f \in \cF \colon \cE_P(f) \leq \delta\}.
\]
Пусть функция $\bar f \in \Argmin_{f \in \cF} P f$ минимизирует истинный риск,
а~функция $\hat f \in \Argmin_{f \in \cF} P_n f$ минимизирует эмпирический риск.
Обозначим $\hat \delta = \cE_P(\hat f)$ и
допустим, что $\bar f \in \cF$.
Тогда $\hat f, \bar f \in \cF(\hat \delta)$ и~$P_n \hat f \leq P_n \bar f$.
Следовательно,
\[
    \hat \delta = \cE_P(\hat f) = P(\hat f - \bar f) =
        P_n (\hat f - \bar f) + (P - P_n)(\hat f - \bar f),
\]
а~значит,
\[
    \hat \delta \leq \sup_{f, g \in \cF(\delta)}|(P_n - P) (f - g)|.
\]
Допустим, что существует неслучайная верхняя оценка вида
\begin{equation}
    \label{stationaryPointBound}
    U_n(\delta) \geq \sup_{f, g \in \cF(\delta)}|(P_n - P) (f - g)|,
\end{equation}
верная с~высокой вероятностью равномерно по~$\delta$.
Тогда избыточный риск $\eps_P(\hat f)$ будет с~той же вероятностью
ограничен сверху наибольшим решением неравенства $\delta \leq U_n(\delta)$.

Оказывается, что оценку вида~\eqref{stationaryPointBound} можно
построить с~помощью неравенства Талаграна.
Пусть $D(\cF)$ обозначает $L_2(P)$-диаметр $\delta$-минимального множества:
\[
    D(\delta) = \sup_{f, g \in \cF(\delta)} \Big(P(f-g)^2 - (P(f-g))^2\Big).
\]
Определим функцию $\phi_n(\delta)$ следующим образом:
\[
    \phi_n(\delta) =
    \Expect^n \sup_{f, g \in \cF(\delta)}|(P_n - P)(f - g)|;
\]

\begin{Theorem}[Колчинский,~\cite{koltchinskii11oracle}]
\label{thKolchinskii}
Пусть $\{\delta_j\}_{j \geq 0}$ "--- убывающая последовательность положительных чисел, такая что $\delta_0 = 1$.
%Пусть $\{t_j\}_{j \geq 0}$ "--- любая последовательность положительных чисел.
Рассмотрим кусочно-постоянную функцию $U_n(\delta)$,
определенную на~промежутках $\delta \in (\delta_{j+1}, \delta_j]$ следующей формулой:
\[
    U_n(\delta, t) = \phi_n(\delta_j) + \sqrt{2 \frac{t}{n}(D^2(\delta_j) + 2 \phi_n(\delta_j))} + \frac{t}{2 n}, \text { где } t > 0.
\]
Положим
\[
    \delta_n(t) = \sup \{\delta \in (0, 1] \colon \delta \leq U_n(\delta)\}.
\]
Тогда для всех $\delta \geq \delta_n(t)$ выполнено
\begin{equation}
    \label{eqKolchinskii}
    \Prob^n\Big\{\cE(\hat f_n) > \delta\Big\}
        \leq  C(\delta) e^{{-}t},
\end{equation}
где $C(\delta)$ "--- количество членов последовательности $\{\delta_j\}_{j \geq 0}$, превышающих $\delta$.
\end{Theorem}

%Отметим, что вид функции $U_n(\delta, t)$ в~теореме~\ref{thKolchinskii} продиктован неравенством Талаграна.

Зафиксируем число $q > 1$ и~положим $\delta_j = q^{-j}$.
Тогда в~условиях прошлой теоремы получим оценку
\[
    \Prob^n\Big\{\cE(\hat f) \geq \delta \Big\} \leq \left( \log_q \frac{q}{\delta}\right)e^{{-}t},
\]
справедливую при $\delta \geq \delta_n(t)$.

На оценки, приведенные в~данном параграфе, можно смотреть как на~итерационный процесс.
На первой итерации неравенство концентрации меры применяется ко всему семейству функций $\cF$,
и~получается верхняя оценка на~избыточный риск $\cE(\hat f) \leq \delta_0$.
На следующем шаге оценка применяется уже к~$\delta_0$-минимальному множеству $\cF(\delta_0)$,
и~получается новая оценка $\cE(\hat f) \leq \delta_1$.
При этом сужение рассматриваемого класса функций $\cF \supset \cF(\delta_0) \supset \cF(\delta_1) \supset \dots$
приводит к~уменьшению дисперсии и, как следствие,
к повышению точности оценки на~каждой следующей итерации.
Именно для этого важно использовать неравенства типа Бернштейна, а~не Хевдинга.
Отметим, что на~каждой итерации неравенство верно лишь с~определенной вероятностью.
Таким образом, вероятность ошибки накапливается,
но весь процесс удалось организовать так, что он сходится к~итоговой оценке~\eqref{eqKolchinskii}.

\section{PAC-Bayes оценки}
В данном параграфе будут рассмотрены оценки обобщающей способности, полученные для семейства линейных решающих правил.
Пусть $\XX = \RR^d$ "--- множество объектов, описанных $d$ вещественными признаками,
а~$\YY = \{{+}1, {-}1\}$ "--- метки целевых классов.
Каждый вектор весов $\vec w \in R^d$ определяет линейный классификатор $c_{\vec w}$, действующий на~объекты $\vec x \in R^d$
по~правилу $c_{\vec w}(\vec x) = \sign ({\vec w}^T \vec x)$.

Как и~в~прошлых главах, для каждого классификатора $c_{\vec w}$ нас интересует его истинный риск $P(c_{\vec w})$
и~эмпирический риск $P_n(c_{\vec w})$ на~выборке $(\vec{x}_i, y_i)_{i=1}^n$:
\begin{equation}
\begin{aligned}
    & P(c_{\vec w}) = \int\limits_{(x, y) \in S} I(\sign({\vec w}^T \vec x), y) d P, \\
    & P_n(c_{\vec w}) = \frac{1}{n}\sum_{i=1}^n I(\sign({\vec w}^T \vec{x}_i), y_i),
\end{aligned}
\end{equation}
где $I(y_1, y_2) = [y_1 \neq y_2]$ "--- функция потерь, $[\text{истина}] = 1$, $[\text{ложь}] = 0$.

Основная идея PAC-Bayes подхода~\cite{langford05tutorial,langford02pacbayes,mcallester1998some,seeger02pacbayes}
заключается в~рассмотрении \emph{стохастических классификаторов}.
Пусть $C$ "--- множество классификаторов, а~$Q$ задает распределение вероятности на~этом множестве.
Истинный и~эмпирический риски стохастического классификатора определены следующим образом:
\begin{equation}
\begin{aligned}
    & P(Q)   = \Expect_{\vec w \sim Q} P(c_{\vec w})   = \int\limits_{w \in C}\int\limits_{(x, y) \in S} I(\sign({\vec w}^T \vec x), y) d P d Q, \\
    & P_n(Q) = \Expect_{\vec w \sim Q} P_n(c_{\vec w}) = \int\limits_{w \in C}\frac{1}{n}\sum_{i=1}^n I(\sign({\vec w}^T \vec{x}_i), y_i) d Q,
\end{aligned}
\end{equation}

Следующая теорема дает оценку обобщающей способности для стохастического классификатора.
\begin{Theorem}[Langford, \cite{langford05tutorial}]
\label{ThPACBayesGeneral}
Пусть $Q_0$ "--- произвольное априорное распределение на множестве классификаторов.
Тогда для любого $\delta \in (0, 1)$ выполнено
\[
    \Prob^n\Big\{ \forall Q, kl\big( P_n(Q), P(Q) \big) \leq \frac{KL(Q || Q_0) + \ln \frac{n+1}{\delta}}{n} \Big\} \geq 1 - \delta,
\]
где $KL(Q || Q_0)$ обозначает дивергенцию Кульбака - Лейблера между распределениями $Q$ и~$Q_0$,
$kl(q||p) = q \log \frac q p + (1 - q) \log \frac{1-q}{1-p}$ определена при $q, p \in [0, 1]$
и~обозначает KL-дивергенцию между двумя случайными величинами Бернулли.
\end{Theorem}
С точки зрения задачи обучения по~прецедентам, распределение $Q_0$ в~теореме~\ref{ThPACBayesGeneral}
следует воспринимать как априорное распределение, выбранное до реализации обучающей выборки.
Распределение $Q$ можно выбрать уже после того, как стала известна обучающая выборка
$(\vec{x}_i, y_i)_{i=1}^n$.

Теорему~\ref{ThPACBayesGeneral} можно применить к~семейству линейных классификаторов.
Пусть результатом обучения является классификатор $\hat {\vec w} \in \RR^n$.
В качестве априорного распределения $Q_0$ всегда выбирают многомерное нормальное распределение $\cN(\vec 0, I_d)$ с~единичной дисперсией $I_d$ и~нулевым вектором математического ожидания.
Апостериорное распределение $Q$ полагают равным $\cN(\mu \hat {\vec w}, I_d)$,
т.~е. вновь используют нормальное распределение с~единичной дисперсией,
но вектор математического ожидания выбирают в~направлении классификатора $\hat {\vec w}$;
длиной вектора управляет константа $\mu$, которая может быть выбрана произвольно.

\begin{Theorem}[Langford, \cite{langford05tutorial}]
\label{thLinearPacBayes}
Пусть $\XX = \RR^d$, $\mu > 0$ "--- константа,
$\hat{\vec w} \in \RR^d, ||\hat{\vec w}|| = 1$ "--- единичный вектор.
Пусть $Q(\mu, \hat{\vec w})$ обозначает распределение на~линейных классификаторах
$c_{\vec w}$, где $\vec w \sim \cN(\mu \hat{\vec w}, I_d)$.
Тогда для любого $\delta \in (0, 1)$ с~вероятностью не~менее $1 - \delta$
относительно реализаций обучающей выборки $(\vec{x}_i, y_i)_{i=1}^n$
\[
    kl( P_n(Q(\mu, \hat{\vec w} )),  P(Q(\mu, \hat{\vec w})) ) \leq
        \frac{\frac{\mu^2}2 + \ln \frac{n+1}{\delta}}{n}
\]
выполнено для всех $\mu > 0$
и~всех $\hat{\vec w} \in \RR^d$ при $||\hat{\vec w}|| = 1$.
Кроме этого, эмпирический риск стохастического классификатора может быть записан в~виде
\[
    P_n(Q(\mu, \hat{\vec w} )) = \frac{1}{n} \sum_{i = 1}^n \overline \Phi(\mu \gamma(\hat{\vec w}, \vec x_i, y_i)),
\]
где $\gamma(\hat{\vec w}, \vec x, y)) = y \frac{\hat{\vec w}^T \vec x}{||\vec x_i||}$ "--- отступ прецедента $(\vec x, y)$ от~разделяющей плоскости $\hat{\vec w}$;
\[
    \overline \Phi(t) = 1 - \Phi(t) = \int_t^\infty \frac{1}{\sqrt{2 \pi}} e^{\tau^2 / 2} d \tau
\]
дает вероятность правого хвоста нормального распределения.
\end{Theorem}

Можно показать, что для любого $\mu > 0$ истинный риск классификатора $c_{\hat{\vec w}}$
не~превосходит удвоенного риска стохастического классификатора $Q(\mu, \hat{\vec w})$.
Это позволяет применить теорему~\ref{thLinearPacBayes} к~детерминированному линейному классификатору.
Алгоритм~\ref{algLinearPacBayes} показывает явную схему вычислений.
Отметим, что теорема~\ref{thLinearPacBayes} справедлива для произвольного значения параметра $\mu$,
что позволяет минимизировать оценку по~этому параметру.

\begin{algorithm}
\caption{PAC-Bayes оценка для линейного классификатора}
\label{algLinearPacBayes}
\begin{algorithmic}[1]
\REQUIRE Классификатор $\hat{\vec w} \in \RR^d$, выборка $(\vec{x}_i, y_i)_{i=1}^n$, параметры $\delta$;
\ENSURE Верхняя оценка $E = P(\hat{\vec w})$ на~истинный риск классификатора $\hat{\vec w}$.
\STATE Нормировать классификатор: $ \hat{\vec w} := \hat{\vec w} \Big/ || \hat{\vec w} || $;
\STATE Вычислить отступы: $\gamma_i := y_i \hat{\vec w}^T \vec{x}_i$, при $i = 1, \dots, n$;
\STATE Сгенерировать логарифмическую сетку $M := \exp({-}7 \colon 0.01 \colon 15)$;
\FORALL{$\mu \in M$}
    \STATE Вычислить эмпирический риск: $E_n := \sum\limits_{i=1}^n \overline{\Phi}(\mu \gamma_i)$;
    \STATE Положить $T := \frac{\mu^2}{2n} + \frac{1}{n}\ln \frac{n+1}{\delta}$;
    \STATE Положить $E_\mu := \max \Big\{p \in [0, 1] \colon kl(E_n, p) \leq T \Big\}$;
\ENDFOR
\RET $P(\hat{\vec w}) := 2 \cdot \Argmin_{\mu \in M}E_\mu$.
\end{algorithmic}
\end{algorithm}

\section{Основные выводы}

Основная задача теории статистического обучения (SLT) "---
вывод теоретических оценок обобщающей способности для методов машинного обучения.
Подобные оценки используются при отборе признаков, выборе моделей при структурной минимизации риска,
а~также как альтернатива вычислительно трудоемкой процедуре скользящего контроля.

В основе SLT лежит модель, основанная на~неизвестном и~принципиально ненаблюдаемом вероятностном распределении на~множестве всех объектов классификации.
Модель SLT гарантирует, что оценки обобщающей способности будут выполнены для новых объектов,
недоступных на~этапе обучения, с~заранее фиксированной вероятностью.

Оценки, полученные в~SLT, остаются слишком завышенными для их~применения в~большинстве прикладных задач.
Основная причина в~том, что SLT дает оценки худшего случая, справедливые для любого вероятностного распределения на~пространстве объектов,
а~также для практически любого метода обучения.
Получить более точные оценки возможно лишь за счет учета специфических свойств конкретных задач и~методов обучения.

\chapter{Комбинаторный подход}

В~данной главе вводятся основные определения и~понятия комбинаторного подхода к оценке обобщающей способности.

\section{Основные определения}

Пусть задана генеральная выборка $\XX=\{ x_1, \ldots, x_L \}$, состоящая из~$L$ объектов.
Пусть $\cA$ "--- некоторое семейство алгоритмов (например, семейство всех линейных разделяющих поверхностей в~исходном признаковом пространстве задачи).
Каждый алгоритм классификации $\alpha \in \cA$, примененный к~выборке $\XX$, порождает бинарный вектор
ошибок $a \equiv \bigl( I(\alpha, x_i) \bigr){}_{i=1}^L$,
где $I(\alpha, x_i) \in \{0, 1\}$ "--- индикатор ошибки алгоритма $\alpha$ на~объекте $x_i$.
Множество попарно-различных векторов ошибок, индуцированных семейством $\cA$ и~выборкой $\XX$,
называется \emph{матрицей ошибок семейства $\cA$} и~обозначается через~$A$.
В дальнейшем выборка~$\XX$ предполагается фиксированной,
поэтому алгоритмы $\alpha \in \cA$ будут отождествляться с~векторами своих ошибок на~выборке $\XX$,
а~семейство $\cA$ "--- с~матрицей ошибок~$A$.

\begin{Remark}
Важно помнить, что на объектах выборки $\XX=\{ x_1, \ldots, x_L \}$ выбран фиксированный порядок (нумерация от $1$ до $L$).
Это позволяет рассматривать бинарные \emph{векторы} ошибок алгоритмов, 
в которых порядок следования нулей и единиц определяется выбранным порядком объектов выборки.
Вместе с тем на алгоритмах $\alpha \in \cA$ и~на их векторах ошибок порядок не введен.
Говоря <<матрица ошибок>>,
мы на~самом деле имеем в~виду неупорядоченное множество векторов ошибок.
Таким образом, матрица ошибок~$A$ рассматривается как подмножество $A \subset \AA \equiv \{0, 1\}^L$
множества всех возможных векторов ошибок.
Кроме этого, вместо термина <<матрица ошибок алгоритмов>> часто будет употребляться термин <<множество алгоритмов>>.
\end{Remark}

\begin{Remark}
В ряде случаев мы будем искусственно генерировать матрицу ошибок алгоритмов~$A$ в~явном виде,
не~указывая, из~какого семейства $\cA$ она была получена.
В таких случаях мы будем говорить о \emph{модельном множестве алгоритмов}.
\end{Remark}

\paragraph{Метод обучения.}
\emph{Методом обучения} называют отображение вида $\mu \colon 2^\XX \rightarrow A$.
Для произвольной обучающей выборки $X \subset \XX$ метод обучения возвращает алгоритм
$a = \mu X$ из~фиксированного множества~$A$.
Мы будем использовать обозначения $\mu(X, A)$ в~тех случаях, когда нужно явно подчеркнуть, из~какого множества алгоритмов производится выбор.

Для выборки $X \subset \XX$ обозначим через
$n(a,X) = \sum\limits_{x\in X}I(a,x)$
\emph{число ошибок}, а~через
$\nu(a,X) = n(a,X) / |X|$ "---
\emph{частоту ошибок} алгоритма~$a$ на~выборке~$X$.
Подмножество $A_m = \{a \in A \colon n(a, \XX) = m\}$ называют \emph{$m$-слоем} алгоритмов.

Частоту ошибок на~обучающей выборке называют \emph{эмпирическим риском}.
\emph{Минимизация эмпирического риска} (МЭР) "--- это метод обучения,
который из~заданного множества $A \subset \AA$ выбирает алгоритм $a \in A$,
допускающий наименьшее число ошибок на~обучающей выборке $\Xl$.
Таким образом, для всех $\Xl \subset \XX$ выполнено $\mu \Xl \in A(\Xl)$,
где множество
\begin{equation}
\label{eq:A(X)}
    A(X) = \Argmin_{a\in A} n(a,\Xl)
\end{equation}
соответствует слою алгоритмов с~минимальным числом ошибок на~обучающей выборке~$\Xl$.
Из-за дискретности функции $n(a, X)$
минимальный эмпирический риск может достигаться сразу для нескольких алгоритмов.
Чтобы разрешить эту неоднозначность, вводится \emph{пессимистический} МЭР.
Он разрешает неоднозначность, выбирая в~$A(X)$ алгоритм с~наибольшим числом ошибок на~полной выборке:
\begin{equation}
    \label{eq:mu-ERM-pessimistic}
    \mu X \in \Argmax_{a\in A(X)} n(a, \XX).
\end{equation}
Пессимистический МЭР не~может быть реализован на~практике,
т.к. он подглядывает в~скрытую часть выборки.
Тем не~менее, пессимистический МЭР является удобной теоретической конструкцией,
поскольку он позволяет получать верхние оценки на~вероятность переобучения любого МЭР.

\paragraph{Перестановочная вероятность.}
Обозначим через~$\XXell$ множество всех разбиений генеральной выборки~$\XX$
на~обучающую выборку~$\Xl$ длины~$\ell$ и~контрольную выборку~$\Xk$ длины $k=L-\ell$.

Для предиката $\phi \colon \XXell \rightarrow \{0, 1\}$
и~вещественной функции $\psi \colon \XXell \rightarrow \RR$
определим оператор вероятности~$\Prob$ и~матожидания~$\Expect$:
\[
    \Prob \phi = \frac 1{\CC_L^\ell} \sum_{X \in \XXell} \phi(X),
    \qquad
    \Expect \psi = \frac 1{\CC_L^\ell} \sum_{X \in \XXell} \psi(X).
\]

Если \emph{уклонение частот} $\delta(a, X) = \nu(a,\X) - \nu(a, X)$
превосходит фиксированный порог $\eps > 0$,
то~говорят, что алгоритм $a = \mu X$ является \emph{переобученным}.
Нашей целью является оценка \emph{вероятности переобучения}~\cite{voron07theory,voron08pria-eng}:
\begin{equation}
    \label{eq:QEps}
    Q_\eps (\mu, \XX)
    =
    \Prob\bigl[
        \delta(\mu, X) \geq \eps
        %\nu(\mu X,\X) - \nu(\mu X, X) \geq \eps
    \bigr].
\end{equation}
где для краткости введено обозначение
$\delta(\mu, X) = \delta(\mu X, X)$,
а~квадратные скобки действуют по~правилам $[\text{истина}] = 1$, $[\text{ложь}] = 1$.

\emph{Обращением оценки} $Q_\eps \leq \eta(\eps)$ называют неравенство вида
\[\nu(\mu X,\X) - \nu(\mu X, X) \leq \eps(\eta),\]
выполненное с~вероятностью не~менее $1-\eta$, где $\eps(\eta)$
является обратной функцией для $\eta(\eps)$.
\emph{Медианой оценки} $Q_\eps \leq \eta(\eps)$ называют инверсию в~точке~$\eta = 1/2$.

Средние частоты ошибок на~обучении и~на контроле определим следующим образом:
\begin{gather}
    \label{eq:avgTrainNu}
    \nu_\ell(\mu, \XX) = \Expect\nu(\mu X, X);
\\
    \label{eq:avgTestNu}
    \bar \nu_\ell(\mu, \XX) = \Expect\nu(\mu X, \X).
\end{gather}

\begin{Example}
В~следующей таблице показан пример модельного множества алгоритмов,
для которого минимизация эмпирического риска приводит к~переобучению.
Столбцы таблицы соответствуют алгоритмам,
строки "--- объектам обучающей выборки $\{x_1,\ldots,x_\ell\}$
и~контрольной выборки $\{x_{\ell+1},\ldots,x_L\}$.
Единица в~$[i,d]$-й ячейке таблицы означает, что
алгоритм~$a_d$ допускает ошибку на~объекте~$x_i$.
\[
    \bordermatrix{
          & a_1 & a_2 & \cdots & a_d & \cdots & a_D \cr
    x_1 & 0 & 1 & \cdots & {0} & \cdots & 1 \cr
    \cdots & 1 & 1 & \cdots & {0} & \cdots & 0 \cr
    x_\ell & 0 & 0 & \cdots & {0} & \cdots & 0 \vspace{-2ex}\cr\cline{2-7}
    x_{\ell + 1} & 1 & 1 & \cdots & {1} & \cdots & 1 \cr
    \cdots & 1 & 0 & \cdots & {1} & \cdots & 0 \cr
    x_L & 0 & 0 & \cdots & {1} & \cdots & 0
    }
\]
В~данном примере переобучение могло быть следствием <<неудачного>> разбиения
генеральной выборки на~обучение и~контроль.
Поэтому функционал вероятности переобучения~\eqref{eq:QEps}
содержит усреднение по~всем разбиениям $\XX = X \sqcup \X$ на~обучение и~контроль фиксированной длины.
\end{Example}

%Функционал $Q_\eps(A)$ уже не~зависит от~выбора разбиения
%и~характеризует качество данного метода обучения на~данной генеральной выборке.
%Заметим, что $1-\Q(A)$ как функция порога $\eps$ есть функция распределения случайной величины $\delta(\mu(A, X), X)$,
%определенной на~конечном вероятностном пространстве
%$\{\XXell, 2^{\XXell}, \Prob\}$, где $\Prob$ "--- равномерное распределение.

Определение~\eqref{eq:QEps} впервые упоминается в~работе~\cite{haussler94predicting} для частного случая $k = 1$.
Кроме этого, оно встречается в~работах~\cite{bottou94effective,bax97similar},
на~этот раз для произвольного $k$, но с~существенными различиями в~обозначениях.
Это определение не~случайно напоминает процедуру полной кросс-валидации,
поскольку при решении практических задач кросс-валидация зарекомендовала себя как
наиболее точный инструмент для оценки обобщающей способности.

\paragraph{Гипергеометрическое распределение.}
Рассмотрим алгоритм~$a$, допускающий $m = n(a, \XX)$ ошибок на~полной выборке.
Вероятность того, что из~$m$ ошибок в~обучающей выборке~$X$ окажется ровно~$s$ ошибок, равна \emph{гипергеометрической функции}:
\[
    \Prob[ n(a,X)=s ]
    = \frac{\CC_m^s \CC_{L-m}^{\ell-s}}{\CC_L^\ell}
    \equiv
    \hyper{L}{m}{\ell}{s},
\]
где
параметр~$s$ пробегает от~${s_0 = \max\{0,m-k\}}$ до ${s_1 = \min\{m,\ell\}}$,
а~параметр~$m$ принимает значения $0,\ldots,L$.
Мы полагаем
$\CC_m^s = \hyper{L}{m}{\ell}{s} = 0$
для всех прочих значений $m,s$.

Определим \emph{функцию гипергеометрического распределения} следующим образом:
\[
    \Hyper{L}{m}{\ell}{z}
    =
    \sum\limits_{s=s_0}^{\lfloor z \rfloor}
    \hyper{L}{m}{\ell}{s}.
\]

Рассмотрим множество $A=\{a\}$, состоящее из~одного алгоритма.
Тогда $\mu X = a$ для любой выборки $X \in \XXell$.
Это значит, что вероятность переобучения~$Q_\eps$ преобразовалась
в~вероятность больших уклонений между частотами ошибок в~выборках~$X,\X$.
Допустим, что число ошибок $n(a,\XX)$ нам известно, и получим точное выражение для $Q_\eps$.

\begin{Theorem}[FC-оценка~\cite{voron11premi}]
\label{th:QEps-FC-bound}
    Для фиксированного алгоритма~$a$, такого что ${m=n(a,\XX)}$,
    любой генеральной выборки $\XX$
    и~любого $\eps\in [0,1]$
    вероятность переобучения определяется левым хвостом гипергеометрического распределения:
    \begin{equation}
    \label{eq:QEps-FC-bound}
        Q_\eps(a, \XX)
        =
        \Hyper{L}{m}{\ell}{ \tfrac{\ell}{L} (m-\eps k) }.
    \end{equation}
\end{Theorem}

Гипергеометрическое распределение играет важную роль во многих комбинаторных оценках.
Оценка~\eqref{eq:QEps-FC-bound}, примененная совместно с~неравенством Буля,
позволяет получить верхнюю оценку на~$Q_\eps(\mu, \XX)$, справедливую для любого метода обучения $\mu$:
\begin{Theorem}[VC-оценка~\cite{voron11premi}]
\label{th:QEps-VC-bound}
    Для любой генеральной выборки $\XX$,
    метода обучения~$\mu$
    и~любого $\eps\in [0,1]$
    вероятность переобучения ограничена суммой FC-оценок по~множеству алгоритмов~$A$:
    \begin{equation}
    \label{eq:QEps-VC-bound}
        Q_\eps(\mu, \XX)
        %Q_\eps(A, \XX)
        \leq
        \Prob\bigl[
        \max_{a \in A}\delta(a, X) \geq \eps
        \bigr]
        \leq
        \sum_{a\in A}
        \Hyper{L}{m}{\ell}{ \tfrac{\ell}{L} (m-\eps k) },
        \quad
        m = n(a,\XX).
    \end{equation}
\end{Theorem}
Назовем две причины завышенности оценки~\eqref{eq:QEps-VC-bound}.
Во-первых, большинство алгоритмов из~$A$ имеют высокую частоту ошибок,
а следовательно, имеют исчезающе малую вероятность реализоваться в~результате обучения.
Тем не~менее, оценка равномерного уклонения игнорирует это свойство метода обучения~$\mu$.
Во-вторых, неравенство Буля игнорирует тот факт, что алгоритмы с~близкими векторами ошибок переобучаются в~основном на~одних и~тех же разбиениях.
Более точные оценки должны учитывать свойства метода обучения и~сходство между алгоритмами.

\section{Расслоение и~связность}

\paragraph{Граф расслоения-связности.}
На множестве алгоритмов~$A$ естественным образом вводится \emph{отношение частичного порядка}:
$a\leq b$ тогда и~только тогда, когда $I(a, x) \leq I(b, x)$ для всех $x \in \XX$.
Определим $a < b$ если $a \leq b$ и~$a \neq b$.
\emph{Расстоянием} между парой алгоритмов называют хэммингово расстояние между их векторами ошибок:
$\rho(a,b) = \sum\limits_{i=1}^L |a_i-b_i|$.
Если $a < b$ и~$\rho(a, b) = 1$, то~говорят, что~$a$ предшествует $b$, и~записывают $a \prec b$.
Очевидно, что при этом $n(a, \XX) + 1 = n(b, \XX)$.

\begin{Definition}[Воронцов,~\cite{voron09roai2008}]
    \emph{Графом расслоения--связности\footnote{В~\cite{haussler94predicting} аналогичный граф называют термином $1$-inclusion graph.}}
    множества алгоритмов~$A$
    называют направленный граф $\langle A, E\rangle$
    с~множеством ребер $E = \bigl\{ (a,b) \colon a \prec b \bigr\}$.
\end{Definition}

\begin{Example}
    На~рис.\,\ref{fig:SC-graph-linear-classifiers-example} показан граф расслоения--связности,
    порождаемый семейством линейных алгоритмов классификации
    на~выборке длины~$L=10$.
%    Начальный фрагмент его матрицы ошибок приводился
%    на~рис.\,\ref{figMatrixOfErrorsLin}, стр.\,\pageref{figMatrixOfErrorsLin}.
    Выборка линейно разделима,
    поэтому в~графе имеется нулевой слой.
    Этот слой состоит из~единственной вершины,
    соответствующей нулевому вектору ошибок.
    Первый слой образуется 5~алгоритмами с~одной  ошибкой,
    второй слой "--- 8~алгоритмами с~двумя ошибками, и~т.\,д.
\end{Example}

Граф расслоения--связности является многодольным,
доли соответствуют слоям~$A_m = \{a \in A \colon n(a, \XX) = m\}$,
ребрами могут соединяться только алгоритмы соседних слоев.
Каждому ребру ${a\prec b}$ графа расслоения--связности
соответствует один и~только один объект $x_{ab} \in \XX$,
такой, что $I(a,x_{ab})=0$ и~$I(b,x_{ab})=1$.

\begin{figure}[t]
    \begin{center}
        \includegraphics[width = 70mm]{Pictures/SimpleGraph.PNG.eps}
        \includegraphics[width = 70mm]{Pictures/SimpleSample0num.PNG.eps}
        \includegraphics[width = 70mm]{Pictures/SimpleSample1.PNG.eps}
        \includegraphics[width = 70mm]{Pictures/SimpleSample2.PNG.eps}
    \end{center}
    \vskip-2ex
    \caption[Пример графа расслоения--связности]{%
		\small
        Пример графа расслоения--связности (вверху слева; по~вертикальной оси отложены номера слоев),
        порождаемого семейством линейных алгоритмов классификации
        на~выборке из~10~объектов, по~5~объектов в~каждом классе (вверху справа).
        Первый слой образуется 5~алгоритмами с~одной ошибкой (внизу слева),
        второй слой "--- 8~алгоритмами с~двумя ошибками (внизу справа), и~т.\,д.}
    \label{fig:SC-graph-linear-classifiers-example}
\end{figure}

%Граф расслоения--связности является подграфом графа транзитивной редукции отношения порядка~$\leq$,
%называемого также \emph{диаграммой Х\'ассе}.
%В~графе $\langle A, E\rangle$ ребрами соединяются только алгоритмы, отличающиеся на~одном объекте,
%тогда как в~диаграмме Хассе ребрами соединяются также и~алгоритмы $a,b$,
%отличающиеся более чем на~одном объекте,
%если не~существует такого $c\in A$, что $a < c < b$.

\paragraph{Оценка расслоения-связности.}

\begin{Def}
\label{def:upperConnectivity}
\emph{Верхней связностью $u(a)$} алгоритма ${a\in A}$
называют число ребер графа расслоения-связности, исходящих из~вершины~$a$:
\begin{equation}
    \label{eq:upperConnectivity}
    u(a)
    =
    \#\bigl\{
        x_{ab}\in \XX \colon  a\prec b
    \bigr\}.
\end{equation}
\end{Def}
\begin{Def}
\label{def:inferiority}
\emph{Неполноценностью $q(a)$} алгоритма ${a\in A}$
называют число объектов~$x\in\XX$, на~которых алгоритм~$a$ ошибается,
при том, что существует алгоритм $b\in A$, лучший, чем~$a$ (то~есть $b<a$),
не~ошибающийся на~$x$:
\begin{equation}
    \label{eq:inferiority}
    q(a) = \#\{x\in \XX \bigm| \exists b\in A\colon I(b,x)<I(a,x),\; b\leq a\}
\end{equation}
\end{Def}
В~терминах графа расслоения"=связности $q(a)$ равно числу различных объектов~$x_{bc}$,
соответствующих всевозможным ребрам $(b,c)$ на~путях, ведущих к~вершине~$a$.

\begin{Example}
    На рис.~\ref{fig:SC-graph-monotonic-net-2D-example} показан пример
    вычисления верхней связности и~неполноценности алгоритма по~графу расслоения"=связности.
\end{Example}

\begin{figure}[t]
    \begin{center}
        \includegraphics[width=80mm,height=48mm]{Pictures/SC-graph-3a.eps}
        \caption{\small Пример двумерной сети алгоритмов.
            Для алгоритма~$a$
            верхняя связность $u(a) = \#\{ \mathit{x3,x4} \} = 2$,
            неполноценность $q(a) = \#\{ \mathit{x1,x2} \} = 2$.
        }
        \label{fig:SC-graph-monotonic-net-2D-example}
    \end{center}
\end{figure}

\begin{Theorem}[SC-оценка~\cite{voron11premi}]
\label{th:QEps-SC-bound}
    Пусть метод обучения ~$\mu$ является пессимистическим МЭР. Тогда для любого $\eps\in[0,1]$
    вероятность переобучения ограничена взвешенной суммой FC-оценок по~множеству~$A$:
    \begin{equation}
    \label{eq:QEps-SC-bound}
        Q_\eps(\mu,\XX)
        \leq
        \sum_{a\in A}
            \frac{\CC_{L-u-q}^{\ell-u}}{\CC_{L}^{\ell}}
            \Hyper{L-u-q}{m-q}{\ell-u}{\tfrac\ell L (m - \eps k)},
    \end{equation}
    где $m = n(a,\XX)$,
    $u = u(a)$ "--- верхняя связность, $q = q(a)$ "--- неполноценность алгоритма~$a$.
\end{Theorem}
SC-оценка~\eqref{eq:QEps-SC-bound} превращается в~VC-оценку~\eqref{eq:QEps-VC-bound},
если положить все $q(a)$ и~$r(a)$ равными нулю.
Вес
$P_a = {\CC_{L-u-q}^{\ell-u}} \big/ {\CC_{L}^{\ell}}$
в~сумме~\eqref{eq:QEps-SC-bound}
соответствует верхней оценке на~вероятность
$\Prob[\mu X = a]$
получить алгоритм~$a$ в~результате обучения.
Эта величина уменьшается экспоненциально быстро с~ростом связности~$u(a)$ и~неполноценности~$q(a)$.
Таким образом, эффективное вычисление $Q_\eps(\mu, \XX)$ требует знаний не про все множество~$A$,
а~лишь про несколько нижних слоев~$A$.

Оценка расслоения"-связности $\eqref{eq:QEps-SC-bound}$ уточняет VC-оценку $\eqref{eq:QEps-VC-bound}$,
но в~ряде случаев остается завышенной.

\begin{Experiment}
Рассмотрим модельное множество $A = (a_1, a_2)$, состоящее из~двух алгоритмов.
Векторы ошибок подобраны так, что оба алгоритма допускают по~$m$ ошибок на~полной выборке,
а~хэммингово расстояние $\rho(a_1, a_2)$ равняется заранее фиксированному числу $d$.
На рис.~\ref{fig:EOF-pair} приведена зависимость медианы распределения $\Q(A)$
от~хэммингова расстояния между алгоритмами.
Видно, что переобучение увеличивается с~ростом~$\rho(a_1, a_2)$.
Вместе с~тем и~неполноценность, и~верхняя связность обоих алгоритмов данного множества равны нулю.
Таким образом, SC-оценка не~учитывает зависимость вероятности переобучения от~$\rho(a_1, a_2)$.
\end{Experiment}

\begin{figure}[t]
    \centering
%    \includegraphics[height=48mm]{overfit(rho).eps}
     \includegraphics[height=54mm]{Pictures/pair.eps}
    \caption{\small Зависимость медианы распределения $\Q$ от~хэммингова расстояния $d = \rho(a_1, a_2)$ между векторами ошибок пары алгоритмов. $L=100$, $\ell = 50$.}
    \label{fig:EOF-pair}
\end{figure}

Эффект сходства алгоритмов еще сильнее проявляется на~примере следующего модельного множества алгоритмов.

\begin{Definition}
Пусть $a_0$ "--- произвольный алгоритм с~$m$ ошибками, $r \leq m$ "--- натуральное число.
\emph{Центральным слоем хэммингова шара} называется модельное множество алгоритмов
\[
    B_r^m(a_0) = \{a \in \AA \colon \rho(a, a_0) \leq r \text { и~} n(a, \XX) = m\}.
\]
Данное множество состоит из~алгоритмов хэммингова шара радиуса $r$ с~центром в~$a_0$,
допускающих на~полной выборке столько же ошибок, сколько и~центр шара.
Вероятность переобучения $\Q(B_r^m(a_0))$ зависит только от~радиуса шара $r$ и~числа ошибок $n(a_0, \XX)$,
поэтому в~дальнейшем вместо $B_r^m(a_0)$ будет использоваться сокращенная запись $B_r^m$.
%Количество алгоритмов в~$B_r^m$ дается выражением $\sum \limits_{i = 0}^{\lfloor r / 2 \rfloor} C_m^i C_{L-m}^i$.
\end{Definition}

\begin{Experiment}
Исследуем вероятность переобучения $\Q(B_r^m)$ численно с~помощью метода Монте-Карло,
усреднив переобученность $\delta(\mu X, X)$ не~по всем $X \in \XXell$, а~по $10$ тыс. случайным подвыборкам.
Для сравнения мы рассмотрим еще одно модельное множество $R_n^m$, составленное из~$n$ алгоритмов, допускающих по~$m$ ошибок на~полной выборке.
Векторы ошибок всех алгоритмов из~$R_n^m$ сгенерированы случайно и~независимо.
В следующей таблице показано, при каком числе алгоритмов $n$ в~$R_n^m$ медианы распределений $\Q(R_n^m)$ и~$\Q(B_r^m)$ совпадают.
\begin{table}[t]
  \caption{\small Сравнение $|R_n^m|$ и~$|B_r^m|$ при $L=50$, $\ell=25$, $m=10$}
  \label{tab:QEps-Ball-Layer-vs-Random-Set}
  \begin{center}
    \begin{tabular}[t]{|c|c|c|c|c|}
    \hline
    $r$ & $|B_r^m|$ & $|R_n^m|$ & $EOF(\mu, \XX)$ & $\eps \colon \Q(B_r^m) = 0.5$ \\
    \hline
    2 & 401 & 2 & 0.079 & 0.320 \\
    4 & 35\,501 & 7 & 0.160 & 0.400 \\
    6 & 1\,221\,101 & 39 & 0.240 & 0.400 \\
    8 & 20\,413\,001 & 378 & 0.319 & 0.400 \\
    \hline
    \end{tabular}
  \end{center}
\end{table}
%\end{Example}

Из таблицы~\ref{tab:QEps-Ball-Layer-vs-Random-Set} видно, что всего семь алгоритмов со случайными векторами ошибок могут переобучиться так же сильно,
как и~множество из~десятков тысяч алгоритмов с~близкими векторами ошибок.
Таким образом, вероятность переобучения множества $B_r^m$ существенно зависит от~сходства алгоритмов.
\end{Experiment}

Основной задачей данной диссертационной работы является получение оценок,
одновременно учитывающих и~расслоение алгоритмов по~числу ошибок,
и~сходство алгоритмов внутри одного слоя.

\section{Основные выводы и~постановка задачи}

В комбинаторной теории оценок обобщающей способности изучается функционал вероятности переобучения.
Этот функционал основан на~принципе полного скользящего контроля и зависит как от~задачи, так и~от метода обучения.
Как исходный функционал вероятности переобучения, так и~все его оценки зависят только от~наблюдаемых величин,
таких как конечная генеральная выборка объектов или матрица ошибок алгоритмов.
В~большинстве комбинаторных оценок в~качестве метода обучения используется минимизация эмпирического риска.
Данный метод обучения позволяет исследовать такие явления, как сходство и~расслоение алгоритмов,
также изучаемые в~классической модели SLT.

Основной комбинаторной оценкой является оценка расслоения-связности.
Она является менее завышенной по~сравнению с~классическими оценками
и~успешно применяется для повышения качества логических алгоритмов классификации.
Вместе с~тем данная оценка не учитывает сходство алгоритмов внутри слоя алгоритмов с~равным числом ошибок.
Анализ и~устранение причин завышенности оценки расслоения-связности
являются основными целями данной диссертационной работы. 
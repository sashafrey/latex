\chapter[Вычислительные эксперименты на~реальных данных]{Вычислительные эксперименты\\на~реальных данных}
\label{chap:5}

\section{Эффективное вычисление SC-оценки}

В данном параграфе подробно разбирается вопрос о вычислении SC-оценки~\eqref{eq:QEps-SC-bound}
по~известной матрице ошибок алгоритмов~$A$.
Вопрос о том, как эффективно сгенерировать эту матрицу для реального семейства алгоритмов,
мы рассмотрим в~одном из~следующих параграфов.

Напомним, что для вычисления SC-оценки
необходимо для каждого алгоритма семейства найти
верхнюю связность (определение~\ref{def:upperConnectivity})
и~неполноценность (определение~\ref{def:inferiority}).

Будем называть алгоритм $s \in A$ \emph{истоком} в~множестве~$A$, если $s \leq a$ для всех $a \in A$.
Очевидно, что для вычисления неполноценности алгоритмов $q(a)$ достаточно сравнивать алгоритм~$a$ лишь с~истоками.
На практике количество истоков семейства на~порядки меньше полного числа алгоритмов,
поэтому предварительный поиск всех истоков позволяет эффективнее вычислять неполноценность алгоритмов.

Для вычисления верхней связности алгоритма $a \in A$ нужен эффективный способ находить все алгоритмы,
отличающиеся от~$a$ на~одном объекте.
Это легко сделать, если для каждого алгоритма построить полиномиальный хэш его вектора ошибок:
$h(a) = \sum\limits_{i=1}^L p^i I(a, x_i)$, где $p$ --- простое число, $p \neq 2$.
Этот хэш обладает полезным свойством: если два алгоритма $a, b \in A$ различаются на~одном объекте,
то~$h(a) - h(b) = p^i$ для некоторого $i$.
Построим для множества~$A$ хэш-контейнер (или бинарное дерево поиска),
используя данный полиномиальный хэш в~качестве ключа.
Тогда для поиска <<соседей>> алгоритма~$a$ достаточно просто проверить все числа из
$\{h(a) \pm p^i\}_{i = 1}^L$
на~принадлежность хэш-контейнеру.
При реализации можно вычислять не~сам хэш, а~величину $h(a) \mod 2^{64}$,
используя целочисленный тип данных и~разрешая переполнения.
Коллизию ключей в~хэш-контейнере можно просто игнорировать.
В отдельных случаях это может привести к~неточному вычислению верхней связности некоторых алгоритмов,
но для практических целей такой точности всегда достаточно.

Полезно реализовать вычисление оценки $Q_\eps(A) \leq \eta(\eps)$ сразу для вектора значений $\eps$.
Это помогает эффективнее обращать оценку $\Q(A) \leq \eta(\eps)$,
найдя $\max\limits_{\eps \in [0, 1)} \eta(\eps) \geq 0.5$.

\begin{algorithm}
\caption{Эффективное вычисление SC-оценки}
\label{alg:CalcScBound}
\begin{algorithmic}[1]
\REQUIRE Матрица ошибок алгоритмов~$A$; вектор $\eps_1, \dots, \eps_t$;
\ENSURE Вектор SC-оценок, посчитанных в~точках $E = \{\eps_1, \dots, \eps_t\}$.
\STATE $S := \text{НайтиИстоки}(A)$;
\LINEFORALL{$\eps \in E$}{положить $Q(\eps) := 0$;}
\FORALL{$a \in A$}
    \STATE $X_q := X_r := \emptyset$;
    \FORALL{$s \in S \text{\textbf{ таких, что} } s < a$}
        \STATE{$X_r := X_r \cup \{x \in \XX \colon I(a, x) = 1 \text{ и~} I(s, x) = 0\}$};
    \ENDFOR
    \FORALL{$b \in A \colon a \prec b$}
        \STATE{$X_q := X_q \cup \{x_{ab}\}$};
    \ENDFOR
    \STATE $H(0) := 0$; $m_a := n(a, \XX$;
    \FOR{$s = 1, \dots, m_a$}
        \STATE {\label{alg:CalcScBound11}} $H(s) := H(s - 1) + C_{m_a-|X_r|}^{s} C_{L-|X_q|-m_a}^{\ell - |X_q| - s} / C_{L}^{\ell}$;
    \ENDFOR
    \FORALL{$\eps \in E\text{\textbf{ таких, что }} m_a \geq \eps k$}
        \STATE {$Q(\eps) := Q(\eps) + H(\lfloor \tfrac{\ell}L (m - \eps k)\rfloor)$;}
    \ENDFOR
\ENDFOR
\RET $Q$
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{НайтиИстоки($A$)}
\label{algFindSources}
\begin{algorithmic}[1]
\ENSURE Множество истоков $S \subset A$.
\STATE $S := \emptyset$
\FORALL{$a \in A$} \label{forallA1}
    \LINEIF{$\exists s \in S \colon s < a$} {\GOTO{forallA1}}
    \STATE{исключить из~$S$ все $s \in S$ такие что $a < s$};
    \STATE $S := S \cup \{a\}$;
\ENDFOR
\RET $S$
\end{algorithmic}
\end{algorithm}

Наконец, отметим, что при вычислении биномиальных коэффициентов
полезно составить таблицу $\log n!$ при $n = 1, \dots, L$
и~использовать ее на~шаге~\ref{alg:CalcScBound11} алгоритма~\ref{alg:CalcScBound}.
Отметим, что биномиальный коэффициент $\CLl$ выходит за границы чисел двойной точности
уже при $L = 1030$, $\ell = L/2$.
Вместе с~тем каждое слагаемое вида $C_{m_a-r}^{s} C_{L-q-m_a}^{\ell - q - s} / C_{L}^{\ell}$ никогда не~превышает единицу.
Поэтому важно сперва вычислить логарифм всего выражения, и~лишь затем взять его экспоненту.

\section[Применение комбинаторных оценок к~логическим алгоритмам]{Применение комбинаторных оценок\\к~логическим алгоритмам}

В работах~\cite{ivahnenko11mmro,voron11premi}
был предложен критерий предсказанной информативности,
использующий SC-оценку для
повышения качества логических алгоритмов классификации.

В данной диссертационной работе предложен более эффективный
метод вычисления предсказанной информативности~\cite{frey12iip}.
В~отличие от~предыдущих работ,
не~производится никакого дополнительного перебора и~оценивания правил~---
оценки вычисляются только по~тем правилам, которые уже были построены в~процессе перебора.

\paragraph{Логические закономерности.}
Рассматривается стандартная постановка задачи классификации.
Задано множество объектов ${\XX=(x_i)_{i=1}^L}$,
описанных $n$~действительными признаками, ${x_i = (x_i^1,\ldots,x_i^n)}$;
каждому объекту~$x_i$ соответствует ответ~$y_i$ из~множества~$Y = \{-1, 1\}$.

\emph{Логическим правилом} называется конъюнкция пороговых предикатов~(термов) вида
\begin{equation}
\label{eq:Rule}
    r(x_i) \equiv r(x_i;c^1,\ldots,c^n)  = \prod_{j\in \omega} \bigl[ x_i^j \lessgtr_j c^j \bigr],
\end{equation}
\vskip-2ex\noindent
где
%$x = (x^1,\ldots,x^n) \in \RR^n$,\;
$\omega\subseteq\{1,\ldots,n\}$ --- подмножество признаков,\;
$\lessgtr_j$ "--- одна из~операций сравнения $\{\leq,\geq\}$,\;
$c^j$ "--- порог по~$j$"=му признаку.
Говорят, что правило~$r$ \emph{выделяет} объект~$x$, если~$r(x)=1$.

\emph{Логическая закономерность}~--- это правило, выделяющее
достаточно много~($p$) объектов выбранного класса~$y$ (положительных примеров)
и~приемлемо мало~($n$) объектов всех остальных классов (отрицательных примеров).
Для поиска закономерностей класса~$y$ по~обучающей выборке~${X \subset \XX}$
решается задача двухкритериальной оптимизации:
\begin{align*}
    p(r,X) &= \sum_{x_i\in X} \! r(x_i) \, [y_i = y ] \to \max_r;\\
    n(r,X) &= \sum_{x_i\in X} \! r(x_i) \, [y_i \neq y ] \to \min_r.
\end{align*}

Обычно эта задача сводится к~максимизации выбранного скалярного критерия информативности $H(p,n)$.
В~частности, это может быть точный тест Фишера~\cite{martin97exact},
энтропийный критерий, индекс Джини, тест~$\chi^2$, тест~$\omega^2$ и~другие~\cite{zagoruiko99methods}.
В~обзоре~\cite{furnkranz05rocnrule} приведено более 20~критериев,
но~ни один из~них не~является безусловно лучшим.

Для поиска закономерностей применяются методы дискретной оптимизации:
жадные алгоритмы с~последующий редукцией правил~\cite{cohen99simple},
поиск в~ширину~\cite{lbov81methods},
генетические алгоритмы~\cite{Yankovskaya2007b},
асимптотически оптимальные алгоритмы~\cite{Inyakin2008}
и~другие.

Выбор функционала информативности и~метода его оптимизации является эвристикой.

\paragraph{Переобучение закономерностей.}
На~практике часто приходится наблюдать эффект переобучения закономерностей~---
на~независимой контрольной выборке
пропорция числа положительных~$p'$ и~отрицательных~$n'$ примеров,
как правило, смещается в~нежелательную сторону:
${n'/p' > n/p}$.
Для сокращения переобучения в~\cite{ivahnenko11mmro,voron11premi}
предлагается использовать функционал \emph{предсказанной информативности}.
Это обычный функционал информативности~$H$,
в~который вместо величин~$p$,~$n$ на~известной обучающей выборке
подставляются оценки соответствующих величин~$p'$,~$n'$ на~неизвестной контрольной выборке,
\[
    \tilde H(p,n)
    %= H(\hat p', \hat n')
    = H(p-\delta',n+\delta''),
\]
где $\delta'$ и~$\delta''$~--- поправки на~переобучение,
получаемые из~комбинаторных оценок вероятности переобучения.
Преимущество данного подхода в~том, что
он~совместим с~любыми функционалами информативности и~любыми алгоритмами поиска закономерностей,
поэтому его можно встраивать в~стандартные библиотеки.
Эксперименты на~6~реальных задачах классификации из~репозитория~UCI показывают, что
максимизация предсказанной информативности улучшает обобщающую способность
двух типов композиций закономерностей~---
взвешенного голосования и~решающего списка (голосования по~старшинству)~\cite{voron11premi}.

В~то~же время, недостатком предложенного в~\cite{voron11premi} алгоритма
является относительно низкая численная эффективность.
Чтобы вычислить вероятность переобучения для заданного набора признаков,
приходится перебирать все конъюнкции,
находящиеся в~некоторой окрестности выбранной оптимальной конъюнкции.
При этом размер окрестности увеличивается экспоненциально
с~ростом числа признаков (ранга конъюнкции).
Кроме того, в~\cite{voron11premi} предполагается, что
значения каждого признака попарно различны на~объектах выборки.

В~работе~\cite{frey12iip} предлагается ряд упрощений,
повышающих численную эффективность и~расширяющих границы применимости
метода максимизации предсказанной информативности.
Во"~первых, в~оценках вероятности переобучения не~учитывается связность,
что позволяет применять их для признаков любых типов.
Во"~вторых, вместо полного перебора конъюнкций по~специально построенной окрестности
применяется сокращенный перебор только по~тем конъюнкциям,
для которых в~процессе поиска закономерностей было вычислено значение информативности.
%В~результате
%оценки вероятности переобучения становятся менее точными, причем
%пренебрежение связностью завышает их,
%а~сокращение числа конъюнкций~--- занижает.
%Как будет показано ниже,
%наложение этих двух противоположных тенденций
%в~итоге
Данный подход
приводит к~улучшению обобщающей способности логических закономерностей
по~сравнению с~\cite{voron11premi}.

\paragraph{Оценки вероятности переобучения для логических закономерностей.}

Правило~$r$ класса~${y\in Y}$ индуцирует на~$\XX$ бинарный вектор ошибок
$\bigl( I(r, x_i) \bigr){}_{i=1}^L$,
где
$I(r, x_i) = \bigl[ r(x_i) \neq [y_i{=}y] \bigr]$~---
индикатор ошибки правила $r$ на~объекте $x_i$.
Как и~в~прошлых параграфах,
\emph{число} и~\emph{частота} ошибок правила~$r$ на~выборке~$X \subseteq \XX$ обозначаются, соответственно, через
$m(r,X) = \sum\limits_{x_i\in X} I(r, x_i)$ и
$\nu(r,X) = \frac{m(r,X)}{|X|}$.
%Пусть множество объектов~$\XX$ разбито две непересекающиеся подвыборки:
%обучающую~$X$ длины~$\ell$ и~контрольную~$\X$ длины ${k=L-\ell}$.
\emph{Методом обучения} называется отображение,
которое произвольной обучающей выборке ${X\subseteq \XX}$
ставит в~соответствие некоторое правило ${r = \mu X}$.

Метод обучения~$\mu$ называется \emph{монотонным}, \mbox{если}
${\mu X = \mathrm{arg}\min_{r} K(r,X)}$,
где критерий $K(r,X)$~--- строго монотонная функция вектора ошибок:
для любой пары правил $r,v$ и~любой выборки ${X\subset\XX}$
\mbox{если} ${I(r,x_i) \leq I(v,x_i)}$ для всех ${x_i\in X}$
и~хотя бы одно из~неравенств строгое,
то~${K(r,X) < K(v,X)}$.

В работе~\cite{ivahnenko11mmro} доказано, что SC-оценка~\eqref{eq:QEps-SC-bound} выполнена не~только для ПМЭР,
но и~для любого монотонного метода обучения.
Кроме этого, оказывается, что если функция $H(p,n)$
строго монотонно возрастает по~$p$
и~строго монотонно убывает по~$n$, то~критерий
$K(r,X) = -H\bigl( p(r,X), n(r,X) \bigr)$
является монотонным,
а~максимизация информативности~--- монотонным методом обучения.
Все используемые на~практике критерии
обладают свойством монотонности в~указанном смысле.

Пусть $R$~--- некоторое множество правил.
Тогда, согласно SC-оценке, для любого монотонного метода обучения и~любой выборки~$\XX$
справедлива оценка
\begin{equation}
    \label{eq:SC-bound-rules}
    Q_\eps(\mu,\XX)
    \leq
    \sum_{r\in R}
        \frac{\CC_{L-u-q}^{\ell-u}}{\CC_{L}^{\ell}}
        \Hyper{L-u-q}{m-q}{\ell-u}{\tfrac\ell L (m - \eps k)} \equiv \eta(\eps),
\end{equation}
где $m = n(r,\XX)$,
$u = u(r)$ "--- верхняя связность~\eqref{eq:upperConnectivity},
$q = q(r)$ "--- неполноценность~\eqref{eq:inferiority} правила~$r$.

Пусть $\eps(\eta)$~--- функция, обратная к~$\eta(\eps)$.
Тогда справедливо утверждение, эквивалентное неравенству~\eqref{eq:SC-bound-rules}:
с~вероятностью не~менее $1-\eta$
\[
    \nu(r, \X) \leq \nu(r, X) + \eps(\eta).
\]
Для контроля переобучения правил эту оценку необходимо обобщить,
чтобы она учитывала ошибки первого и~второго рода.
Введем множества положительных и~отрицательных примеров:
%\begin{align*}
\[
    \XX'  = \{x_i \in \XX \colon y_i = y\};
    \quad
    \XX'' = \{x_i \in \XX \colon y_i \neq y\}.
\]
%\end{align*}
Также введем индикаторы ошибки I и~II рода:
\begin{align*}
    I' (r, x) &= [r(x_i) = 0][y_i = y];\\
    I''(r, x) &= [r(x_i) = 1][y_i \neq y].
\end{align*}
Число и~частоту ошибок относительно этих индикаторов обозначим через
$m'(r, X)$, $m''(r, X)$, $\nu'(r, X)$ и~$\nu''(r, X)$ соответственно.

Следующие формулы являются обобщением оценки~\eqref{eq:SC-bound-rules}.
Для любого монотонного метода обучения справедливы оценки вероятности переобучения
по~ошибкам первого и~второго рода:
\begin{align*}
    \label{eq:SC-bound-rules-separate}
     Q'_\eps(\mu,\XX)
        \leq
        \sum_{r\in R}
            \frac{\CC_{L-u-q}^{\ell-u}}{\CC_{L}^{\ell}}
            \Hyper{L-u-q}{m'-q'}{\ell-u}{\tfrac\ell L (m' - \eps k)} \equiv \eta''(\eps); \\
     Q''_\eps(\mu,\XX)
        \leq
        \sum_{r\in R}
            \frac{\CC_{L-u-q}^{\ell-u}}{\CC_{L}^{\ell}}
            \Hyper{L-u-q}{m''-q''}{\ell-u}{\tfrac\ell L (m'' - \eps k)} \equiv \eta''(\eps);
\end{align*}
где ${u = u(r)}$ --- верхняя связность относительно индикатора ошибки $I$,
${q = q(r)}$, ${q' = q'(r)}$, ${q'' = q''(r)}$~---
неполноценность правила $r$ относительно индикаторов ошибки $I$, $I'$, $I''$, соответственно;
${m' = m'(r, \XX')}$ и~${m'' = m''(r, \XX'')}$ "--- число ошибок $r$ на~$\XX$ относительно индикаторов ошибки $I'$, $I''$.

\paragraph{Критерий предсказанной информативности.}
Пусть $H(p, n)$ "--- критерий информативности, монотонный по~$p$ и~$n$.
Обозначим через $\eps'(\eta)$ и~$\eps''(\eta)$
функции, обратные к~$\eta'(\eps)$ и~$\eta''(\eps)$.
В~новых обозначениях число положительных и~отрицательных примеров
во~всей выборке~$\XX$ равны, соответственно,
${p = |\XX'| - m'(r,\XX)}$ и
${n = m''(r,\XX)}$
Возьмем в~качестве поправок на~переобучение медианные оценки частоты ошибок на~контроле,
получаемые при $\eta=0.5$:
\begin{equation}
\label{eq:Hpn}
    \tilde H(p, n)
    = H\bigl(
        p - L \eps'(0.5),\:
        n + L \eps''(0.5)
    \bigr).
\end{equation}

Полученная оценка не~накладывает никаких ограничений на~то,
как именно выбирается множество правил~$R$.
Оценки расслоения--связности, использованные в~\cite{voron11premi},
довольно жестко предполагали, что $R$~--- это множество всех правил,
получаемых при фиксации набора признаков~$\omega$, фиксации знаков неравенств~$\lessgtr_j$
и~варьировании порогов~$c^j$.
В~этом случае максимизация предсказанной информативности $\tilde H(p, n)$
может использоваться только в~качестве критерия отбора признаков~$\omega$.

Теперь же можно ввести более общее представление процесса поиска закономерностей,
считая, что он разбит на~\emph{стадии}.
На~каждой стадии просматривается некоторое множество правил~$R$ и~из них выбирается лучшее.
Критерий~$\tilde H$ предсказывает,
какую информативность выбранное правило будет иметь на~новых данных.
Для этого используется все множество правил~$R$, учитывается его сложность и~расслоение.
Таким образом,
критерий~$\tilde H$ позволяет правильно отранжировать правила, полученные на~разных стадиях,
но~не~позволяет сделать правильный выбор внутри каждой стадии.
В~работе~\cite{frey12iip} для~вычисления поправок на~переобучение правила~$r$
в~качестве множества~$R$ использовались все правила того~же целевого класса, что~и~$r$,
построенные алгоритмом поиска закономерностей для~признаков, входящих в~состав~$r$.

\begin{algorithm}[t]
\caption{ComBoost (Committee Boosting).}
\label{alg:comboost}
\begin{algorithmic}
\REQUIRE
   ~$X$~--- обучающая выборка;
    $T, l_0, l_1$~--- параметры;
\ENSURE композиция правил $a_T = (r_1, \dots, r_T)$.
\BEGIN
\STATE
    инициализировать выборку $X'$ и~отступы:
    $X' := X$;\; $M_i := 0$, $i = 1, \dots, \ell$;
\FORALL{$t = 1, \dots, T$}
    \STATE обучить правила $r^y_t$,\; ${y \in Y}$ по~выборке $X'$;
    \STATE $(r_t,y_t) := \argminCompact_{(r^y_t,y)\colon y\in Y} \; \sum \limits_{x_i \in X'} [a_t(x_i) \neq y_i]$;
    \STATE обновить значения отступов:
        $M_i := M_i + y_t y_i r_t(x_i)$,\; $i = 1, \dots, \ell$;
    \STATE упорядочить выборку~$X$ по~возрастанию $M_i$;\\
    \STATE $X' := \{x_i \in X \colon \ell_0 < i \leq \ell_1\}$.
\ENDFOR
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[t]
\caption{Усеченный поиск в~ширину.}
\label{alg:QuasiTemp}
\begin{algorithmic}
\REQUIRE
   ~$X$~--- обучающая выборка;\\
    $\Theta$~--- семейство термов;\\
    $M$~--- максимальный ранг конъюнкции;\\
    $S_1$ "--- параметр ширины поиска;
\ENSURE $R$~--- набор правил.
\BEGIN
    \STATE инициализация: $R := \emptyset$, $R_0 := \{\emptyset\}$;
    \FOR{$m=1,\dots,M$}
        \STATE $R_m := \emptyset$;
        \FORALL{$r \in R_{m-1}$}
            \STATE нарастить правило $r$ термами $t$:\\
                $R_m := R_m \, \bigcup \, \{r \wedge t \colon t\in\Theta \text{ допустим для } r \}$;
        \ENDFOR
        \STATE выбрать в~$R_m$ целевые классы;
        \STATE по~критерию $\tilde H$ оставить в~$R_m$ не~более $S_1$ лучших правил за каждый класс;
        \STATE сохранить правила: $R := R \cup R_m$;
    \ENDFOR
    \RET $R$;
\end{algorithmic}
\end{algorithm}

\paragraph{Композиция закономерностей.}

\emph{Простое голосование}~---
это один из~стандартных способов построения композиции вида
\begin{equation}
\label{eq:SimpleVoting}
    a_t(x) = \sign \biggl(\sum_{r \in R_{+1}} \!\! r(x) - \sum_{r \in R_{-1}} \!\! r(x) \biggr),
\end{equation}
состоящей из~$t= |R_{-1}|+|R_{+1}|$ логических закономерностей,
где $R_y$ "--- множество закономерностей класса~$y$.
Для обучения композиции~\eqref{eq:SimpleVoting}
используется комитетный бустинг
ComBoost~\cite{matsenov07mmro}.
В~отличие от~других разновидностей бустинга,
он не~взвешивает объекты выборки, а~только отбирает подвыборки.
Поэтому к~методу обучения базовых закономерностей
применимы комбинаторные оценки переобучения,
существующие только для бинарных функций потерь.
Другое важное преимущество ComBoost в~том, что,
благодаря явной оптимизации распределения отступов,
он стремится набрать минимальное достаточное число базовых закономерностей.

\begin{table}[t]
 % \centering
%  \footnotesize
 % \tabcolsep=5pt
  \caption{\small Средняя частота ошибок (в~процентах) на~обучающей и~тестовой выборке
    по~различным задачам и~различным методом контроля переобучения.}
  \label{tab:ComBoostResults}
      \centering
    \begin{tabular}[t]{||l|r|r|r|r|r|r||}
    \headline
           & \multicolumn{2}{c|}{ComBoost-C}  & \multicolumn{2}{c|}{ComBoost-B} & \multicolumn{2}{c||}{ComBoost-A}\\
    \headline
    задача     & обуч. & тест & обуч. & тест & обуч. & тест \\
    \headline
    australian  &6.8    &14.0   &9.9    &14.9   &6.2    &\textbf{13.8}\\
    echo-card   &0.1    &2.3    &0.2    &\textbf{0.9}    &0.1    &2.4\\
    german      &13.1   &\textbf{25.4}   &18.3   &27.6   &12.9   &26.0\\
    heart dis.  &8.0    &18.9   &11.1   &\textbf{18.5}   &7.6    &19.3\\
    hepatitis   &3.0    &19.9   &7.8    &\textbf{18.0}   &1.8    &21.4\\
    labor       &0.6    &\textbf{8.9}    &1.1    &11.9   &0.5    &10.9\\
    liver       &11.3   &\textbf{31.4}   &33.0   &42.7   &8.3    &32.3\\
    \hline
    \end{tabular}
\end{table}

На~шаге~3 алгоритма~\ref{alg:comboost} для каждого класса~$y$
применяется алгоритм~\ref{alg:QuasiTemp} поиска информативных правил,
аналогичный алгоритму ТЭМП~\cite{lbov81methods}.

На~шаге~5 алгоритма~\ref{alg:QuasiTemp} допустимыми для добавления считаются термы,
не~содержащие признаков, которые уже вошли в~правило~$r$.

\paragraph{Результаты экспериментов.}
В эксперименте~\cite{frey12iip} на~семи реальных задачах классификации из~репозитория UCI
сравнивались три варианта ComBoost
с~точным тестом Фишера в~качестве критерия информативности:
\begin{enumerate}
    \item[A:] без поправок на~переобучение;
    \item[B:] с~поправками по~предложенному методу~\eqref{eq:Hpn};
    \item[C:] с~поправками по~эмпирической оценке $Q(\eps)$,
вычисляемой методом Монте-Карло по~случайному подмножеству разбиений.
\end{enumerate}
Для упрощения комбинаторных оценок верхняя связность искусственно полагалась равной нулю во всех экспериментах.

Результаты эксперимента приведены в таблице \ref{tab:ComBoostResults}.
Во всех задачах, кроме australian,
варианты B~и~C дают лучшее качество классификации тестовых данных.
Для упрощения комбинаторные оценки вычислялись неточно,
и~в~некоторых случаях вариант~B лучше варианта~C.
На~пяти из~семи задач вариант~B дал лучшие результаты,
чем в~\cite{voron11premi},
несмотря на~то, что он не~учитывает эффект связности.
Во~всех задачах вариант~B имеет существенно меньшую переобученность~---
разность частоты ошибок между тестовой и~обучающей выборками.

%для поиска логических закономерностей в~задачах классификации.
%Замена обычного критерия информативности на~предсказанную информативность
%может быть выполнена для любого стандартного метода поиска закономерностей,
%независимо от~вида критерия и~механизма перебора правил.

%Улучшение обобщающей способности достигается благодаря
%комбинаторным оценкам вероятности переобучения,
%учитывающим эффект расслоения семейства правил.

\section{Проблема сэмплирования алгоритмов}

Для вычисления SC-оценки с~помощью алгоритма~\ref{alg:CalcScBound}
требуется в~явном виде построить матрицу ошибок алгоритмов~$A$.
В прошлом параграфе этой проблемы удалось избежать,
поскольку используемый метод поиска логических закономерностей
просматривал в~процессе своей работы большое число промежуточных решений.
Именно множество этих решений и~было использовано для вычисления SC-оценки.

В остальных случаях множество~$A$ приходится генерировать.
Как было показано в~\cite{kochedykov09mmro},
Для широко используемого класса линейных алгоритмов классификации
все множество~$A$ может состоять из~огромного числа алгоритмов (до $10^9$, и~даже выше),
поэтому на~практике возникает проблема выбора небольшого подмножества (вплоть до~$10^4$ алгоритмов),
позволяющего достаточно точно восстановить оценку переобучения~\eqref{eq:QEps}.
В работе~\cite{esokolov12iip} для построения множества алгоритмов
предлагается метод случайных блужданий по~графу расслоения-связности.
Основные вычислительные затраты метода были связаны с~трудоемкостью поиска всех соседей
алгоритма на~графе расслоения-связности.
В данной диссертационной работе предлагается более
эффективный способ организовать такое случайное блуждание \cite{voron12jmlda-eng}.
Для этого вместо поиска всех соседей алгоритма предлагается производить поиск вдоль случайно выбранного направления.

Пусть объекты $\{x_i\}_{i=1}^L$ описаны вещественными признаками: $x_i \in \RR^d$, $i = 1,\dots,L$.
Пусть каждому объекту $x_i$ однозначно соответствует один из~двух возможных классов $y_i \in \{-1, +1\}$.
Рассмотрим множество несмещенных линейных классификаторов $a(x; w) = \sign \langle w, x \rangle$,
где $w \in \RR^d$ задает вектор весов признаков.
Пусть $\XX = \{(x_i, y_i)\}_{i=1}^L$ "--- генеральная выборка объектов.
Будем говорить, что алгоритмы $(w_1, w_2)$ являются \emph{соседями},
если они по-разному классифицируют лишь один объект
(т.~е. $\exists ! x \in \XX$, такой что $\sign(\langle w_1, x \rangle) \cdot \sign(\langle w_2, x \rangle) = -1$).

Для произвольного алгоритма $w_0$ опишем метод поиска его соседей.
В дальнейшем этот метод будет использован,
чтобы организовать случайное блуждание по~графу расслоения-связности.

\paragraph{Поиск соседних алгоритмов вдоль заданного направления.}
\emph{Преобразование двойственности} $D$ отображает точку ${x \in \RR^d}$ в~гиперплоскость
${D(x) = \{w \in \RR^d \colon \langle w, x \rangle = 0\}}$,
и~наоборот, гиперплоскость
${h = \{x \in \RR^d \colon \langle w, x \rangle = 0\}}$
отображается в~точку $D(h) = w$.
Каждая гиперплоскость $h_i = D(x_i)$ разделяет~$\RR^d$ на~два полупространства:
\begin{align*}
    h_i^+ &= \{w \in \RR^d \colon \sign \langle w, x_i \rangle = y_i\},
    \\
    h_i^- &= \{w \in \RR^d \colon \sign \langle w, x_i \rangle = -y_i\},
\end{align*}
таких что в~$h_i^+$ все алгоритмы классифицируют объект $x_i$ правильно,
а~в~$h_i^-$ "--- неправильно.
Применив преобразование $D$ ко всей генеральной выборке ${\XX \subset \RR^d}$,
получим набор гиперплоскостей ${\HH \equiv \{D(x_i)\}_{i=1}^{L}}$.
Эти гиперплоскости разбивают пространство всех алгоритмов $\RR^d$ на~конусы, называемые \emph{ячейками конфигурации}~\cite{agarwal98arrangements}.
При этом оказывается, что в~каждой ячейке конфигурации все алгоритмы имеют равный вектор ошибок.
Тем самым задача поиска соседних алгоритмов сводится к~поиску соседних ячеек конфигурации.

Для поиска алгоритма, соседнего с~$w_0$, предлагается выбрать произвольный вектор $u \in \RR^d$
и~рассмотреть однопараметрическое семейство алгоритмов $\{w_0 + t u \colon t \geq 0\}$.
Этому семейству соответствует луч в~пространстве алгоритмов, выходящий из~$w_0$ в~направлении $u$.
Пересечение этого луча с~плоскостью $h_i \in \HH$ определяется условием $\langle w_0 + t u, x_i\rangle = 0$,
т.~е. происходит при значении $t_i = - \frac{\langle w_0, x_i\rangle}{\langle u, x_i\rangle}$.
Пусть $t_{(1)}$ и~$t_{(2)}$ являются первым и~вторым минимальным положительным значением из~множества $\{t_i\}$, $i = 1, \dots, L$.
Легко понять, что алгоритм $w' = w_0 + \frac{1}{2}(t_{(1)} + t_{(2)}) u$ является соседним с~$w_0$.

\paragraph{Случайное блуждание на~графе расслоения-связности.}
Техника случайных блужданий ~\cite{avrachenkov2010restarts, ribeiro2010multidimensional}
является общепринятым методом сэмплирования вершин из~больших графов.
В нашем случае случайные блуждания будут использованы, чтобы оценить вероятность переобучения
по~формулам~\eqref{eq:QEps},~\eqref{eq:QEps-VC-bound} или~\eqref{eq:QEps-SC-bound}.
При блужданиях будет применяться описанная выше процедура поиска случайного соседа алгоритма $w \in A$.

\begin{algorithm}[t]
\caption{Случайное блуждание на~графе расслоения-связности}
\label{alg:walking}
\begin{algorithmic}[1]
\REQUIRE начальная точка $w_0$; выборка $\XX \subset \RR^d$; параметры $N, m, n \in \NN$, $p \in (0, 1]$;
\ENSURE множество алгоритмов~$A$ с~попарно-различными векторами ошибок

\STATE Инициализация: $v_i = w_0$, $i = 1, \dots, N$;
\STATE $A := \emptyset$;
\WHILE{$|A| < n$}
    \FORALL{$i \in 1, \dots, N$} \label{alg:walking3}
        \STATE найти соседа $v'_i$ для $v_i$ вдоль случайного направления $u \in \RR^d$;
        \IF{$n(v'_i, \XX) > n(v_i, \XX)$}
            \STATE с~вероятностью $(1 - p)$ \GOTO{alg:walking3}
        \ELSIF{$n(v'_i, \XX) > n(w_0, \XX) + m$}
            \STATE \GOTO{alg:walking3}
        \ENDIF
        \STATE $v_i := v'_i$;
        \STATE $A := A \cup v_i$;
    \ENDFOR
\ENDWHILE
\RET~$A$
\end{algorithmic}
\end{algorithm}

Алгоритм~\ref{alg:walking} управляется следующими параметрами:
$n$ "--- критерий останова по~числу алгоритмов,
$m$ "--- ограничение на~число рассматриваемых слоев алгоритмов,
$N$ "--- число одновременных блужданий,
$p$ "--- вероятность перехода к~алгоритму с~большим числом ошибок.
Вычислительная сложность алгоритма равна $O(L d n)$.

\begin{figure}[t]
\centering
\begin{multicols}{2}
    \hfill
    \includegraphics[width=0.98\linewidth]{Pictures/RW_maps_pTransition_1.eps}
    \hfill
    \caption{\small Карта хэммингова расстояния между алгоритмами (верхний график)
        и~профиль числа ошибок (нижний график) для простого блуждания ($p=1.0$)}
    \label{fig:rwMappingSimple}
    \hfill
    \includegraphics[width=0.98\linewidth]{Pictures/RW_maps_pTransition_05.eps}
    \hfill
    \caption{\small Карта хэммингова расстояния между алгоритмами (верхний график)
        и~профиль числа ошибок (нижний график) для блуждания при $p = 0.5$.}
    \label{fig:rwMappingPTransition}
\end{multicols}
\end{figure}

Рис.~\ref{fig:rwMappingSimple} соответствует $n = 2000$ шагам простого блуждания ($p = 0$).
На нижнем графике показано число ошибок $n(v_i, \XX)$ как функция от~номера шага.
На верхнем графике показана цветовая карта хэммингова расстояния $\rho(v_i, v_j)$.
В качестве начального приближения использовался алгоритм, настроенный логистической регрессией.
Естественно ожидать, что данный алгоритм имеет меньше ошибок, чем случайно выбранный алгоритм,
поэтому при простом случайном блуждании число ошибок быстро смещается вверх.
Этот эффект является нежелательным, поскольку наибольший вклад в~SC-оценку вносят
алгоритмы с~наименьшим числом ошибок.

На рис.~\ref{fig:rwMappingPTransition} аналогичные результаты представлены для случайного блуждания,
в~котором переход к~алгоритму с~большим числом ошибок производится с~вероятностью $p = 0.5$.
Благодаря этому случайное блуждание остается в~нижних слоях графа расслоения-связности.

\section[Прогноз кривых обучения логистической регрессии]{Прогноз кривых обучения логистической\\регрессии}

В данном параграфе приводятся результаты численного эксперимента из~работы~\cite{voron12jmlda-eng}.
Основные цели эксперимента заключались в~следующем:
\begin{itemize}
    \item проверить, что метод случайного блуждания по~графу расслоения-связности дает репрезентативную выборку алгоритмов, достаточную для вычисления оценок переобучения;
    \item проверить, что комбинаторное определение вероятности переобучения $Q_\eps(\mu,\XX)$~\eqref{eq:QEps}
    и~средней ошибки $\bar\nu_\ell(\mu,\XX)$~\eqref{eq:avgTestNu} дают разумные оценки,
    сравнимые с~фактическим переобучением используемых на~практике методов обучения (таких как, например, логистическая регрессия).
\end{itemize}
%The results confirm that our approach provides sharp estimates of overfitting,
%which correlate with the actual overfitting,
%recovers a correct shape of the learning curves,
%and outperform the state-of-art PAC-bayesian bounds.

\begin{table}[t]
\caption{\small Описание задач}
\label{tab:datasets}
    \centering
    \begin{tabular}[t]{||c|c|c||c|c|c||}
    \hline
    Задача&\#Объектов&\#Признаков&Задача&\#Объектов&\#Признаков \\
\hline
    Sonar      & 208   & 60 & Statlog    & 2310  & 19 \\
    Glass      & 214   &  9 & Wine       & 4898  & 11 \\
    Liver dis. & 345   &  6 & Waveform   & 5000  & 21 \\
    Ionosphere & 351   & 34 & Pageblocks & 5473  & 10 \\
    Wdbc       & 569   & 30 & Optdigits  & 5620  & 64 \\
    Australian & 690   &  6 & Pendigits  & 10992 & 16 \\
    Pima       & 768   &  8 & Letter     & 20000 & 16 \\
    Faults     & 1941  & 27 &            &       &    \\
\hline
\end{tabular}
\end{table}

В эксперименте было использовано 15 задач из~репозитория UCI~\cite{blake98uci}.
Описание задач приводится в~таблице~\ref{tab:datasets}.
Для многоклассовых задач целевые метки были вручную сгруппированы в~два класса.
К каждому признаку задачи применялось линейное преобразование так,
чтобы все значения признака попали в~интервал $[0, 1]$.

\begin{figure}[t]
    \begin{tabular}{ccc}
        \includegraphics[width=0.40\textwidth]{Pictures/pac_Sonar.eps} &
        \includegraphics[width=0.40\textwidth]{Pictures/pac_glass.eps} \\
        Sonar &
        Glass \\
        \includegraphics[width=0.40\textwidth]{Pictures/pac_Liver_Disorders.eps} &
        \includegraphics[width=0.40\textwidth]{Pictures/pac_Ionosphere.eps} \\
        Liver Dis. &
        Ionosphere \\
        \includegraphics[width=0.40\textwidth]{Pictures/pac_Wdbc.eps} &
        \includegraphics[width=0.40\textwidth]{Pictures/pac_Australian.eps} \\
        Wdbc &
        Australian \\
        \includegraphics[width=0.40\textwidth]{Pictures/pac_pima.eps} &
        \includegraphics[width=0.40\textwidth]{Pictures/pac_faults.eps} \\
        Pima &
        Faults \\
    \end{tabular}
    \caption{\small Кривые обучения логистической регрессии и~ПМЭР.
        Частота ошибок логистической регрессии оценена методом Монте-Карло
        на~разбиениях исходной задачи~$\XX = \XX_L \cup \XX_K$.
        Частота ошибок ПМЭР оценена по~разбиениям обучающей выборки~$\XX_L = X_\ell \cup X_k$.
        Продолжение на~с.~\pageref{fig:LearningCurves2}.}
    \label{fig:LearningCurves1}
\end{figure}

\begin{figure}[t]
    \begin{tabular}{ccc}
        \includegraphics[width=0.40\textwidth]{Pictures/pac_statlog.eps} &
        \includegraphics[width=0.40\textwidth]{Pictures/pac_wine.eps} \\
        Statlog &
        Wine \\
        \includegraphics[width=0.40\textwidth]{Pictures/pac_waveform.eps} &
        \includegraphics[width=0.40\textwidth]{Pictures/pac_pageblocks.eps} \\
        Waveform &
        Pageblocks \\
        \includegraphics[width=0.40\textwidth]{Pictures/pac_Optdigits.eps} &
        \includegraphics[width=0.40\textwidth]{Pictures/pac_pendigits.eps} \\
        Optdigits &
        Pendigits \\
        \multicolumn{2}{c}{ \includegraphics[width=0.40\textwidth]{Pictures/pac_Letter.eps} } \\
        \multicolumn{2}{c}{  Letter } \\
    \end{tabular}
    \caption{\small Кривые обучения логистической регрессии и~ПМЭР. Начало на~с. \pageref{fig:LearningCurves1}.}
    \label{fig:LearningCurves2}
\end{figure}

В эксперименте сравниваются спрогнозированные и~фактические кривые обучения логистической регрессии.
Для этого исходная задача $\XX$ разбивается на~обучающую выборку $\XX_L$ и~контрольную выборку $\XX_K$.
Обучающая выборка $\XX_L$ используется для настройки логистической регрессии и~вычисления оценок переобучения.
Затем эти оценки сравниваются с~реальной частотой ошибок на~контрольной выборке $\XX_K$.

Параметр~$L$ варьировался в~пределах от~5\% до~95\% от~размера исходной задачи с~шагом в~5\%.
Для каждого значения~$L$ генерируется~$M = 100$ случайных разбиений
${\XX = \XX_L^i \cup \XX_K^i}$,\; ${i = 1, \dots, M}$,
по~которым с~помощью метода Монте-Карло оценивается
частота ошибок на~обучении~$\nu_L(\mu_\LR, \XX)$ (формула~\eqref{eq:avgTrainNu})
и~частота ошибок на~контроле~$\bar \nu_L(\mu_\LR, \XX)$ (формула~\eqref{eq:avgTestNu}),
где в~качестве метода обучения~$\mu_\LR$ выступает логистическая регрессия:
\[
    \hat \nu_L(\mu_\LR, \XX)
    =
    \frac{1}{M} \sum_{i = 1}^{M} \nu(\mu_\LR \XX_L^i, \XX_L^i),
    \qquad
    \hat{\bar \nu}_L(\mu_\LR, \XX)
    =
    \frac{1}{M} \sum_{i = 1}^{M} \nu(\mu_\LR \XX_L^i, \XX_K^i).
\]
По каждой обучающей выборке~$\XX_L$ производится сэмплирование множества алгоритмов,
а~также оценка средних ошибок ПМЭР
(ошибки на~обучении $\nu_\ell(\mu, \XX_L)$
и~ошибки на~контроле $\bar \nu_\ell(\mu, \XX_L)$,
где метод обучения $\mu$ соответствует ПМЭР).
Для сэмплирования множества алгоритмов по~выборке $\XX_L$ запускается алгоритм~\ref{alg:walking}
с~параметрами $n=8\,192$, $N = 64$, $m = 15$, $p = 0.8$,
а~в~качестве начального приближения используется алгоритм ~$\mu_\LR \XX_L$, настроенный логистической регрессией.
Для вычисления $\nu_\ell(\mu, \XX_L)$ и~$\bar \nu_\ell(\mu, \XX_L)$ вновь используется метод Монте-Карло,
оценивающий определения~\eqref{eq:avgTrainNu} и~\eqref{eq:avgTestNu}
по~$M' = 4\,096$ разбиениям $\XX_L = X_\ell^j \cup X_k^j$,
$j = 1, \dots, M'$, при $\frac{\ell}{L} = 0.8$:
\[
    \hat \nu_\ell(\mu, \XX_L)
    =
    \frac{1}{M'} \sum_{j = 1}^{M} \nu(\mu X_\ell^j, X_\ell^j),
    \qquad
    \hat{\bar \nu}_\ell(\mu, \XX_L)
    =
    \frac{1}{M'} \sum_{j = 1}^{M} \nu(\mu X_\ell^j, X_k^j).
\]
Затем эти оценки усредняются по~всем разбиениям~$\XX = \XX_L^i \cup \XX_K^i$.

Эти четыре значения
(фактическая частота ошибок логистической регрессии на~обучении $\nu_L(\mu_\LR, \XX)$
и~на~контроле $\bar \nu_L(\mu_\LR, \XX)$,
частота ошибок ПМЭР на~обучении $\nu_\ell(\mu, \XX_L)$,
частота ошибок ПМЭР на~контроле $\bar \nu_\ell(\mu, \XX_L)$)
приводятся на~рисунках~\ref{fig:LearningCurves1} и~\ref{fig:LearningCurves2} как функции числа объектов на~обучении.
Рисунки приводятся в~порядке возрастания числа объектов в~задачах.
Отметим, что частота ошибок ПМЭР на~контроле может быть как выше,
так и~ниже фактической частоты ошибок логистической регрессии,
поскольку~$\mu$ и~$\mu_\LR$ являются разными методами обучения.
Тем не~менее из~графиков следует вывод, что оценка $\bar \nu_\ell(\mu, \XX_L)$,
полученная по~обучающей выборке $\XX_L$, дает достаточно точный прогноз
фактической частоты ошибок $\bar \nu_L(\mu_\LR, \XX)$
и~кривой обучения логистической регрессии на~контрольной выборке $\XX_K$.

\section[Экспериментальное сравнение комбинаторных оценок]{Экспериментальное сравнение комбинаторных\\оценок}

Проведем экспериментальное сравнение новой оценки~\eqref{eq:pzm-cluster} с~тремя комбинаторными оценками
(VC- и~SC-оценками из~\cite{voron10roai-eng}, ES-оценкой из~\cite{esokolov12iip})
и~двумя PAC-Bayes оценками из~\cite{jin2012pacbayes}.
Основная цель данного эксперимента "--- сравнить завышенность перечисленных оценок.

%\item Оценить степень завышенности VC-оценки~\eqref{eq:QEps-VC-bound} и~SC-оценки~\eqref{eq:QEps-SC-bound}
%по сравнению с~определением $Q_\eps(\mu,\XX)$.
%\item Сравнить завышенность комбинаторных оценок с~PAC-Bayes оценками из~\cite{jin2012pacbayes}.

В качестве исходных данных были использованы те же задачи из~репозитория UCI, что и~в~прошлом параграфе.
Описание задач приведено в~таблице~\ref{tab:datasets}.

%На этапе предобработки удалялись объекты с~хотя бы одним пропущенным признаком.
%После этого каждый признак нормировался в~интервал $[0, 1]$.
%Для многоклассовых задач целевые классы были вручную сгруппированы в~два класса.

К каждой задаче была применена процедура пятикратной кросс-валидации,
которая запускалась 100 раз для усреднения результатов.
Таким образом, для каждой задачи генерировалось $M = 500$ разбиений
$\XX = \XX_L^i \sqcup \XX_K^i$, $i = 1, \dots, M$
и~вычислялась оценка Монте-Карло для среднего уклонения частот ошибок логистической регрессии:
\[
  \hat \delta_L(\mu_{\LR}, \XX) = \frac{1}{M}\sum_{i=1}^M \nu(\mu_{\LR} \XX_L^i, \XX_K^i) - \nu(\mu_{\LR} \XX_L^i, \XX_L^i).
\]
После этого каждая обучающая выборка $\XX_L$ использовалась для вычисления комбинаторной оценки
на~уклонение частот ошибок МЭР.
Множества алгоритмов~$A$, из~которого МЭР выбирал лучший алгоритм,
генерировалось с~помощью случайных блужданий по~графу расслоения-связности линейных классификаторов
(алгоритм~\ref{alg:walking}).
В качестве начального приближения для случайного блуждания использовался алгоритм $\mu_{\LR} \XX_L$, настроенный логистической регрессией по~обучающей выборке $\XX_L$.
Далее вновь использовался метод Монте-Карло: генерировались
$M' = 4096$ случайных разбиений $\XX_L = X^j_\ell \sqcup X^j_k$, $j = 1, \dots, M'$
(при $\frac{\ell}{L} = 0.8$)
и~вычислялась следующая величина:
\[
    \hat \delta_\ell(\mu, \XX_L) = \frac 1{M'}\sum_{j=1}^{M'}\nu(\mu X^j_\ell, X^j_k) - \nu(\mu X^j_\ell, X^j_\ell),
\]
где $\mu$ "--- метод минимизации эмпирического риска.
В заключение эта величина усреднялась по~всем разбиениям $\XX = \XX_L^i \sqcup \XX_K^i$.
Величины $\hat \delta_L(\mu_{\LR}, \XX)$ и~$\hat \delta_\ell(\mu, \XX_L)$ соответствуют реальному переобучению логистической регрессии и~его идеальной оценке в~рамках комбинаторного подхода.

\begin{table}[t]
      \caption{\small Сравнение фактического переобучения и~различных оценок
%        TrainErr stands for $\nu_L(\mu_\LR, \XX)$,
%        TestErr for $\bar \nu_L(\mu_\LR, \XX)$,
%        Overfit is their difference, %for $\bar \nu_L(\mu_\LR, \XX) - \nu_L(\mu_\LR, \XX)$
%        $\delta_\ell(\mu) \equiv \bar \nu_\ell(\mu, \XX_L) - \nu_\ell(\mu, \XX_L)$.
}
      \label{tab:compareToPacBayes2}
      \centering
        \begin{tabular}[t]{||l||r|r|r|r|r|r|r|r|r||}
        \hline
        &
        \multicolumn{1}{|c|}{Ошибка}&
        \multicolumn{2}{|c|}{Переобучение}&
        \multicolumn{4}{|c|}{Комбинаторные оценки} &
        \multicolumn{2}{|c|}{PAC-Bayes}
        \\
        \hline
            Task&
            Тест &
            $\hat\delta_L(LR)$ &
            $\hat\delta_\ell(\mu)$&
            VC&
            SC&
            ES&
            AF&
            DI&
            DD \\
        \hline
            glass		& 0.076	& 0.030	& 0.067	& 0.191	& 0.127	& 0.124	& 0.106	& 1.268	& 0.740 \\
            Liver dis.	& 0.315	& 0.017	& 0.046	& 0.249	& 0.192	& 0.146	& 0.161	& 1.207	& 1.067 \\
            Ionosphere	& 0.126	& 0.079	& 0.042	& 0.138	& 0.099	& 0.087	& 0.084	& 1.219	& 1.149 \\
            Australian	& 0.136	& 0.014	& 0.023	& 0.130	& 0.101	& 0.081	& 0.086	& 1.145	& 0.678 \\
            pima		& 0.227	& 0.007	& 0.021	& 0.151	& 0.117	& 0.090	& 0.098	& 0.971	& 0.749 \\
            faults		& 0.210	& 0.011	& 0.008	& 0.091	& 0.070	& 0.046	& 0.060	& 1.110	& 1.054 \\
            statlog		& 0.142	& 0.004	& 0.008	& 0.072	& 0.060	& 0.043	& 0.051	& 1.102	& 0.746 \\
            wine		& 0.250	& 0.002	& 0.003	& 0.061	& 0.047	& 0.032	& 0.040	& 0.776	& 0.637 \\
            waveform	& 0.105	& 0.003	& 0.003	& 0.043	& 0.033	& 0.023	& 0.023	& 0.561	& 0.354 \\
            pageblocks	& 0.051	& 0.001	& 0.003	& 0.030	& 0.022	& 0.016	& 0.018	& 0.739	& 0.186 \\
            Optdigits	& 0.121	& 0.006	& 0.003	& 0.043	& 0.034	& 0.023	& 0.026	& 1.068	& 0.604 \\
        \hline
        \end{tabular}
    \end{table}

В таблице~\ref{tab:compareToPacBayes2} сравниваются следующие величины:
    $\hat \delta_L(\mu_{\LR}, \XX)$ и~$\hat \delta_\ell(\mu, \XX_L)$;
    четыре верхние комбинаторные оценки величины $\hat \delta_\ell(\mu, \XX_L)$, обозначенные как VC, SC, ES и~AF;
    две PAC-Bayes оценки (обозначены как DD и~DI).
В отличие от~комбинаторных оценок, ограничивающих уклонение частот ошибок,
PAC-Bayes оценки справедливы непосредственно для частоты ошибок на~контроле (приведена в~столбце <<Ошибка тест>>).
DD-оценка учитывает размерность пространства признаков и~является более точной по~сравнению с~универсальной DI-оценкой, справедливой для любого числа признаков.

Комбинаторная SC-оценка соответствует оценке расслоения-связности из~\cite{voron10roai-eng}.
VC-оценка~также приведена в~\cite{voron10roai-eng},
и~она, в~отличие от~SC-оценки, не~учитывает ни расслоение, ни связность.
ES-оценка~\cite{esokolov12iip} основана на~более тонком учете расслоения,
при котором каждый алгоритм сравнивается со всем множеством найденных истоком графа расслоения-связности.

AF-оценка получена из~оценки метода порождающих и запрещающих множеств~\eqref{eq:pzm-cluster}.
Чтобы полностью конкретизировать~\eqref{eq:pzm-cluster}, необходимо уточнить следующее:
метод разбиения исходного множества алгоритмов~$A$ на~кластеры,
способ выбора порождающих и~запрещающих множеств для каждого кластера,
способ оценивания вероятности переобучения каждого кластера.
В AF-оценке порождающие и~запрещающие множества выбирались в~соответствии с~\eqref{eq:pzm-cluster},
для оценки вероятности переобучения каждого кластера использовалась формула~\eqref{eq:QEps-interval-layer},
а~представление множества алгоритмов~$A$ в~виде $A = A_1 \sqcup \dots \sqcup A_t$
производилось с~помощью иерархической кластеризации при выборе расстояния дальнего соседа.
Исходная метрика на~$A$ определялась как хэммингово расстояние между векторами ошибок алгоритмов.

Из экспериментальных данных следует, что переобучение логистической регрессии
хорошо приближается комбинаторной оценкой $\hat \delta_\ell(\mu, \XX_L)$ для МЭР.
Все четыре комбинаторные оценки существенно точнее обеих PAC-Bayes оценок.
Среди комбинаторных оценок наименее завышенной оказывается ES-оценка.
За ней следует предложенная нами AF-оценка.
Каждая из~этих оценок существенно уточняет SC-оценку расслоения-связности.
Улучшение точности в~ES- и~AF-оценках основано на~двух различных эффектах "--- более тонком учете расслоения в~ES-оценке и~учете сходства алгоритмов в~AF-оценке.
Представляется возможным, что объединение ES- и~AF-оценок позволит добиться еще большего качества комбинаторных оценок вероятности переобучения.

В заключение отметим, что в~данном эксперименте VC-оценка посчитана по~малому подмножеству алгоритмов~$A$,
полученному с~помощью случайных блужданий. Это <<локальная>> версия VC-оценки.
Обычная VC-оценка основана на~VC-размерности~$d$ всего пространства алгоритмов и~превышает единицу на~всех рассмотренных задачах.

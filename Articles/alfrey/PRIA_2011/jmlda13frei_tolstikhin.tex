\documentclass[12pt,twoside]{article}
\usepackage{jmlda}


\newcommand{\XX}{\mathbb{X}}
\newcommand{\YY}{\mathbb{Y}}
\newcommand{\Xl}{X}
\newcommand{\Xk}{\bar X}
\newcommand{\X}{\bar X}
\newcommand{\XXell}{[\XX]^\ell}
\renewcommand{\AA}{\mathbb{A}}
\newcommand{\fA}{\mathfrak{A}}
\newcommand{\Argmax}{\mathop{\rm Arg}\mathop{\rm max}\limits}
\newcommand{\Argmin}{\mathop{\rm Arg}\mathop{\rm min}\limits}
\newcommand{\Sym}{\mathop{\rm Sym}\limits}
\renewcommand{\geq}{\geqslant}
\renewcommand{\leq}{\leqslant}
\renewcommand{\epsilon}{\varepsilon}
\newcommand{\eps}{\varepsilon}
\def\brop#1{#1\discretionary{}{\hbox{$#1$}}{}} % перенос знака операции на следующую строку
\renewcommand{\em}{\it}
%\newcommand{\sign}{\mathop{\rm sign}\limits}
%\newcommand{\Expect}{\mathbb{E}}
%\newcommand{\Prob}{\mathbb{P}}

\newcommand{\hypergeom}[5]{{#1}_{#2}^{#4,#3}\left(#5\right)}
\newcommand{\Bhypergeom}[5]{{#1}_{#2}^{#4,#3}\bigl(#5\bigr)}
\newcommand{\hyper}[4]{\hypergeom{h}{#1}{#2}{#3}{#4}}
\newcommand{\Hyper}[4]{\hypergeom{H}{#1}{#2}{#3}{#4}}
\newcommand{\BHyper}[4]{\Bhypergeom{H}{#1}{#2}{#3}{#4}}
\newcommand{\HyperR}[4]{\hypergeom{\bar{H}}{#1}{#2}{#3}{#4}}
\newcommand{\Binom}[2]{C_{#1}^{#2}}
%\newcommand{\Binom}[2]{\binom{#1}{#2}}
\newcommand{\CLl}{\Binom{L}{\ell}}

\newcommand{\Q}{Q_\eps}
\def\LR{\text{LR}}
\renewcommand{\vec}[1]{\boldsymbol{#1}}

\newcommand{\mur}[3]{\mu({#1}, {#2}, {#3})}
\newcommand{\todo}{\textcolor{red}{[ToDo]} }


\newtheorem{Experiment}{Эксперимент}

%\NOREVIEWERNOTES
\title
    [Комбинаторные оценки вероятности переобучения на~основе кластеризации алгоритмов] % Краткое название; не нужно, если полное название влезает в~колонтитул
    {Комбинаторные оценки вероятности переобучения на~основе кластеризации и покрытий множества алгоритмов}
\author
    %[Фрей~А.\,И., Толстихин~И.\,О.] % список авторов для колонтитула; не нужен, если основной список влезает в колонтитул
    {Фрей~А.\,И., Толстихин~И.\,О.} % основной список авторов, выводимый в оглавление
%    [Автор~И.\,О.$^1$, Соавтор~И.\,О.$^2$, Фамилия~И.\,О.$^2$] % список авторов, выводимый в заголовок; не нужен, если он не отличается от основного
\thanks
    {Работа поддержана РФФИ (проект \No\,11-07-00480, \No\,12-07-33099\,-мол-а-вед) и~программой ОМН~РАН
<<Алгебраические и~комбинаторные методы математической кибернетики
и~информационные системы нового поколения>>.}
\email
    {sashafrey@gmail.com, iliya.tolstikhin@gmail.com}
\organization
    {Вычислительный Центр им.\  А.\,А.\,Дородницына РАН}
\abstract
    {В данной работе предлагается новая комбинаторная оценка вероятности переобучения, учитывающая сходство алгоритмов.
Оценка основана на разложении множества алгоритмов на непересекающиеся подмножества (кластеры).
Итоговая оценка учитывает сходство алгоритмов внутри каждого кластера,
и расслоение алгоритмов по числу ошибок между кластерами.
Для оценки вероятности переобучения каждого кластера предлагается теоретико-групповой подход,
основанный на учете симметрий.
На примере задач из репозитория UCI показано, что предлагаемый метод в ряде случаев дает менее завышенную оценку вероятности переобучения
по сравнению с известными ранее комбинаторными оценками.
}
\titleEng
    {Combinatorial bounds on probability of overfitting based~on~clustering and coverage of classifiers.}
\authorEng
    {Frey~A.\,I., Tolstikhin~I.\,O.}
\organizationEng
    {Computing Centre of RAS}
\abstractEng
    {The paper improves existing combinatorial bounds on probability of overfitting.
A new bound is based on partitioning of a set of classifiers into non-overlapping clusters, and then embedding each cluster into a superset with known exact formula for the probability of overfitting. The~key idea is to account for similarities between classifiers within each cluster. As a result, the new bound outperforms existing combinatorial bounds in our experiments on real datasets from UCI repository.}
\begin{document}
\maketitle
\linenumbers
\section{Введение}

Решение задач классификации и~прогнозирования можно рассматривать как задачу выбора по~неполной информации.
Качество алгоритма, выбранного по конечной обучающей выборке объектов, часто оказывается значительно хуже на независимой контрольной выборке.
В таких случаях говорят, что произошло \emph{переобучение} алгоритма \cite{vapnik74rus, vapnik98stat}.
%В противном случае, когда переобучение мало, говорят о высокой \emph{обобщающей способности} алгоритма.

В комбинаторной теории оценок обобщающей способности \cite{voron09dan}
\emph{вероятностью переобучения} называют долю разбиений генеральной выборки на обучающую и контрольную подвыборки фиксированной длины,
при которых произошло переобучение. В \cite{voron09pria} показано, что вероятность переобучения зависит
от \emph{профиля расслоения} множества алгоритмов и от \emph{сходства алгоритмов} между собой.

\emph{Профилем расслоения} называют распределение алгоритмов по числу ошибок на генеральной выборке.
Алгоритмы с высоким числом ошибок имеют низкую вероятность реализоваться в результате обучения
и потому дают незначительный вклад в вероятность переобучения.
Данное явление подробно изучено в работах \cite{voron10pria, voron10roai, frey10ioi}.
В дальнейших работах \cite{voron11premi, frey12ioi} показано, что применение полученных оценок вероятности переобучения
позволяет значительно улучшить качество композиций логических алгоритмов классификации на многих задачах из репозитория UCI.

\emph{Схожими} называют алгоримы, хэмминговы расстояния между которыми малы.
В \cite{voron09pria} экспериментально показано, что сходство алгоритмов существенно уменьшает вероятность переобучения.
Отметим, что большинство комбинаторных оценок вероятности переобучения основаны на анализе пар связных алгоритмов, т.е. различающихся только на одном объекте.
Данный подход не позволяет в полной мере учесть сходство алгоритмов.
Предложенный в \cite{bax97similarity} метод позволяет учесть сходство, но лишь в виде оценок худшего случая.

В данной работе связь между сходством алгоритмов и вероятностью переобучения будет изучена с помощью теоретико-группового подхода \cite{frey09mmro, frey10pria, tolstihin10ioi}.
Чтобы устранить эффект расслоения в первую очередь будут рассмотрены модельные семейства,
в которых все алгоритмы допускают равное число ошибок на полной выборке.
На основе полученных результатов предлагается новая верхняя оценка вероятности переобучения,
основанная на кластеризации алгоритмов с~близкими векторами ошибок.
Затем данная оценка обобщается на семейства с расслоением алгоритмов по числу ошибок.
%Также доказаны оценки, одновременно учитывающие оба эффекта: и сходство, и расслоение.
Эксперименты на 11 задачах из репозитория UCI показывают, что предлагаемый подход в ряде случаев уточняет все известные оценки вероятности переобучения.



\section{Определения}

Пусть задана генеральная выборка $\XX=\bigl( x_1, \ldots, x_L)$, состоящая из~$L$ объектов.
Произвольный алгоритм классификации, примененный к~данной выборке, порождает бинарный вектор
ошибок $a \equiv \bigl( I(a, x_i) \bigr){}_{i=1}^L$,
где $I(a, x_i) \in \{0, 1\}$ "--- бинарный индикатор ошибки алгоритма $a$ на~объекте $x_i$.
В~дальнейшем генеральная выборка $\XX$ предполагается фиксированной,
поэтому алгоритмы будут отождествляться с~векторами их~ошибок на~выборке~$\XX$.

Для произвольной подвыборки $U \subseteq \XX$
\emph{число} и \emph{частота} ошибок алгоритма~$a$ обозначаются, соответственно, через
$n(a, U) = \sum \limits_{x_i \in U}I(a, x_i)$ и
$\nu(a, U) = n(a, U) / |U|$.

Пусть $\XXell$ "--- множество всех разбиений генеральной выборки~$\XX$
на обучающую выборку~$\Xl$ длины~$\ell$ и~контрольную выборку~$\Xk$ длины $k=L-\ell$.
\emph{Методом обучения} называют отображение $\mu$, которое произвольной
обучающей выборке $X \in \XXell$ ставит в соответствие некоторый алгоритм $a = \mu(A, X)$ из заранее фиксированного множества $A \subset \AA$,
где $\AA = \{0, 1\}^L$ "--- множество всех возможных бинарных векторов ошибок.
%Будем использовать сокращенное обозначение $\mu X$ вместо $\mu(A, X)$ в тех случаях, когда из контекста понятно, о каком множестве алгоритмов идёт речь.
Для произвольного разбиения $X \sqcup \X = \XX$ \emph{переобученностью} алгоритма $a = \mu(A, X)$
называют уклонение частот его ошибок на контроле и на обучении
$\delta(a, X) = \nu(a, \X) - \nu(a, X)$.

Частоту ошибок $\nu(a, \Xl)$ алгоритма $a$ на~обучающей выборке $X$ часто называют \emph{эмпирическим риском}.
\emph{Минимизация эмпирического риска} (МЭР) "--- это такой метод обучения,
что для любой обучающей выборки $X$ выбранный алгоритм $a = \mu(A, X)$
допускает наименьшее число ошибок на обучающей выборке $X$.
Таким образом, для всех $\Xl \in \XXell$ должно быть выполнено $\mu(A, X) \in A(\Xl)$, где
\begin{equation}
\label{eqERM-A(X).sym}
    A(X) \equiv \Argmin_{a \in A} n(a,\Xl).
\end{equation}
При минимизации эмпирического риска может возникать неоднозначность "---
несколько алгоритмов из~$A(\Xl)$ могут иметь одинаковое число ошибок на~обучающей выборке.
Для устранения неоднозначности используется метод \emph{пессимистической минимизации эмпирического риска},
выбирающий в $A(X$) алгоритм с наибольшим числом ошибок на полной выборке.
Пессимистический МЭР не может быть реализован на практике,
т.к. он подглядывает в скрытую часть генеральной выборки.
Тем не менее, пессимистический МЭР является удобной теоретической конструкцией,
поскольку он позволяет получать верхние оценки на вероятность переобучения любого МЭР.

Следуя слабой вероятностной аксиоматике \cite{voron09pria}, будем считать, что на множестве $\XXell$
всех $C_L^\ell$ разбиений $X \sqcup \X$ введено равномерное распределение вероятностей.
Тогда вероятность переобучения $\Q(A)$ определяется как доля разбиений, при которых переобученность
превышает заданный порог $\eps \in (0, 1]$:
\begin{equation}
    \label{def:probOverfit}
    \Q(A) = \Prob[\delta(\mu(A, X), X) \geq \eps],
\end{equation}
где $\Prob[\phi\,] \equiv \frac{1}{\CLl}\sum\limits_{X \in \XXell} \phi(X)$, $\phi$ "--- произвольный предикат на множестве разбиений~$\XXell$,
а квадратные скобки переводят логическое выражение в~число $0$ или $1$ по~правилам~$[\text{истина}] = 1$, $[\text{ложь}] = 0$.
Заметим, что $1-\Q(A)$ как функция порога $\eps$ есть функция распределения случайной величины $\delta(\mu(A, X), X)$,
определенной на конечном вероятностном пространстве
$\{\XXell, 2^{\XXell}, \Prob\}$, где $\Prob$ "--- равномерное распределение.
В случаях, когда из контекста понятно, о каком множестве алгоритмов идёт речь, будем опускать аргумент $A$ и записывать вероятность переобучения как $\Q$.

Рассмотрим множество $A=\{a\}$, состоящее из одного алгоритма.
Тогда $\mu X = a$ для любой выборки $X \in \XXell$.
Это значит, что вероятность переобучения~$Q_\eps$ преобразовалась
в вероятность больших уклонений между частотами ошибок в выборках~$X,\X$.
Допустив, что число ошибок $n(a,\XX)$ нам известно, получим точное выражение для $Q_\eps$.

\begin{Theorem}[FC-оценка~\cite{voron11premi}]
\label{thOneAlg}
    Для фиксированного алгоритма~$a$, такого что ${m=n(a,\XX)}$,
    и любого $\eps\in [0,1]$
    вероятность переобучения определяется левым хвостом гипергеометрического распределения:
    \begin{equation}
    \label{eq:OCbound}
        Q_\eps(a)
        =
        \Hyper{L}{m}{\ell}{ \tfrac{\ell}{L} (m-\eps k) },
    \end{equation}
    где $\Hyper{L}{m}{\ell}{s} = \sum\limits_{t = 0}^{s} \hyper{L}{m}{\ell}{t}$ "--- функция гипергеометрического распределения,
    $\hyper{L}{m}{\ell}{t} = C_m^t C_{L-m}^{\ell - t} / \CLl$ "--- функция плотности гипергеометрического распределения~\cite{voron09pria}.
\end{Theorem}

Гипергеометрическое распределение играет важную роль во многих комбинаторных оценках.
Оценка \eqref{eq:OCbound}, примененная совместно с неравенством Буля,
позволяет получить верхнюю оценку на $Q_\eps(A)$, справедливую для любого метода обучения $\mu$.
\begin{Theorem}[VC-оценка~\cite{voron11premi}]
\label{thOneAlg2}
    Для любого метода обучения~$\mu$
    и любого $\eps\in [0,1]$
    вероятность переобучения ограничена суммой FC-оценок по множеству алгоритмов~$A$:
    \begin{equation}
    \label{eq:VCbound}
        Q_\eps(A)
        \leq
        \Prob\bigl[
        \max_{a \in A}\delta(a, X) \geq \eps
        \bigr]
        \leq
        \sum_{a\in A}
        \Hyper{L}{m}{\ell}{ \tfrac{\ell}{L} (m-\eps k) },
        \quad
        m = n(a,\XX).
    \end{equation}
\end{Theorem}

Назовём две причины завышенности оценки~\eqref{eq:VCbound}.
Во-первых, большинство алгоритмов из $A$ имеют высокую частоту ошибок
и, следовательно, имеют исчезающе малую вероятность реализоваться в результате обучения.
Тем не менее, оценка равномерного уклонения игнорирует это свойство метода обучения~$\mu$.
Во-вторых, неравенство Буля игнорирует тот факт, что алгоритмы с близкими векторами ошибок переобучаются в основном на одних и тех же разбиениях.
Более точные оценки должны учитывать свойства метода обучения и сходство между алгоритмами.

\section{Эффект сходства}

\emph{Хэмминговым расстоянием} между алгоритмами $a_1$ и $a_2$ называют величину
\[\rho(a_1, a_2) = \sum\limits_{x_i \in \XX} [a_1(x_i) \neq a_2(x_i)].\]

Рассмотрим простой пример, иллюстрирующий зависимость переобучения от хэммингова расстояния между алгоритмами семейства.

\begin{Experiment}
Множество $A = (a_1, a_2)$ состоит из двух алгоритмов, допускающих по~$m$ ошибок на полной выборке.
Векторы ошибок подобраны так, чтобы хэммингово расстояние $\rho(a_1, a_2)$ равнялось заранее фиксированному числу $d$.
На рисунке \ref{fig1} приведена зависимость медианы распределения $\Q(A)$
от хэммингова расстояния между алгоритмами.
Видно, что переобучение увеличивается с ростом~$\rho(a_1, a_2)$.
\end{Experiment}

\begin{figure}[t]
    \centering
%    \includegraphics[height=48mm]{overfit(rho).eps}
     \includegraphics[height=48mm]{pair.eps}
    \caption{Зависимость медианы распределения $\Q$ от хэммингова расстояния $d = \rho(a_1, a_2)$ между векторами ошибок пары алгоритмов. $L=100$, $\ell = 50$.}
    \label{fig1}
\end{figure}

Зададимся целью построить верхнюю оценку вероятности переобучения, учитывающую данный эффект.
Допустим, что исходное множество алгоритмов $A$ представлено в~виде разбиения на непересекающиеся подмножества
$A = A_1 \sqcup A_2 \sqcup \dots \sqcup A_t$ так, что в каждое $A_i$ попали лишь алгоритмы с близкими векторами ошибок.
В данной ситуации будем называть множества $A_i$ \emph{кластерами} алгоритмов.
Покажем, что задачу оценивания вероятности переобучения всего множества $A$ можно свести к оцениванию вероятности переобучения отдельных кластеров.

\begin{Lemma}
\label{lem:qDecomp}
Пусть множество алгоритмов $A$ произвольным образом представлено в~виде разбиения на непересекающиеся подмножества
$A = A_1 \sqcup A_2 \sqcup \dots \sqcup A_t$.
Тогда вероятность переобучения пессимистического метода минимизации эмпирического риска
оценивается сверху следующим выражением:
\begin{equation}
    \label{eq:qDecomp}
    \Q(A) \leq \sum_{i=1}^t \Q(A_t).
\end{equation}
\end{Lemma}

В дальнейшем лемма \ref{lem:qDecomp} будет играть ту же роль, что и неравенство Буля при выводе оценки \eqref{eq:VCbound}.
Преимущество данной леммы в том, что вместо суммирования по всем алгоритмам $a \in A$ суммирование 
производится по кластерам произвольного разбиения $A = A_1 \sqcup A_2 \sqcup \dots \sqcup A_t$.

\begin{Proof}
Заметим, что достаточно доказать неравенство \eqref{eq:qDecomp} для $t = 2$ (для произвольного числа кластеров неравенство доказывается индукцией по $t$).
Обозначим через $\mu(A, X)$ алгоритм, выбранный пессимистическим методом минимизации эмпирического риска из множества $A$ по обучающей выборке $X$.
Рассмотрим произвольное разбиение $X \in \XXell$ и покажем следующее:
\begin{equation}
    \label{eq_qDecompProof}
    [\delta(\mu(A, X), X) \geq \eps] \leq [\delta(\mu(A_1, X), X) \geq \eps] +     [\delta(\mu(A_2, X), X) \geq \eps].
\end{equation}

Для разбиения $X$ и множеств $A_1, A_2, A$ множества  $A_1(X), A_2(X), A(X)$ определены согласно \eqref{eqERM-A(X).sym}.
Обозначим через $n_1(X), n_2(X)$ и $n(X)$ число ошибок на обучающей выборке для алгоритмов из $A_1(X)$, $A_2(X)$ и $A(X)$, соответственно.
Очевидно, что $n_1(X) \geq n(X)$ и $n_2(X) \geq n(X)$, но по крайней мере одно из этих неравенств обязательно обращается в равенство.
Рассмотрим два случая: в первом одно неравенство строгое, во втором оба неравенства обращаются в равенство.

Случай 1. Пусть для определенности $n_1(X) > n(X)$. Тогда $A_2(X) = A(X)$, и следовательно $\mu(A_2, X) = \mu(A, X)$,
откуда немедленно следует \eqref{eq_qDecompProof}.

Случай 2. Из $n_1(X) = n_2(X) = n(X)$ следует, что $A(X) = A_1(X) \cup A_2(X)$, и, таким образом, либо $\mu(A, X) \in A_1(X)$, либо $\mu(A, X) \in A_2(X)$
(в зависимости от того, в какое из этих двух множеств попал алгоритм с наибольшим числом ошибок на полной выборке).
Значит, вновь выполнено \eqref{eq_qDecompProof}.
\end{Proof}

Для вывода верхних оценок вероятности переобучения каждого кластера удобно потребовать, 
чтобы внутри каждого кластера алгоритмы допускали равное число ошибок на полной выборке. 
Тогда можно воспользоваться следующей леммой из работы \cite{tolstihin10ioi}.
\begin{Lemma}
\label{le:LayerGr}
Пусть $A_i, B$ "--- два множества алгоритмов,
$A_i \subseteq B$, и все алгоритмы из $B$ допускают равное число ошибок на полной выборке.
Пусть метод обучения является минимизацией эмпирического риска.
Тогда для всех $\eps > 0$ выполнено неравенство $\Q(A_i) \leq \Q(B)$.
\end{Lemma}

\begin{Proof}
Докажем утверждение для частного случая $B = A_i \cup \{b\}$.
Рассмотрим произвольное разбиение $X \in \XXell$. Нас интересуют только разбиения с $\mu(B, X) = b$,
потому что вклад остальных разбиений в вероятность переобучения не изменился.
Пусть $a = \mu(A_i, X)$ "--- алгоритм, выбранный на разбиении $X$ методом обучения из множества $A_i$.
Поскольку $\mu$ является минимизацией эмпирического риска, получим $n(b, X) \leq n(a, X)$.
Поскольку по условию алгоритмы $a$ и $b$ имеют равное число ошибок на полной выборке, уклонение частоты
$\delta(b, X) \geq \delta(a, X)$.
Следовательно, вклад каждого разбиения от добавления алгоритма $b$ мог только увеличиться.
\end{Proof}

На выбор множества $B$ накладывается несколько условий.
Во-первых, оно должно состоять из алгоритмов с~равным числом ошибок на полной выборке.
Во-вторых, все алгоритмы должны иметь близкие векторы ошибок.
В-третьих, оценка вероятности переобучения $\Q(B)$ должна быть вычислительно эффективной.
Оказывается, следующее семейство удовлетворяет всем этим требованиям.
\begin{Definition}
\label{exCentralBallSlice}
Пусть $a_0$ "--- произвольный алгоритм с $m$ ошибками, $r \leq m$ "--- натуральное число.
\emph{Центральным слоем хэммингова шара} называется множество:
\[
    B_r^m(a_0) = \{a \in \AA \colon \rho(a, a_0) \leq r \text { и } n(a, \XX) = m\}.
\]
Данное множество состоит из алгоритмов хэммингова шара радиуса $r$ с центром в $a_0$,
допускающих на полной выборке столько же ошибок, сколько и центр шара.
Вероятность переобучения $\Q(B_r^m(a_0))$ зависит только от радиуса шара $r$ и числа ошибок $n(a_0, \XX)$,
поэтому в дальнейшем вместо $B_r^m(a_0)$ будет использоваться сокращенная запись $B_r^m$.
%Количество алгоритмов в $B_r^m$ дается выражением $\sum \limits_{i = 0}^{\lfloor r / 2 \rfloor} C_m^i C_{L-m}^i$.
\end{Definition}

\begin{Experiment}
\label{experiment2}
Исследуем вероятность переобучения $\Q(B_r^m)$ численно с помощью метода Монте-Карло,
сэмплируя \eqref{def:probOverfit} по $10$ тыс. случайным подвыборкам $X \in \XXell$.
Для сравнения мы рассмотрим еще одно модельное множество $R_n^m$, составленное из $n$ алгоритмов, допускающих по $m$ ошибок на полной выборке.
Векторы ошибок всех алгоритмов из $R_n^m$ сгенерированы случайно и независимо.
В следующей таблице показано, при каком числе алгоритмов $n$ в $R_n^m$ медианы распределений $\Q(R_n^m)$ и $\Q(B_r^m)$ совпадают.
\begin{table}[h!]
  \begin{center}
  \caption{Сравнение $|R_n^m|$ и $|B_r^m|$ при $L=50$, $\ell=25$, $m=10$.}
    \label{tab:RBcomparison}
    \begin{tabular}[t]{|c|c|c|c|}
    \hline
    $r$ & $|B_r^m|$ & $|R_n^m|$ & $\delta$ \\
    \hline
    2 & 401 & 2 & 0.079 \\
    4 & 35\,501 & 7 & 0.160 \\
    6 & 1\,221\,101 & 39 & 0.240 \\
    8 & 20\,413\,001 & 378 & 0.319 \\
    \hline
    \end{tabular}
  \end{center}
\end{table}
%\end{Example}

Из таблицы \ref{tab:RBcomparison}
видно, что всего семь алгоритмов со случайными векторами ошибок могут переобучиться так же сильно,
как и множество из десятков тысяч алгоритмов с~близкими векторами ошибок.
%Таким образом, вероятность переобучения множества $B_r^m$ существенно зависит от сходства алгоритмов.
В следующем параграфе мы детально изучим это свойство множества $B_r^m$ и приведем точную формулу для вероятности переобучения $\Q(B_r^m)$.
\end{Experiment}

\section{Центральный слой хэммингова шара}

Точная формула вероятности переобучения $\Q(B_r^m)$ впервые приводится в работе \cite{tolstihin10ioi}.
\begin{Theorem}[\cite{tolstihin10ioi}]
\label{thBallSclice}
Вероятность переобучения рандомизированного метода минимизации эмпирического риска для $m$-го слоя хэммингова шара $B_r^m$ радиуса $r$
при $r \leq 2 m$ и $n(a_0, \XX) = m$ записывается в виде
\begin{equation}
    \label{eq:ballSclice}
    \Q(B_r^m)
    =
    H_L^{\ell, m}(\tfrac \ell L (m - \epsilon k) + \big\lfloor r/2 \big\rfloor) \cdot [m \geq \eps k],
\end{equation}
где
$H_{L}^{\ell, m}(s)$ "--- функция гипергеометрического распределения.
\end{Theorem}
Доказательство этого утверждения ранее не публиковалось, и мы приводим его в настоящем параграфе.
При доказательстве будет использоваться теоретико-групповой подход \cite{frey09mmro, frey10pria, tolstihin10ioi}.

Пусть $S_L = \{ \pi \colon \XX \rightarrow \XX \}$ "--- симметрическая группа из~L элементов,
действующая на генеральную выборку перестановками объектов.
Действие произвольной $\pi \in S_L$ на алгоритм $a \in A$ определено перестановкой координат вектора
ошибок: $(\pi a)(x_i)= a(\pi^{-1}x_i)$.
Для произвольной выборки $X \in \XXell$ и множества алгоритмов $A \subset \{0, 1\}^L$ действия
$\pi X$ и $\pi A$ определены следующим образом:
$\pi X = \{ \pi x \colon x \in X \}$, $\pi A = \{ \pi a \colon a \in A\}$.

\begin{Def}[\cite{frey09mmro}]
    \label{def:symmetryGroup}
    \emph{Группой симметрий} $\Sym(A)$ множества алгоритмов $A \subset \AA$
    называют его стационарную подгруппу:
    \[
        \Sym(A) = \{\pi \in S_L \colon \pi A = A\}.
    \]
\end{Def}

\emph{Орбитой} элемента $m$ множества $M$, на~котором действует группа $G$,
называется подмножество $Gm = \{g m \colon g \in G\} \subseteq M$.
Орбиты двух элементов $m_1$ и~$m_2$ либо не~пересекаются, либо совпадают.
Это позволяет говорить о разбиении множества $M$ на~непересекающиеся орбиты:
$M = G m_1 \sqcup \ldots \sqcup G m_k$.
Множество орбит действия группы $\Sym(A)$ на~$A$ обозначим через $\Omega(A)$,
и для каждой орбиты $\omega \in \Omega(A)$ обозначим через $a_\omega$ произвольного представителя этой орбиты.
Аналогично, множество орбит действия $\Sym(A)$ на $\XXell$ обозначим через $\Omega(\XXell)$,
и для орбиты $\tau \in \Omega(\XXell)$ обозначим её представителя через $X_\tau$.

Для широкого класса методов обучения группа $\Sym(A)$ позволяет учесть симметрии множества алгоритмов при выводе оценок вероятности переобучения.
В частности, в работах \cite{frey09mmro, frey10pria} используется \emph{рандомизированный метод минимизации эмпирического риска}.
Этот метод выбирает произвольный алгоритм из~множества~$A(X)$ случайно и~равновероятно.
Определение вероятности переобучения \eqref{def:probOverfit} приходится модифицировать,
усреднив переобученность по~множеству $A(X)$:
\begin{equation}
\label{QepsRERM.sym}
    \Q(A)
    =
    \frac 1 \CLl\sum_{X \in \XXell}
    \frac1{|A(X)|} \sum_{a\in A(X)}
    \bigl[
        \delta(a,X) \geq \eps
    \bigr].
\end{equation}
В \cite{frey10pria} показано, что с учетом группы симметрий $\Sym(A)$ вероятность переобучения \eqref{QepsRERM.sym} может быть переписана следующим образом:
\[
    \Q(A) = \frac{1}{\CLl}\sum_{\omega \in \Omega(A)}|\omega|\sum_{X \in \XXell}\frac{[a_\omega \in A(X)]}{|A(X)|}[\delta(a_\omega, X) \geq \eps].
\]
Для вывода точной формулы $\Q(B_r^m)$ нам будет удобнее 
рассматривать действие группы симметрий на множестве $\XXell$ всех разбиений выборки на обучение и контроль.

\begin{Lemma}
Пусть для некоторой функции $f \colon 2^\AA \times \XXell \rightarrow \RR$ для всех $A \subset \AA$, $X~\in~\XXell$ и всех $\pi \in \Sym(A)$ выполнено условие
$f(A, X) = f(A, \pi X)$. Тогда справедливо следующее разложение:
\[
    \sum_{X \in \XXell} f(A, X) = \sum_{\tau \in \Omega(\XXell)} |\tau| f(A, X_\tau).
\]
\end{Lemma}
\begin{Proof} Доказательство с очевидностью следует из группировки равных слагаемых.\end{Proof}

Нас интересует, какие функции удовлетворяют условию $f(A, X) = f(A, \pi X)$.
Введем следующую классификацию:

\begin{itemize}
  \item Симметричной функцией \emph{первого рода} будем называть $g \colon \AA \times \XXell \rightarrow \RR$, такую что для~всех $\pi \in S_L$ выполнено $g(a, X) = g(\pi a, \pi X)$;
  \item Симметричной функцией \emph{второго рода} будем называть $G \colon 2^\AA \times \XXell \rightarrow 2^\AA$, такую что для всех $\pi \in S_L$ выполнено $\pi G(A, X) = G(\pi A, \pi X)$;
  \item Симметричной функцией \emph{третьего рода} будем называть $f \colon 2^\AA \times \XXell \rightarrow \RR$, такую что для всех $\pi \in S_L$ выполнено $f(A, X) = f(\pi A, \pi X)$.
\end{itemize}

В \cite{frey10pria} было показано, что функции $n(a, X)$ и $\nu(a, X)$ являются симметричными функциями первого рода, а $A$ и $A(X)$ "--- симметричными второго рода.
Следующие две теоремы позволяют легко строить новые симметричные функции из уже имеющихся.
\begin{Theorem}
\label{th:sym1}
    Пусть
        $g_1, g_2, \dots, g_p$ "--- симметричные функции первого рода,
        $f_1, f_2, \dots, f_p$ "--- симметричные функции третьего рода,
        $F \colon \RR^p \rightarrow \RR$ "--- произвольная функция многих переменных.
    Тогда
        $F(g_1, g_2, \dots, g_p)$ "--- вновь симметричная функция первого рода,
        $F(f_1, f_2, \dots, f_p)$ "--- симметричная функция третьего рода.
\end{Theorem}
\begin{Proof}
Проведя элементарные выкладки, получим
\[
    F(\pi a, \pi X) \equiv F(g_1(\pi a, \pi X), \dots, g_p(\pi a, \pi X)) = F(g_1(a, X), \dots, g_p(a, X)) \equiv F(a, X),
\]
и аналогично для функций третьего рода.
\end{Proof}

\begin{Theorem}
\label{th:sym2}
    Пусть $g$ "--- симметричная функция первого рода, $G$ "--- симметричная функция второго рода.
    Тогда $f(A, X) \equiv |G(A, X)|$ и $f(A, X) \equiv \sum\limits_{a \in G(A, X)} g(a, X)$ "--- симметричные функции третьего рода.
\end{Theorem}
\begin{Proof}
Заметим, что для любого $A \subset \AA$ выполнено $|A| = |\pi A|$, поскольку $\pi$, как элемент группы, является биекцией. Следовательно, $|G(A, X)| = |\pi G(A, X)| = |G(\pi A, \pi X)|$.

Для функции $f(A, X) \equiv \sum\limits_{a \in G(A, X)} g(a, X)$ запишем следующую цепочку равенств:
\begin{align*}
    f(\pi A, \pi X) &= \sum\limits_{a \in G(\pi A, \pi X)} g(a, \pi X) = \sum\limits_{a \in \pi G(A, X)} g(a, \pi X) = \\
     &= \sum\limits_{a \in G(A, X)} g(\pi a, \pi X) = \sum\limits_{a \in G(A, X)} g(a, X) = f(A, X).
\end{align*}
\end{Proof}

Из приведенных выше теорем следует, что $\frac 1{|A(X)|} \sum\limits_{a \in A(X)}[\delta(a, X) \geq \eps]$ является симметричной функцией третьего рода,
а следовательно вероятность переобучения можно факторизовать по действию группы симметрий на множестве разбиений выборки:
\begin{equation}
\label{eq:factorization}
 \Q(A) =
    \sum_{\tau \in \Omega(\XXell)} \frac {|\tau|}{|A(X_\tau)|} \sum\limits_{a \in A(X_\tau)}[\delta(a, X_\tau) \geq \eps].
\end{equation}

Данную формулу можно упростить для случая,
когда все алгоритмы из $A$ имеют равное число ошибок на полной выборке.

\begin{Theorem}
\label{crl:easyFormula}
Пусть все $a \in A$ имеют равное число ошибок на полной выборке.
Тогда вероятность переобучения рандомизированного метода минимизации эмпирического риска записывается в виде
\begin{equation}
\label{eq:easyFormula}
    \Q(A)
    =
    \frac1{C_L^\ell} \sum_{\tau \in \Omega(\XXell)}
    %\textbf{E}
    |\tau| \left[\min_{a \in A} n(a, X_\tau) \leq \frac \ell L(m - \epsilon k)\right].
\end{equation}
\end{Theorem}

\begin{Proof}
Заметим, что все алгоритмы из $A(X_\tau)$ имеют одинаковое переобучение.
Это следует из двух утверждений: во-первых, все алгоритмы из $A$ имеют равное число ошибок на полной выборке,
во-вторых, все алгоритмы из $A(X_\tau)$ имеют равное число ошибок на обучении.
Значит \eqref{eq:factorization} можно упростить следующим образом:
\[
    \Q(A)
    =
    \frac1{C_L^\ell} \sum_{\tau \in \Omega(\XXell)}
    |\tau| \left[\delta(a', X_\tau) \geq \eps\right],
\]
где $a'$ "--- произвольный алгоритм из $A(X_\tau)$.
Из $a' \in A(X_\tau)$ следует, что $n(a', X_\tau) = \min\limits_{a \in A}n(a, X)$.
Подставляя это выражение в определение уклонения частоты $\delta(a, X)$ и проводя элементарные выкладки, получаем \eqref{eq:easyFormula}.
\end{Proof}

Вернемся к выводу формулы вероятности переобучения для центрального слоя хэммингова шара $B_r^m$ с центром в $a_0$.
%Первым делом нам нужно узнать строение группы симметрий данного множества. Для этого
Обозначим через $X^m = \{x \in \XX \colon a_0(x) = 1\}$ множество объектов, на которых ошибается алгоритм $a_0$,
и $X^{L-m} = \{x \in \XX \colon a_0(x) = 0\}$ "--- множество объектов, на которых $a_0$ не ошибается.
\begin{Lemma}
\label{lem:ballSyms}
Группа $S_m \times S_{L-m}$, где $S_m$ и $S_{L_m}$ "--- симметрические группы перестановок,
действующие на множествах $X^m$ и $X^{L-m}$, соответственно, является подгруппой группы
симметрий множества алгоритмов $B_{r}^m$.
\end{Lemma}
\begin{Proof}
Доказательство следует из определения центрального слоя хэммингова шара
и инвариантности хэммингова расстояния к действию группы $S_L$.
\end{Proof}

\begin{Lemma}
\label{lem:ballOrbitSize}
Орбиты $\tau \in \Omega(\XXell)$ индексированы параметром $i = |\Xl \cap X^m|$.
Мощность орбиты $\tau_i$ записывается в виде $|\tau_i| = C_L^\ell h_L^{\ell, m}(i)$,
где $\hyper{L}{m}{\ell}{i} = C_m^t C_{L-m}^{\ell - i} / \CLl$ "--- функция плотности гипергеометрического распределения.
\end{Lemma}

\begin{Proof}
Первое утверждение леммы непосредственно следует из структуры подгруппы симметрий,
полученной в лемме \ref{lem:ballSyms}.
Мощность орбиты $|\tau_i| = C_L^\ell h_L^{\ell, m}(i)$ определяется числом способов выбрать $i$ объектов из $X^m$ и
$\ell - i$ объектов из $X^{L-m}$.
\end{Proof}

Теперь мы можем приступить к доказательству теоремы \ref{thBallSclice}.

\noindent{\bf Доказательство.} 
Воспользовавшись теоремой \ref{crl:easyFormula} и леммой \ref{lem:ballOrbitSize}, получим
\[
    \Q(B_r^m)
    =
    \sum_{i=0}^{m}
    h_L^{\ell, m}(i) \left[\min_{a \in A} n(a, X_i) \leq \frac \ell L(m - \epsilon k)\right].
\]
Напомним, что по определению параметр $i$ обозначает мощность множества $\Xl \cap X^m$. 
Пусть~$r' = \big\lfloor \frac r 2 \big\rfloor$.
Тогда
\[
    \min_{a \in B_r^m} n(a, X_i) =
    \begin{cases}
        & 0, \text{ при } i \leq r', \\
        & i - r', \text{ при } i > r'.
    \end{cases}
\]
Следовательно,
\[
    \Q(B_r^m)
    =
%    \sum_{i=0}^{\lfloor s_d(\epsilon)\rfloor + r'} h_L^{\ell, m}(i) =
    \begin{cases}
        & 0, \text{ при } m < \eps k, \\
        & H_L^{\ell, m}( \frac \ell L (m - \epsilon k) + \big\lfloor r/2 \big\rfloor), \text{ при } m \geq \eps k.
        \;\;\;\scriptstyle\blacksquare
    \end{cases}
\]

Из доказанной формулы следует, что вероятность переобучения $Q_\eps(B_r^m)$
соответствует FC-оценке \eqref{eq:OCbound} для фиксированного алгоритма, 
смещенной вправо на $\Delta \eps = \frac{L}{k \ell} \big\lfloor r/2 \big\rfloor$.
Это объясняет, почему в эксперименте \ref{experiment2}
медиана распределения $Q_\eps(B_r^m)$ растет линейно с ростом радиуса $r$.

%Из этой формулы подтверждает результаты примера \ref{exCentralBallSlice}, в которых медиана распределения переобученности возрастала линейно по радиусу шара.

\section{Учёт расслоения}
Результаты двух предыдущих параграфов позволяют сформулировать следующую оценку вероятности переобучения.
\begin{Theorem}
\label{th:decompToBallSclice}
Пусть $A = A_1 \sqcup A_2 \sqcup \dots \sqcup A_t$, и в каждом подмножестве~$A_i$ алгоритмы допускают равное число ошибок.
Пусть каждое множество $A_i$ вложено в центральный слой хэммингова шара $B_{r_i}^{m_i}$. Тогда
\begin{equation}
\label{eq:decompToBallSlice}
    \Q(A) \leq \sum_{i = 1}^t \Q(B_{r_i}^{m_i}) = \sum_{i = 1}^t \Big\{ H_L^{\ell, m_i}(\tfrac \ell L (m_i - \epsilon k) + \big\lfloor r_i/2 \big\rfloor) \cdot [m_i \geq \eps k] \Big\}.
\end{equation}
\end{Theorem}
\begin{Proof} Доказательство следует из лемм \ref{lem:qDecomp}, \ref{le:LayerGr} и формулы \eqref{eq:ballSclice}.
\end{Proof}

Оценка \eqref{eq:decompToBallSlice} учитывает сходство, но не расслоение алгоритмов по числу ошибок.
Этот недостаток можно исправить, применив метод порождающих и запрещающих множеств~\cite{voron10pria}.
Для этого метод необходимо обобщить, чтобы он был применим не к отдельным алгоритмам, а непосредственно к кластерам алгоритмов.

\begin{Hypothesis}
\label{generalizedPZM}
Пусть множество алгоритмов $A$ представлено в~виде разбиения на непересекающиеся подмножества
$A = A_1 \sqcup A_2 \sqcup \dots \sqcup A_t$.
Пусть выборка $\XX$ и метод обучения $\mu$ таковы, что для каждого $i=1,\dots,t$ можно указать пару непересекающихся подмножеств $X_i \subset \XX$ и $X'_i \subset \XX$,
удовлетворяющую условию
\[
    [\mu(A, X) \in A_i] \leq [X_i \subset X][X'_i \subset \X], \;\;\forall X \in \XXell.
\]
Пусть, кроме этого, все алгоритмы $a \in A_i$ не допускают ошибок на $X_i$ и ошибаются на~всех объектах из $X'_i$.
\end{Hypothesis}
Множество $X_i$ будем называть \emph{порождающим}, множество $X'_i$ "--- \emph{запрещающим} для $A_i$.
Гипотеза \ref{generalizedPZM} означает, что результат обучения может принадлежать $A_i$ только в том случае, если
в обучающей выборке $X$ находятся все порождающие объекты и ни одного запрещающего.
Все остальные объекты $\YY_i \equiv \XX \backslash X_i \backslash X'_i$ будем называть \emph{нейтральными} для~$A_i$.

Пусть $L_i = L - |X_i| - |X'_i|$, $\ell_i = \ell - |X_i|$, $k_i = k - |X'_i|$.
Пусть $Q'_\eps(A_i)$ есть вероятность переобучения на множестве нейтральных объектов $\YY_i$:
\[
    Q'_\eps(A_i) = \frac{1}{C_{L_i}^{\ell_i}} \sum_{Y \in [\YY_i]^{\ell_i}} [\delta(\mu(A_i, Y), Y) \geq \eps],
\]
где $[\YY_i]^{\ell_i}$ "--- множество разбиений $\YY_i$ на обучающую выборку~$Y$ длины~$\ell_i$ и~контрольную выборку~$\bar Y$ длины $k_i=L_i-\ell_i$.

\begin{Theorem}[Оценка расслоения-сходства]
\label{th:generalizedPZM}
Пусть выполнена гипотеза \ref{generalizedPZM},
а на разбиение $A = A_1 \sqcup A_2 \sqcup \dots \sqcup A_t$ наложено дополнительное ограничение:
внутри каждого кластера $A_i$ все алгоритмы допускают равное число ошибок (обозначаемое через $m_i$).
Тогда вероятность переобучения $Q_\eps(A)$ ограничена сверху следующей оценкой:
\begin{equation}
    \label{generalizedPZMtheorem}
    Q_\eps(A) \leq \sum_{i = 1}^t P_i \, Q'_{\eps_i}(A_i),
\end{equation}
где $P_i = \frac{C_{L_i}^{\ell_i}}{\CLl}$,
$\eps_i = \frac{L_i}{\ell_i k_i} \frac{\ell \, k}{L} \eps + \big(1 - \frac{\ell \, L_i}{L \ell_i}\big) \frac{m_i}{k_i} - \frac{|X'_i|}{k_i}$,
$Q'_\eps(A_i)$ "--- определенная выше вероятность переобучения на множестве нейтральных объектов.
\end{Theorem}

\begin{Proof} %Доказательство во многом повторяет аналогичной теоремы из \cite{voron10pria}.
Распишем определение вероятности переобучения:
\begin{align*}
    Q_\eps(A) &    = \frac{1}{\CLl}\sum_{X \in \XXell} [\delta(\mu(A, X), X) \geq \eps] = \\
              &    = \frac{1}{\CLl} \sum_{i = 1}^t  \sum_{X \in \XXell} [\mu(A, X) \in A_i] [\delta(\mu(A_i, X), X) \geq \eps] \leq \\
              & \leq \frac{1}{\CLl} \sum_{i = 1}^t  \sum_{X \in \XXell} [X_i \subset X][X'_i \subset \X] [\delta(\mu(A_i, X), X) \geq \eps].
\end{align*}
Пусть $Y = X \backslash X_i$.
Тогда $\sum\limits_{X \in \XXell}$ при условии $[X_i \subset X][X'_i \subset \X]$
можно заменить на суммирование по $Y \in [\YY_i]^{\ell_i}$.
\begin{equation}
    \label{generalizedPZMlbl1}
    Q_\eps(A) \leq \frac{C_{L_i}^{\ell_i}}{\CLl} \sum_{i = 1}^t \frac {1}{C_{L_i}^{\ell_i}} \sum_{Y \in [\YY_i]^{\ell_i}} [\delta(\mu(A_i, X), X) \geq \eps], \text{ где } X = Y \sqcup X_i.
\end{equation}
Выразим условие $\delta(\mu(A_i, X), X) \geq \eps$ в терминах $Y$. Обозначим $a = \mu(A_i, X)$, и пусть $n(a, Y) = s$.
Тогда, используя условие $n(a, X_i) = 0$ и $n(a, X'_i) = |X'_i|$ из гипотезы \ref{generalizedPZM}, получим
$n(a, X) = s$, $n(a, \X) = m_i - s$, $n(a, \bar Y) = m_i - |X'_i| - s$.
Следовательно, условия переобучения для $X$ и $Y$ запишутся следующим образом:
\begin{align*}
    [\delta(\mu(A_i, X), X) \geq \eps]   & = \Big[s \leq \frac{\ell}L (m_i - \eps k)\Big], \\
    [\delta(\mu(A_i, Y), Y) \geq \eps_i] & = \Big[s \leq \frac{\ell_i}{L_i} \big(m_i - |X'_i| - \eps_i k_i\big)\Big].
\end{align*}
Пусть $\eps_i = \frac{L_i}{\ell_i k_i} \frac{\ell \, k}{L} \eps + \big(1 - \frac{\ell \, L_i}{L \ell_i}\big) \frac{m_i}{k_i} - \frac{|X'_i|}{k_i}$.
Непосредственной проверкой убеждаемся, что $[\delta(\mu(A_i, X), X) \geq \eps] = [\delta(\mu(A_i, Y), Y) \geq \eps_i]$.
Подставляя это в \eqref{generalizedPZMlbl1}, получаем утверждение теоремы.
\end{Proof}

Покажем, как для произвольного разбиения $A = A_1 \sqcup A_2 \sqcup \dots \sqcup A_t$ построить систему порождающих и запрещающих множеств.
Следуя \cite{voron10pria}, введем на $A$ отношение частичного порядка:
$a \leq b$ тогда и только тогда, когда $I(a, x) \leq I(b, x), \forall x \in \XX$.
Определим $a < b$ если $a \leq b$ и $a \neq b$.
Если $a < b$ и при этом $\rho(a, b) = 1$, то будем говорить, что $a$ \emph{предшествует} $b$, и записывать $a \prec b$.

Для отдельного алгоритма $a \in A$ порождающие и запрещающие множества определены в \cite{voron10pria}:
\begin{equation}
    \label{standardPZM}
    \begin{split}
        X_a  & = \{x \in X \colon \exists b \in A \colon a \prec b, I(a, x) < I(b, x)\}, \\
        X'_a & = \{x \in X \colon \exists b \in A \colon b < a,     I(b, x) < I(a, x)\}.
    \end{split}
\end{equation}

Для кластера $A_i$ положим
\begin{equation}
    \label{klasterPZM}
    X_i = \bigcap\limits_{a \in A_i} X_a,\;\; X'_i = \bigcap\limits_{a \in A_i} X'_a.
\end{equation}

\begin{Lemma}
    \label{lemmaKlasterPZM}
    Множества $X_i$ и $X'_i$, определенные в \eqref{klasterPZM}, являются, соответственно, порождающим и запрещающим множествами для кластера $A_i$ в смысле гипотезы \ref{generalizedPZM}.
\end{Lemma}
\begin{Proof}
Для произвольного разбиения $X \in \XXell$ обозначим $a = \mu X$, и пусть ${a \in A_i}$.
В \cite{voron10pria} показано, что определенные в \eqref{standardPZM} множества $X_a$ и $X'_a$ являются порождающим и запрещающим множествами для алгоритма $a$,
т.е. из условия $\mu X = a$ следует, что $X_a \subset X$ и $X'_a \subset \X$.
Из определения $X_i$ и $X'_i$ следует, что $X_i \subset X_a$ и $X'_i \subset X'_a$. Следовательно, $X_i \subset X$ и $X'_i \subset \X$.

Условие <<все алгоритмы $a \in A_i$ не допускают ошибок на $X_i$ и ошибаются на всех объектах из $X'_i$>> также следует из определения $X_i$ и $X'_i$.
\end{Proof}

Полученные выше результаты позволяют уточнить оценку \eqref{eq:decompToBallSlice}.
\begin{Theorem}
В условиях теоремы \ref{th:decompToBallSclice}, определений \eqref{standardPZM} и \eqref{klasterPZM} для порождающих и запрещающих множеств
справедлива следующая оценка вероятности переобучения:
\begin{equation}
\label{eq:decompToBallSlicePZM}
    \Q(A) \leq
          \sum_{i = 1}^t
             \frac{C_{L_i}^{\ell_i}}{\CLl}
             Q'_{\eps'}(B_{r_i}^{m'_i})
          =
          \sum_{i = 1}^t
          \Big\{
             \frac{C_{L_i}^{\ell_i}}{\CLl}
             H_{L_i}^{\ell_i, m'_i}(s(\epsilon) + \big\lfloor r_i/2 \big\rfloor)
             \cdot
             [m_i \geq \eps k]
          \Big\},
\end{equation}
где $s(\epsilon) = \frac \ell L (m_i - \epsilon k)$, $L_i = L - |X_i| - |X'_i|$, $\ell_i = \ell - |X_i|$, $m'_i = m_i - |X'_i|$.
\end{Theorem}
\begin{Proof}
Доказательство следует из теоремы \ref{th:generalizedPZM}, леммы \ref{lemmaKlasterPZM} и формулы \eqref{eq:ballSclice}.
\end{Proof}
Главное отличие \eqref{eq:decompToBallSlicePZM}
от полученной ранее оценки \eqref{eq:decompToBallSlice} "--- в коэффициенте~$\frac{\Binom{L_i}{\ell_i}}{\CLl}$,
экспоненциально убывающем с ростом мощности порождающего и запрещающего множеств.

\section{Локальная окрестность малой мощности}
Отметим, что центральный слой хэммингова шара $B_r^m$ даёт достаточно грубую оценку вероятности переобучения для множества $A_i \subset B_r^m$.
Во-первых, такая аппроксимация множества $A_i$ не учитывает объекты выборки,
лежащие глубоко внутри своего класса, и потому одинаково классифицируемые всеми алгоритмами кластера $A_i$.
Во-вторых, при~оценке не учитывается мощность кластера $A_i$, которая на реальных данных оказывается много меньше мощности множества $B_r^m$.

\begin{Def}
\label{def:localVicinity}
Пусть все объекты генеральной выборки $\XX$ разделены на три непересекающихся множества:
надежно классифицируемые объекты $X_0$,
ошибочно классифицируемые объекты $X_1$
и пограничные объекты $X_r$.
Пусть $|X_r| = r$ и $|X_1| = m$, $\rho$ "--- целочисленный параметр, $\rho \leq r$.
Рассмотрим алгоритм $a_0$, допускающий $m$ ошибок на $X_1$ и $\rho$ ошибок на $X_r$.
\emph{Локальной окрестностью} алгоритма $a_0$ будем называть множество алгоритмов $\hat B_{r,\rho}^{m} \subset \AA$, удовлетворяющее следующим условиям:
\begin{itemize}
    \item $\hat B_{r,\rho}^{m}$ содержит все алгоритмы, допускающие ровно $\rho$ ошибок на объектах из $X_r$,
    \item ни один алгоритм из $\hat B_{r,\rho}^{m}$ не ошибается на объектах из $X_0$,
    \item все алгоритмы из $\hat B_{r,\rho}^{m}$ ошибаются на всех объектах из $X_1$.
\end{itemize}
\end{Def}
%
%\begin{figure}[t]
%    \begin {multicols}{2}
%    \centering
%    \hfill
%    \includegraphics[width=72mm,height=36mm]{ballslice_vs_localvicinity.eps}
%    \hfill
%    \caption{Зависимость среднего уклонения частоты $\delta$ от параметра $\rho$
%        для центрального слоя шара $B_{2 \rho}^{m}$ и
%        локальной окрестности $\hat B_{2\rho, \rho}^{m - \rho}$ при $L=200$, $\ell = 100$, $m=50$.}
%    \label{figBallSliceVsLocalVicinity}
%    \medskip
%    \hfill
%    \includegraphics[width=72mm,height=36mm]{ballslice_vs_localvicinity_D.eps}
%    \caption{Зависимость $\bar Q_\eps(B, d)$ от $d$
%        для центрального слоя хэммингова шара $B_{2 \rho}^{m}$ и
%        локальной окрестности $\hat B_{2\rho, \rho}^{m - \rho}$ при $L=200$, $\ell = 100$, $m=50$, $\rho = 5$, $\eps = 0.1$.}
%    \label{figBallSliceVsLocalVicinityD}
%    \hfill
%    \end {multicols}
%\end{figure}

\begin{figure}[t]
    \centering
    \includegraphics[width=172mm,height=48mm]{ballslice_vs_localvicinity_combined.eps}
    \caption{Переобучение центрального слоя шара $B_{2 \rho}^{m}$ (сплошная кривая) и
        локальной окрестности $\hat B_{2\rho, \rho}^{m - \rho}$ (пунктирная кривая) при $L=200$, $\ell = 100$, $m=50$.
        Рисунок слева отображает среднее уклонение частот ошибок на обучении и контроле в зависимости от параметра $\rho$. Рисунок справа отображает зависимость средней вероятности переобучения $\bar Q_\eps(B, d)$ от параметра $d$ при $\rho = 5$, $\eps = 0.1$.}
    \label{figBallSliceVsLocalVicinity}
\end{figure}


На рис. \ref{figBallSliceVsLocalVicinity} слева сравниваются вероятности переобучения центрального слоя хэммингова шара и локальной окрестности.
Видно, что локальная окрестность даёт меньшую оценку вероятности переобучения.
Следовательно, аппроксимация кластеров $A_i$ с помощью локальных окрестностей даёт более точную оценку вероятности переобучения.

Для дальнейшего уточнения оценки мы будем рассматривать кластер $A_i$ как случайное подмножество некоторого объемлющего множества $B$
(например, центрального слоя хэммингова шара или локальной окрестности).

\begin{Def}
\emph{Средней вероятностью переобучения по подмножествам фиксированной мощности} назовём следующую величину:
\begin{equation}
    \label{eq:randomizedSubsetOverfitting}
    \bar{Q}_{\eps}(B, d) = \frac{1}{C_{|B|}^d} \sum_{A' \in [B]^d} \Q(A'),
\end{equation}
где $[B]^d = \{A' \subset B \colon |A'| = d\,\}$ "--- система подмножеств фиксированной мощности.
\end{Def}
На рис. \ref{figBallSliceVsLocalVicinity} справа показан пример зависимости средней вероятности переобучения $\bar{Q}_{\eps}(B, d)$ от параметра $d$ для двух рассматриваемых нами семейств алгоритмов.

\begin{Theorem}
\label{thTolstR2}
Пусть $B$ "--- множество алгоритмов, допускающих равное число ошибок на~полной выборке.
Тогда выполнено следующее:
\begin{equation}
    \label{eq_thTolstR2}
    \bar{Q}_{\eps}(B, d) = 1 -
        \frac 1{\CLl}
            \sum\limits_{\tau \in \Omega(\XXell)}
                |\tau|\frac{C^d_{N_\eps(B, X_\tau)}}{C^d_{|B|}},
\end{equation}
где
    $\Omega(\XXell)$ "--- множество орбит действия группы симметрий $A$ на $\XXell$,
    $X_\tau$ "--- произвольный представитель орбиты $\tau \in \Omega(\XXell)$,
    $N_\eps(B, X) = \sum\limits_{a\in B}[n(a,X) > s(\eps)]$ "--- число алгоритмов из~$B$, непереобученных на разбиении $X$,\:
    $s(\eps)=\frac{\ell}{L}(m - \eps k)$.
\end{Theorem}

\begin{Proof}
Запишем определение $\bar{Q}_\eps(B, d)$ и воспользуемся тем,~что $A' \subset B$ вновь является подмножеством слоя:
\[
\bar{Q}_{\eps}(B, d) =
    \frac{1}{C^d_{|B|}}\sum_{A' \in [B]^d}
    \frac{1}{C^{\ell}_L}
    \sum_{X\in \XXell}
    \left[\exists a \in A' \colon n(a, X) \leq s(\eps)\right].
\]
Переставим местами знаки суммирования и применим логическое отрицание:
\[
\bar{Q}_{\eps}(B, d) =
    1 -
    \frac 1 \CLl
    \frac{1}{C^d_{|B|}}
    \sum_{X\in \XXell}
    \underbrace{\sum_{A' \in [B]^d}
    \left[\forall {a \in A'} \colon n(a, X) > s(\eps)\right]}_{F_\eps(B, \, X)}.
\]
Заметим, что выделенное в прошлой формуле выражение $F_\eps(B, X)$ соответствует числу способов
выбрать из $B$ подмножество $A'$ мощности $d$ так, чтобы ни один из алгоритмов в $A'$ не был переобученным.
Обозначим через $N_\eps(B, X)$ общее число алгоритмов в $B$, непереобученных на разбиении $X$.
Тогда $F_\eps(B, X)$ является числом сочетаний из $N_\eps(B, X)$ по $d$:
\[
\bar{Q}_{\eps}(B, d) =
    1 - \frac 1{\CLl} \frac 1{C^d_{|B|}}\sum\limits_{X \in \XXell} C^d_{N_\eps(B, X)}.
\]
По теоремам \ref{th:sym1} и \ref{th:sym2} функция $C^d_{N_\eps(B, X)}$, где $N_\eps(B, X) = \sum\limits_{a \in B}[n(a, X) > \eps]$, является симметричной функцией третьего рода,
и, следовательно, \eqref{eq_thTolstR2} факторизуется по действию группы симметрий на множестве разбиений:
\[
\bar{Q}_{\eps}(B, d) =
    1 -
    \frac{1}{C^{\ell}_L}
    \frac{1}{C^d_{|B|}}
    \sum_{\tau\in \Omega(\XXell)}
    |\tau| C_{N_\eps(B, X_\tau)}^{d}.
\]
\end{Proof}

При больших значениях параметра $d$ дробь $\frac{C^d_{N_\eps(B, X)}}{C_{|B|}^d}$ приближенно равна $\Big(\frac{N_\eps(B, X_\tau)}{|B|}\Big)^{d}$.
Таким образом, вклад разбиения $(X, \bar X)$ в вероятность переобучения
полностью определяется мощностью $d$ рассматриваемых подмножеств и числом алгоритмов из $B$, непереобученных на разбиении $(X, \bar X)$.

Покажем,~как вычислять оценку \eqref{eq_thTolstR2} на примере локальной окрестности $\hat B_{r,\rho}^{m}$.

\begin{Theorem}
\label{th:crazyFormula}
Средняя вероятность переобучения случайного подмножества $A_i \subset \hat B_{r,\rho}^{m}$ фиксированной мощности $d$ даётся следующей формулой:
\begin{equation}
\label{crazyFormula}
    \bar{Q}_{\eps}(\hat B_{r,\rho}^{m},d) = 1 -
        \frac 1{\CLl}
            \sum_{i = 0}^{\min(m, \ell)} \sum_{j = 0}^{\min(r, \ell - i)}
                C_m^i C_r^j C_{L - m - r}^{\ell - i - j} \frac{C^d_{N_{i, j}}}{C^d_{|\hat B_{r,\rho}^{m}|}},
\end{equation}
где
\[
    N_{i, j} = \sum_{t = 0}^{\min(j, \rho)} C_{j}^{t} C_{r - j}^{\rho - t} [i + t > s(\eps)].
\]
\end{Theorem}

\begin{Proof}
Рассмотрим три симметрические группы перестановок $S_m$, $S_r$  и $S_{L - m - r}$, действующие на множествах $X_1$, $X_r$ и $X_0$, соответственно.
Группой симметрий множества алгоритмов $\hat B_{r,\rho}^{m}$ является декартово произведение $S_m \times S_r \times S_{L - m - r}$.
Орбиты действия $\Sym(\hat B_{r,\rho}^{m})$ на $\XXell$ индексируются двумя параметрами, $i = |X \cap X_1|$ и $j = |X \cap X_r|$, где $X$ "--- обучающая выборка.
Мощность орбиты $\tau_{i, j}$ даётся, соответственно, выражением $|\tau_{i, j}| = C_m^i C_r^j C_{L - m - r}^{\ell - i - j}$.

Разобравшись с симметриями, необходимо для представителя $X_{i, j} \in \tau_{i, j}$ вычислить величину $N_{i, j} = N(\hat B_{r,\rho}^{m}, X_{i, j})$ "---
количество алгоритмов из $\hat B_{r,\rho}^{m}$, непереобученных на разбиении $X_{i, j}$.
Рассмотрим произвольный алгоритм $a \in \hat B_{r,\rho}^{m}$ и обозначим через $t$ количество ошибок данного алгоритма на $X \cap X_r$.
Тогда данный алгоритм делает $i + t$ ошибок на обучении, и, следовательно, условие того, что он не переобучен, записывается в виде $i + t > s(\eps)$, где $s(\eps) = \frac{\ell}{L}(m + \rho - \eps k)$.
Количество алгоритмов в $\hat B_{r,\rho}^{m}$ с данным значением параметра $t$ равно $C_{j}^{t} C_{r - j}^{\rho - t}$.
Суммируя по $t$, получим количество непереобученных алгоритмов:
\[
    N_{i, j} = \sum_{t = 0}^{\min(j, \rho)} C_{j}^{t} C_{r - j}^{\rho - t} [i + t > s(\eps)].
\]
Тогда, по теореме \ref{thTolstR2}, вероятность переобучения случайного подмножества $\hat B_{r,\rho}^{m}$, состоящего из $d$ алгоритмов, даётся следующей формулой:
\begin{equation}
    \bar{Q}_{\eps}(\hat B_{r,\rho}^{m},d) = 1 -
        \frac 1{\CLl}
            \sum_{i = 0}^{\min(m, \ell)} \sum_{j = 0}^{\min(r, \ell - i)}
               |\tau_{i,j}| \frac{C^d_{N_{i, j}}}{C^d_{|\hat B_{r,\rho}^{m}|}},
\end{equation}
где $\tau_{i,j}$ и $N_{i, j}$ определены выше.
\end{Proof}

Теорема \ref{th:crazyFormula} позволяет уточнить верхнюю оценку вероятности переобучения \eqref{eq:decompToBallSlicePZM}.
Для~этого будем оценивать $Q_\eps(A_i)$ с помощью $\bar Q_\eps(B_{r,\rho}^{m})$, где
$d$ "--- мощность $A_i$, $m$ "--- число объектов, на которых ошибаются все $a \in A_i$,  $r$ "--- число таких объектов, для которых хотя бы два алгоритма из $A_i$ дают разную классификацию,
$\rho$ "--- среднее число ошибок алгоритмов из $A_i$ на множестве $X_r$.
Отметим, что в~данном случае оценка $\Q(A_i) \leq \bar{Q}_\eps(\hat B_{r,\rho}^{m})$ является эвристикой.

\section{Эксперимент}
Проведем экспериментальное сравнение оценки расслоения-сходства \eqref{generalizedPZMtheorem} с тремя комбинаторными оценками
(VC- и SC-оценками из \cite{voron10roai}, ES-оценкой из \cite{esokolov12ioi}) и двумя PAC-Bayesian оценками из \cite{jin2012pacbayes}.

В качестве исходных данных были взяты 11 задач из репозитория UCI \cite{ucirepository}.
Описание задач приводится в таблице \ref{tab:datasets}.
На этапе предобработки удалялись объекты с хотя бы одним пропущенным признаком.
После этого каждый признак нормировался в интервал $[0, 1]$.
Для многоклассовых задач целевые классы были вручную сгруппированы в два класса.

\begin{table}[h]
\caption{Описание задач.}
\label{tab:datasets}
    \centering
    \begin{tabular}[t]{||c|c|c||c|c|c||}
    \hline
    Задача&\#Объектов&\#Признаков&Задача&\#Объектов&\#Признаков \\
\hline
    Glass       & 214   &   9   &   Statlog    & 2310  & 19 \\
    Liver dis.  & 345   &   6   &   Wine       & 4898  & 11 \\
    Ionosphere  & 351   &   34  &   Waveform   & 5000  & 21 \\
    Australian  & 690   &   6   &   Pageblocks & 5473  & 10 \\
    Pima        & 768   &   8   &   Optdigits  & 5620  & 64 \\
    Faults      & 1941  &   27  &              &       &    \\
\hline
\end{tabular}
\end{table}

Для каждой задачи мы выполняли процедуру пятикратной кросс-валидации, которая запускалась 100 раз для усреднения результатов.
Таким образом, для каждой задачи мы генерировали $M = 500$ разбиений $\XX = \XX_L^i \sqcup \XX_K^i$, $i = 1, \dots, M$
и вычисляли оценку Монте-Карло для среднего уклонения частот ошибок логистической регрессии:
\[
  \hat \delta_L(\mu_{\LR}, \XX) = \frac{1}{M}\sum_{i=1}^M \nu(\mu_{\LR} \XX_L^i, \XX_K^i) - \nu(\mu_{\LR} \XX_L^i, \XX_L^i).
\]
После этого каждая обучающая выборка $\XX_L$ использовалась для вычисления комбинаторной оценки
на уклонение частот ошибок МЭР.
Множества алгоритмов $A$, из которого МЭР выбирал лучший алгоритм,
генерировалось с помощью случайных блужданий по графу расслоения-связности линейных классификаторов \cite{esokolov12ioi}.
В качестве начального приближения для случайного блуждания использовался алгоритм $\mu_{\LR} \XX_L$, настроенный логистической регрессией по обучающей выборке $\XX_L$.
Далее вновь использовался метод Монте-Карло: генерировались
$M' = 4096$ случайных разбиений $\XX_L = X^j_\ell \sqcup X^j_k$, $j = 1, \dots, M'$
(при $\frac{\ell}{L} = 0.8$)
и вычислялась следующая величина:
\[
    \hat \delta_\ell(\mu, \XX_L) = \frac 1{M'}\sum_{j=1}^{M'}\nu(\mu X^j_\ell, X^j_k) - \nu(\mu X^j_\ell, X^j_\ell),
\]
где $\mu$ "--- метод минимизации эмпирического риска.
В заключение эта величина усреднялась по всем разбиениям $\XX = \XX_L^i \sqcup \XX_K^i$.
Величины $\hat \delta_L(\mu_{\LR}, \XX)$ и $\hat \delta_\ell(\mu, \XX_L)$ соответствуют реальному переобучению логистической регрессии и его идеальной оценке в рамках комбинаторного подхода.

В таблице \ref{tab:compareToPacBayes} сравниваются следующие величины: 
    $\hat \delta_L(\mu_{\LR}, \XX)$ и $\hat \delta_\ell(\mu, \XX_L)$;
    четыре верхние комбинаторные оценки величины $\hat \delta_\ell(\mu, \XX_L)$, обозначенные как VC, SC, ES и AF;
    две PAC-Bayes оценки (обозначены как DD и DI).
В отличие от комбинаторных оценок, ограничивающих уклонение частот ошибок, PAC-Bayes оценки справедливы непосредственно для частоты ошибок на контроле (приведена в столбце <<Ошибка тест>>).
DD-оценка учитывает размерность пространства признаков и является более точной по сравнению с~универсальной DI-оценкой, справедливой для любого числа признаков.

Комбинаторная SC-оценка соответствует оценке расслоения-связности из \cite{voron10roai}.
VC"~оценка~также приведена в \cite{voron10roai}, и она, в отличие от SC-оценки, не учитывает ни расслоение, ни связность.
ES-оценка \cite{esokolov12ioi} основана на более тонком учёте расслоения, при~котором каждый алгоритм сравнивается со всем множеством найденных истоком графа расслоения-связности.

AF-оценка, предлагаемая нами в данной статье, получена из оценки расслоения-сходства \eqref{generalizedPZMtheorem}.
Чтобы полностью конкретизировать оценку \eqref{generalizedPZMtheorem}, необходимо уточнить следующее:
метод разбиения исходного множества алгоритмов $A$ на кластеры,
способ выбора порождающих и запрещающих множеств для каждого кластера,
способ оценивания вероятности переобучения каждого кластера.
В AF-оценке порождающие и запрещающие множества выбирались в соответствии с \eqref{klasterPZM},
для оценки вероятности переобучения каждого кластера используется формула \eqref{crazyFormula},
а представление множества алгоритмов $A$ в виде $A = A_1 \sqcup \dots \sqcup A_t$
производится с помощью иерархической кластеризации при выборе расстояния дальнего соседа.
Исходная метрика на $A$ определяется как хэммингово расстояние между векторами ошибок алгоритмов.
%Именно эта конфигурация оценки \eqref{generalizedPZMtheorem} подразумевается под AF-оценкой.

\begin{table}[t]
      \caption{Сравнение фактического переобучения и различных оценок.
%        TrainErr stands for $\nu_L(\mu_\LR, \XX)$,
%        TestErr for $\bar \nu_L(\mu_\LR, \XX)$,
%        Overfit is their difference, %for $\bar \nu_L(\mu_\LR, \XX) - \nu_L(\mu_\LR, \XX)$
%        $\delta_\ell(\mu) \equiv \bar \nu_\ell(\mu, \XX_L) - \nu_\ell(\mu, \XX_L)$.
}
      \label{tab:compareToPacBayes}
      \centering
        \begin{tabular}[t]{||l||r|r|r|r|r|r|r|r|r||}
        \hline
        &
        \multicolumn{1}{|c|}{Ошибка}&
        \multicolumn{2}{|c|}{Переобучение}&
        \multicolumn{4}{|c|}{Комбинаторные оценки} &
        \multicolumn{2}{|c|}{PAC-Bayes}
        \\
        \hline
            Task&
            Тест &
            $\hat\delta_L(LR)$ &
            $\hat\delta_\ell(\mu)$&
            VC&
            SC&
            ES&
            AF&
            DI&
            DD \\
        \hline
            glass		& 0.076	& 0.030	& 0.067	& 0.191	& 0.127	& 0.124	& 0.106	& 1.268	& 0.740 \\
            Liver dis.	& 0.315	& 0.017	& 0.046	& 0.249	& 0.192	& 0.146	& 0.161	& 1.207	& 1.067 \\
            Ionosphere	& 0.126	& 0.079	& 0.042	& 0.138	& 0.099	& 0.087	& 0.084	& 1.219	& 1.149 \\
            Australian	& 0.136	& 0.014	& 0.023	& 0.130	& 0.101	& 0.081	& 0.086	& 1.145	& 0.678 \\
            pima		& 0.227	& 0.007	& 0.021	& 0.151	& 0.117	& 0.090	& 0.098	& 0.971	& 0.749 \\
            faults		& 0.210	& 0.011	& 0.008	& 0.091	& 0.070	& 0.046	& 0.060	& 1.110	& 1.054 \\
            statlog		& 0.142	& 0.004	& 0.008	& 0.072	& 0.060	& 0.043	& 0.051	& 1.102	& 0.746 \\
            wine		& 0.250	& 0.002	& 0.003	& 0.061	& 0.047	& 0.032	& 0.040	& 0.776	& 0.637 \\
            waveform	& 0.105	& 0.003	& 0.003	& 0.043	& 0.033	& 0.023	& 0.023	& 0.561	& 0.354 \\
            pageblocks	& 0.051	& 0.001	& 0.003	& 0.030	& 0.022	& 0.016	& 0.018	& 0.739	& 0.186 \\
            Optdigits	& 0.121	& 0.006	& 0.003	& 0.043	& 0.034	& 0.023	& 0.026	& 1.068	& 0.604 \\
        \hline
        \end{tabular}
    \end{table}
Из экспериментальных данных следует, что переобучение логистической регрессии хорошо приближается комбинаторной оценкой $\hat \delta_\ell(\mu, \XX_L)$ для МЭР.
Все четыре комбинаторные оценки существенно точнее обеих PAC-bayes оценок.
Среди комбинаторных оценок наименее завышенной оказывается ES-оценка.
За ней следует предложенная нами AF-оценка.
Каждая из этих оценок существено уточняет SC-оценку расслоения-связности.
Улучшение точности в ES- и AF-оценках основано на двух различных эффектах "--- более тонком учете расслоения в ES-оценке и учете сходства алгоритмов в~AF"~оценке.
Представляется возможным, что объединение ES- и AF"~оценок позволит добиться еще большего качества комбинаторных оценок вероятности переобучения.

\section{Выводы}
В данной работе предложена новая оценка вероятности переобучения, учитывающая расстояния между векторами ошибок алгоритмов.
Оценка основана на разложении множества алгоритмов на кластеры, т.е. на непересекающиеся подмножества, состоящие из~алгоритмов с похожими векторами ошибок.
Для каждого такого кластера применяется верхняя оценка вероятности переобучения, учитывающая хэммингов диаметр кластера и его мощность.
По аналогии с уже существующими оценками расслоения-связности доказана новая оценка, одновременно учитывающая и эффект расслоения по числу ошибок, и эффект сходства алгоритмов.
Вывод данной оценки существенно опирается на теоретико-групповой подход.
Эффективность полученных оценок продемонстрирована на примере 11 задач из репозитория UCI.
Показано, что предлагаемый метод в ряде случаев даёт более точную оценку переобучения по сравнению с уже известным оценками.
\begin{thebibliography}{1}
\bibitem{vapnik74rus}
    \BibAuthor{Вапник\;В.\,Н., Червоненкис\;А.\,Я.}
    \BibTitle{Теория распознавания  образов}. "---
    М.:~Наука, 1974.
\bibitem{vapnik98stat}
    \BibAuthor{Vapnik~V.}
    \BibTitle{Statistical Learning Theory}. "---
    New York: Wiley, 1998.
\bibitem{voron09dan}
    \BibAuthor{Воронцов\;К.\,В.}
    \BibTitle{Точные оценки вероятности переобучения}~//
    Доклады РАН, 2009. "--- Т.\,429, \No\,1.  "--- С.\,15--18.
%\bibitem{voron09mmro}
%    \BibAuthor{Воронцов\;К.\,В.}
%    \BibTitle{Комбинаторный подход к~проблеме переобучения}~//
%    Всеросс. конф. ММРО-14 "--- М.:~МАКС Пресс, 2009. "---  \mbox{С.\,18--21}.
\bibitem{voron09pria}
    \BibAuthor{Vorontsov\;K.\,V.}
    Splitting and Similarity Phenomena in the Sets of Classifiers and Their Effect on the Probability of Overfitting~//
    {Pattern Recognition and Image Analysis.} ~---
    2009.~---
    Vol.\,19, No.\,3.~---
    Pp.\,412--420.
\bibitem{voron10pria}
    \BibAuthor{Vorontsov\;K.\,V.}
    Exact combinatorial bounds on the probability of overfitting for empirical risk minimization~//
    {Pattern Recognition and Image Analysis.} ~---
    2010.~---
    Vol.\,20, No.\,3.~---
    Pp.\,269--285.
\bibitem{voron10roai}
    \BibAuthor{Vorontsov\;K.\,V., Ivahnenko\;A.\,A., Reshetnyak\;I.\,M.}
    \BibTitle{Generalization bound based on the splitting and connectivity graph of the set of classifiers}~//
    Pattern Recognition and Image Analysis: new information technologies (PRIA-10),
    St.~Petersburg, Russian Federation, December 5--12, 2010.
\bibitem{frey10ioi}
    \BibAuthor{Фрей\;А.\,И.}
    \BibTitle{Вероятность переобучения плотных и~разреженных многомерных~сеток алгоритмов}~//
    Междунар. конф. ИОИ-8 "--- М.:~МАКС Пресс, 2010.  "---  \mbox{С.\,87--90}.
\bibitem{voron11premi}
    \BibAuthor{Vorontsov\;K.\,V., Ivahnenko\;A.\,A.}
    \BibTitle{Tight Combinatorial Generalization Bounds for Threshold Conjunction Rules}~//
    4-th International Conference on Pattern Recognition and Machine Intelligence,
    June~27 -- July~1, 2011.
    Lecture Notes in Computer Science. Springer-Verlag, 2011.~--- Pp. 66--73.
\bibitem{frey12ioi}
    \BibAuthor{Фрей~А.\,И., Ивахненко~А.\,А, Решетняк~И.\,М.}
    \BibTitle{Применение комбинаторных оценок вероятности переобучения в~простом голосовании конъюнкций}~//
    Междунар. конф. ИОИ-9 "--- М.:~МАКС Пресс, 2012.  "---  \mbox{С.\,86-89}.
\bibitem{bax97similarity}
    \BibAuthor{E.\,Bax.}
    \BibTitle{Similar Classifiers and VC Error Bounds}~//
    Tech. Rep. CalTech-CS-TR97-14: 1997.
\bibitem{frey09mmro}
    \BibAuthor{Фрей\;А.\,И.}
    \BibTitle{Точные оценки вероятности переобучения для симметричных семейств алгоритмов}~//
    Всеросс. конф. ММРО-14 "--- М.:~МАКС Пресс, 2009.  "---  \mbox{С.\,66--69}.
\bibitem{frey10pria}
    \BibAuthor{Фрей\;А.\,И.}
    \BibTitle{Точные оценки вероятности переобучения для симметричных семейств алгоритмов и рандомизированных методов обучения}~//
    Pattern Recognition and Image Analysis. "--- 2010.
\bibitem{tolstihin10ioi}
    \BibAuthor{Толстихин\;И.\,О.}
    \BibTitle{Вероятность переобучения плотных и разреженных семейств алгоритмов}~//
    Междунар. конф. ИОИ-8 "--- М.:~МАКС Пресс, 2010.  "---  \mbox{С.\,83--86}.
\bibitem{esokolov12ioi}
    \BibAuthor{Соколов\;Е.\,А., Воронцов\;К.\,В.}
    \BibTitle{Минимизация вероятности переобучения для композиций линейных классификаторов малой размерности}~//
    Междунар. конф. ИОИ-9 "--- М.:~Торус Пресс, 2012. "--- \mbox{С.\,82--85}.
\bibitem{jin2012pacbayes}
     Jin\;C., Wang\;L.~(2012)
     Dimensionality Dependent PAC-Bayes Margin Bound.
     \emph{In Advances in Neural Information Processing Systems}, 25, 1043--1051.
\bibitem{ucirepository}
    \BibAuthor{K.\,Bache, M.\,Lichman.}
    \BibTitle {UCI} Machine Learning Repository~//
    University of California, Irvine, School of Information and Computer Sciences. "--- 2013.
    %http://archive.ics.uci.edu/ml.

%\bibitem{botov09mmro}
%    \BibAuthor{Ботов\;П.\,В.}
%    \BibTitle{Точные оценки вероятности переобучения для монотонных и~унимодальных семейств алгоритмов}~//
%    Всеросс. конф. ММРО-14 "--- М.:~МАКС Пресс, 2009.  "---  \mbox{С.\,7--10}.
\end{thebibliography}

% Решение Программного Комитета:
%\ACCEPTNOTE
%\AMENDNOTE
%\REJECTNOTE
\end{document}

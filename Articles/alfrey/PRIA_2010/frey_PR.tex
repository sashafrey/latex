\documentclass[12pt]{article}

\usepackage[cp1251]{inputenc}
\usepackage[russian]{babel}
\usepackage{color}
\usepackage{amssymb,amsmath,amsthm}
\usepackage{graphicx}
\usepackage{multicol}
\usepackage{indentfirst}

\textheight=26cm
\textwidth=17cm
\oddsidemargin=0mm
\topmargin=-20mm
\parindent=24pt
\tolerance=500
%\renewcommand{\baselinestretch}{1.3} %для печати с большим интервалом

\newcommand{\RR}{\mathbb{R}}
\newcommand{\XX}{\mathbb{X}}
\newcommand{\Xl}{X}
\newcommand{\Xk}{\bar X}
\newcommand{\XXell}{[\XX]^\ell}
\renewcommand{\AA}{\mathbb{A}}
\newcommand{\fA}{\mathfrak{A}}
\newcommand{\Argmin}{\mathop{\rm Argmin}\limits}
\newcommand{\Sym}{\mathop{\rm Sym}\limits}
\renewcommand{\geq}{\geqslant}
\renewcommand{\leq}{\leqslant}
\renewcommand{\epsilon}{\varepsilon}
\def\brop#1{#1\discretionary{}{\hbox{$#1$}}{}} % перенос знака операции на следующую строку
\renewcommand{\em}{\it}

\theoremstyle{plain}
\newtheorem{Theorem}{Теорема}
\newtheorem{Lemma}[Theorem]{Лемма}
\newtheorem{State}[Theorem]{Утверждение}
\theoremstyle{definition}
\newtheorem{Def}{Определение}
\newtheorem{Definition}[Def]{Определение}
\newtheorem{Corollary}{Следствие}
\newtheorem{Hypothesis}{Гипотеза}
\newtheorem{Task}{Задача}
\newtheorem{Example}{Пример}

% Проглотить следующий пробел
\makeatletter
\def\gobblespace{\@ifnextchar\ {\hspace{-1ex}}\relax}
\makeatother
% Вставка замечания рецензента
\newcommand\REVIEWERNOTE[1]{{%
    \itshape\bfseries%\color{red}%
    \marginpar{%\raisebox{-1ex}{%\color{red}%
        $\checkmark$%\!_{\themmroReviewerNote}
    }%}%
    \{#1\}
}\gobblespace}

\begin{document}

\begin{center}
{\Large \bf Точные оценки обобщающей способности
    для~симметричных множеств алгоритмов
    и~рандомизированных методов обучения}

\vspace{0.2cm}

{\bf Фрей А. И.}

\vspace{0.1cm}

{\bf (МФТИ) }
\end{center}

%\abstract {
    В~комбинаторном подходе к~проблеме переобучения основной задачей является
    получение вычислительно эффективных формул для вероятности переобучения.
    %и~вероятности получить каждый из~имеющихся алгоритмов в~результате обучения.
    Предлагается теоретико-групповой подход, который позволяет проще выводить такие формулы в~тех случаях,
    когда множество алгоритмов наделено некоторой группой симметрий.
    Приводятся примеры таких множеств.
    Для рандомизированного метода обучения
    доказывается общая оценка вероятности переобучения.
    Показывается её применение для~четырёх модельных множеств алгоритмов:
    слоя булева куба, булева куба, унимодальной цепочки и~связки монотонных цепочек.
%}

\tableofcontents

\newpage

\section{Введение}

При решении задач
распознавания образов, восстановления регрессии, прогнозирования
всегда возникает проблема выбора по~неполной информации.
Имея лишь конечную обучающую выборку объектов,
требуется из~заданного множества алгоритмов выбрать алгоритм, который
ошибался~бы как можно реже
не~только на~объектах наблюдаемой обучающей выборки,
но~и~на~объектах скрытой контрольной выборки,
которая в~момент выбора алгоритма ещё неизвестна.
Если частота ошибок на~контрольной выборке
оказывается значительно выше, чем на~обучающей,
то~говорят, что произошло
<<переобучение>> (overtraining) или
<<переподгонка>> (overfitting) алгоритма "---
он~слишком хорошо описывает конкретные данные,
но~не~обладает способностью к~обобщению этих данных,
не~восстанавливает порождающую их~зависимость
и~не~пригоден для построения прогнозов.

Частоту ошибок на~обучающей выборке называют также \emph{эмпирическим риском}.
\emph{Минимизация эмпирического риска} "--- это
метод обучения, который выбирает из~заданного множества алгоритм,
допускающий наименьшее число ошибок на~обучающей выборке~%
\cite{vapnik74rus,vapnik98stat}.
В~следующей таблице показан пример, когда минимизация эмпирического риска приводит к~переобучению.
Столбцы таблицы соответствуют алгоритмам,
строки "--- объектам обучающей выборки $\{x_1,x_2,x_3\}$ и~контрольной выборки $\{x_4,x_5,x_6\}$.
Единица в~$[i,d]$-й ячейке таблицы означает, что
алгоритм~$a_d$ допускает ошибку на~объекте~$x_i$.
\[
    \bordermatrix{
          & a_1 & a_2 & \dots & a_d & \dots & a_D \cr
    x_1 & 0 & 1 & \dots & {0} & \dots & 1 \cr
    x_2 & 1 & 1 & \dots & {0} & \dots & 0 \cr
    x_3 & 0 & 0 & \dots & {0} & \dots & 0 \vspace{-2ex}\cr\cline{2-7}
    x_4 & 1 & 1 & \dots & {1} & \dots & 1 \cr
    x_5 & 1 & 0 & \dots & {1} & \dots & 0 \cr
    x_6 & 0 & 0 & \dots & {1} & \dots & 0
    }
\]

В данном примере переобучение могло быть следствием <<неудачного>> разбиения
генеральной выборки на~обучение и~контроль.
Поэтому вводится функционал \emph{вероятности переобучения},
равный доле разбиений выборки, при которых возникает переобучение~\cite{voron09dan, voron09mmro}.
Этот функционал инвариантен относительно выбора разбиения
и~характеризует качество данного метода обучения на~данной генеральной выборке.

Для некоторых семейств простой структуры
(монотонных и~унимодальных цепочек и~$h$"~мерных сеток)
в~\cite{voron09dan,botov09mmro} найдены точные выражения вероятности переобучения.
В~данной работе развивается теоретико"=групповой подход~\cite{frey09mmro}, позволяющий выводить
эффективные оценки вероятности переобучения для множеств алгоритмов,
обладающих свойствами симметрии.

\subsection{Определения}

Пусть задана генеральная выборка $\XX=\bigl( x_1, \dots, x_L)$, состоящая из~$L$ объектов.
Произвольный алгоритм классификации, примененный к~данной выборке, порождает бинарный вектор
ошибок $a \equiv \bigl( a(x_i) \bigr){}_{i=1}^L$,
где $a(x_i) = 1$ означает, что
алгоритм~$a$ допускает ошибку на объекте~$x_i$.
Генеральная выборка $\XX$ предполагается фиксированной, поэтому алгоритмы
отождествляются со~своими векторами ошибок.

Обозначим
через $\AA = \{0, 1\}^L$ множество всех возможных векторов ошибок длины $L$,
тогда $2^{\AA}$ "--- это множество всех подмножеств $\AA$.
Заметим, что $|\AA|=2^L$,\; $|2^{\AA}|=2^{2^L}$.

Через $\XXell$ обозначим множество всех разбиений генеральной выборки $\XX$
на обучающую выборку $\Xl$ длины~$\ell$ и~контрольную выборку $\Xk$ длины $k=L-\ell$.

\emph{Число ошибок} алгоритма $a$ на~выборке $U \subseteq \XX$
обозначим через $n(a, U) = \sum \limits_{x \in U}a(x)$.

\emph{Детерминированным методом обучения} назовем произвольное отображение вида
$\mu \colon 2^\AA \times \XXell \rightarrow \AA$.
Метод обучения~$\mu$ по~обучающей выборке~$\Xl$
выбирает некоторый алгоритм $a=\mu(A,\Xl)$ из~подмножества $A \subseteq \AA$.
Метод обучения называется \emph{минимизацией эмпирического риска}, если
возвращаемый им алгоритм допускает наименьшее число ошибок на~обучении:
для всех $\Xl \in \XXell$ и~$A \subseteq \AA$ выполнено
$\mu (A, \Xl) \in A(\Xl)$,
где
\[
    A(\Xl) = \Argmin_{a \in A} n(a, \Xl).
\]

При минимизации эмпирического риска может возникать неоднозначность "---
несколько алгоритмов из~$A(\Xl)$ могут иметь одинаковое число ошибок на~обучающей выборке.
В~\cite{voron09mmro} для устранения неоднозначности и~получения точных верхних
оценок вероятности переобучения использовалась \emph{пессимистичная}
минимизация эмпирического риска "--- предполагалось, что в~случае неоднозначности
выбирается алгоритм с~наибольшим числом ошибок на~генеральной выборке~$\XX$.
Это не~устраняет неоднозначность окончательно.
Возможны ситуации, когда несколько алгоритмов имеют
наименьшее число ошибок на~обучающей выборке~$\Xl$
и~одинаковое число ошибок на~генеральной выборке~$\XX$.
\mbox{В~таких} случаях на~множестве алгоритмов вводился линейный порядок,
и~среди неразличимых алгоритмов выбирался алгоритм с~б\'ольшим порядковым номером.
Введение приоритетности алгоритмов является искусственным приемом,
не~имеющим адекватных аналогов среди известных методов обучения.

\subsection{Рандомизированный метод обучения}

\emph{Рандомизированный метод обучения} произвольному множеству алгоритмов $A\subseteq \AA$
и~произвольной обучающей выборке~$\Xl \in \XXell$ ставит в~соответствие функцию
распределения весов на~множестве~алгоритмов:
\begin{equation}
    \label{eq:randomizedSearchMethodDraft}
    \mu : 2^\AA \times \XXell \rightarrow \{f : \AA \rightarrow [0, 1]\}.
\end{equation}
Естественно полагать, что эта функция нормирована и~может быть интерпретирована как вероятность
получить каждый алгоритм в~результате обучения.

Детерминированный метод обучения является частным случаем рандомизированного,
когда функция распределения весов~$f(a)$
принимает единичное значение ровно на~одном алгоритме и~нулевое на~всех остальных.

Заметим, что вместо определения \eqref{eq:randomizedSearchMethodDraft}
можно пользоваться эквивалентным способом задать то~же самое отображение:
\[
    \mu : 2^\AA \times \XXell \times \AA \rightarrow [0, 1].
\]

Рассмотрим группу $S_L$ "--- симметрическую группу из~L элементов, действующую на~множестве
объектов генеральной выборки перестановками $S_L = \{ \pi \colon \XX \rightarrow \XX\}$.

Для каждого $\pi \in S_L$ определим действие $\pi$ на~произвольную выборку $\Xl \in \XXell$
поэлементным действием отображения $\pi \colon \XX \rightarrow \XX$
на каждый объект выборки $\Xl$: $ \pi \Xl \brop= \{ \pi x \colon x \in \Xl\}$.
Это отображение не~меняет числа объектов: $|\Xl| = |\pi \Xl|$, поэтому можно
говорить о~действии $\pi$ на~множестве разбиений генеральной выборки на~обучение и~контроль
фиксированной длины $\pi : \XXell \rightarrow \XXell$.

Определим действие $S_L$ на~множестве всех алгоритмов $\AA$ перестановкой координат векторов
ошибок алгоритмов: $(\pi a)(x_i)= a(\pi^{-1}x_i)$.
Здесь на~объекты действует обратная перестановка $\pi^{-1}$, поскольку именно
в этом случае корректно говорить, что группа~$S_L$ \emph{действует} на~множестве~$\AA$.

\begin{Lemma}
\label{lem:errorCountInvariance}
Число ошибок алгоритма $a$ на~подвыборке $U \subseteq \XX$ не~меняется от~одновременного
применения перестановки $\pi \in S_L$ к~алгоритму и~к подвыборке:
\begin{equation}
    n(a, U) = n(\pi a, \pi U).
\end{equation}
\end{Lemma}

$\square$ \textbf{Доказательство.}
Запишем определение числа ошибок алгоритма и
воспользуемся определенным выше действием перестановки $\pi$ на~алгоритм $a$:
\[
\begin{aligned}
  n(\pi a, \pi U) =
& \sum_{x_i \in \pi U} (\pi a)(x_i) =
  \sum_{x'_i \in U} (\pi a)(\pi x'_i) = \\
& \sum_{x'_i \in U} a(\pi^{-1}(\pi x'_i )) =
  \sum_{x'_i \in U} a(x'_i) =
  n(a, U). \;\;\;\blacksquare
\end{aligned}
\]

Действие группы $S_L$ на~множестве всевозможных алгоритмов $\AA$ естественным  образом продолжается
до действия на~системе всех подмножеств "--- $S_L \colon 2^\AA \rightarrow 2^\AA$ по~правилу
$\pi A = \{\pi a \colon a\in A\}$.
В дальнейшем будет использоваться единое обозначение $\pi$ для описанных выше действий.

Теперь можно дать более строгое определение рандомизированного метода обучения.

\begin{Def}\label{searchMethod}
    \label{def:randomizedSearchMethod}
    \emph{Рандомизированным методом обучения} назовем отображение вида
    \begin{equation}
        \label{eq:randomizedSearchMethod}
        \mu : 2^\AA \times \XXell \times \AA \rightarrow [0, 1],
    \end{equation}
    удовлетворяющее при любых
    $A \in 2^\AA$,\; ${\Xl \in \XXell}$,\; $a,\, b \in A$ и~$\pi \in S_L$
    условиям:
    \begin{enumerate}
        \item[1)] нормировка:
              \begin{equation}
                \sum\limits_{a \in A} \mu(A, \Xl, a) = 1;
              \end{equation}
        \item[2)] неразличимость алгоритмов с~одинаковой частотой ошибок на~обучении:
              \begin{equation}
              n(a, \Xl) = n(b, \Xl) \;\to\; \mu(A, \Xl, a) = \mu(A, \Xl, b);
              \end{equation}
        \item[3)] инвариантность результата обучения относительно замены множества алгоритмов $A$ на $\pi(A)$:
              \begin{equation}
              \label{eq:randomizedSearchMethod_3}
                    \mu(A, \Xl, a) = \mu \bigl( \pi A, \pi \Xl, \pi a \bigr).
              \end{equation}
    \end{enumerate}
\end{Def}

Первое условие означает <<вероятностную>> нормировку весов алгоритмов
и~обеспечивает нулевую <<вероятность>> алгоритмам, не~принадлежащих множеству~$A$.
Второе условие означает, что при любом разбиении $\XX = \Xl \sqcup \Xk$, $\Xl \in \XXell$
вероятность получить алгоритм в~результате обучения
зависит только от~количества ошибок алгоритма на~обучении.
Третье условие означает, что результат обучения не~изменится,
если подействовать перестановкой~$\pi$ одновременно
и~на~множество объектов~$\XXell$, и~на~множество алгоритмов~$\AA$.

Конструктивным примером рандомизированного метода обучения
является следующее отображение, которые мы назовем
\emph{рандомизированным методом минимизации эмпирического риска}:
\begin{equation}
    \label{eq:randomizedRiskMinimization}
    \mu(A, \Xl, a)
    =
    \frac{\bigl[ a \in A(\Xl) \bigr]}{|A(\Xl)|}.
\end{equation}

\begin{Theorem}
Отображение \eqref{eq:randomizedRiskMinimization}
является рандомизированным методом обучения.
\end{Theorem}

$\square$ \textbf{Доказательство.}
Первое условие проверяется явно:
\[
    \sum \limits_{a\in A}\mu(A,\Xl,a) =
    \sum \limits_{a \in A(\Xl)}\frac1{|A(\Xl)|} = 1.
    \]

Для доказательства второго утверждения достаточно заметить,
что два алгоритма $a_1$ и~$a_2$ с~равным числом ошибок на~обучении
могут лежат в~множестве $A(\Xl)$ только одновременно.
Следовательно, вероятность получить каждый из~алгоритмов в~результате обучения
равна либо нулю, либо $\frac 1{|A(\Xl)|}$.

Для проверки третьего условия достаточно доказать, что
\[
    a_0 \in \Argmin_{a \in A} n(a, \Xl)
    \;\;\Leftrightarrow\;\;
    \pi a_0 \in \Argmin_{a \in \pi A} n(a, \pi \Xl).\]

Используя лемму \ref{lem:errorCountInvariance},
проведем следующую цепочку равносильных утверждений:
\[
    \begin{aligned}
    a_0 \in & \Argmin_{a \in A} n(a, \Xl) \;\;\Leftrightarrow \\
    & \;\;\Leftrightarrow \;\;
    \forall a \in A \rightarrow n(a_0, \Xl) \leq n(a, \Xl) \;\; \Leftrightarrow\\
    & \;\; \Leftrightarrow \;\;
    \forall a \in A \rightarrow n\big(\pi a_0, \pi \Xl\big)
            \leq n\big(\pi a, \pi \Xl \big) \;\; \Leftrightarrow\\
    & \;\; \Leftrightarrow \;\;
    \forall a' \in \pi A \rightarrow n\big(\pi a_0, \pi \Xl \big)
            \leq n\big(a', \pi \Xl \big) \;\; \Leftrightarrow\\
    & \;\; \Leftrightarrow \;\;
    \pi a_0 \in \Argmin_{a \in \pi A} n(a, \pi \Xl).
    \end{aligned}
\]

Теорема доказана.
$\blacksquare$

\subsection {Вероятность переобучения}

Величину $\nu(a, U) = n(a, U) / |U|$ будем называть \emph{частотой ошибок}
алгоритма~$a$~на~выборке $U$.
\emph{Уклонение частот} на~разбиении $\XX = \Xl \sqcup \Xk$ определим как разность
частот ошибок на~контроле и~на обучении:
$\delta(a, \Xl) = \nu(a, \Xk) - \nu(a, \Xl)$.

Зафиксируем параметр $\epsilon \in (0, 1]$.
Будем говорить, что алгоритм $a$ \emph{переобучен} при разбиении $\Xl \sqcup \Xk$,
если $\delta(a, \Xl) \geq \epsilon$.

Сделаем основное (и~единственное) вероятностное предположение, что
все разбиения генеральной выборки на~наблюдаемую и~скрытую подвыборки равновероятны~%
\cite{voron09dan,voron09mmro}.

Если $\varphi\colon\XXell\to\{\text{истина},\text{ложь}\}$ "--- некоторый предикат,
то~\emph{вероятностью события}~$\varphi(\Xl)$ будем называть
долю разбиений выборки, при которых предикат $\varphi(\Xl)$ истинен:
\[
    \textbf{P}\bigl[\varphi(\Xl)\bigr]
    =
    \frac{1}{C_L^\ell}
    \sum\limits_{\Xl \in \XXell} \bigl[\varphi(\Xl)\bigr].
\]

Соответственно, математическое ожидание произвольной функции $\xi\colon\XXell\to\RR$ есть
\[
    \textbf{E} \xi(\Xl)
    =
    \frac{1}{C_L^\ell}
    \sum\limits_{\Xl \in \XXell} \xi(X).
\]

Вероятностью получить алгоритм~$a\in A$ в~результате обучения назовем величину
\begin{equation}
    \label{eq:algProbability}
    P_\mu(a,A)
    =
    %\frac1{C_L^\ell} \sum_{\Xl \in \XXell}
    \textbf{E}
    \mu(A, \Xl, a).
\end{equation}

Для произвольного  $\epsilon \in (0, 1]$ определим
\emph{вклад} алгоритма $a\in A$ в~вероятность переобучения:
\begin{equation}
    \label{eq:algContribution}
    Q_\mu(\epsilon, a, A)
    =
    %\frac1{C_L^\ell} \sum_{\Xl \in \XXell}
    \textbf{E}
    \mu(A, \Xl, a)
    \bigl[ \delta(a, \Xl) \geq \epsilon \bigr].
\end{equation}

\emph{Вероятность переобучения} определим как сумму вкладов по~всем алгоритмам:
\begin{equation}
    \label{eq:overfitProbability}
    Q_\mu(\epsilon, A)
    =
    \sum_{a\in A} Q_\mu(\epsilon, a,A)
    =
    %\frac1{C_L^\ell} \sum_{\Xl \in \XXell}
    \textbf{E}
    \sum_{a\in A}
        \mu(A, \Xl, a)
        \bigl[ \delta(a, \Xl) \geq \epsilon \bigr].
\end{equation}

Для детерминированного метода обучения $\mu \colon 2^\AA \times \XXell \rightarrow \AA$
это определение можно упростить:
\[
\begin{aligned}
    Q_\mu(\epsilon, A)
    &=
    \textbf{E}
        \sum_{a\in A}
            \bigl[ \mu(A, \Xl) = a \bigr]
            \bigl[ \delta(a, \Xl) \geq \epsilon \bigr] = \\
    &=
    \textbf{E}
            \bigl[ \delta(\mu(A, \Xl), \Xl) \geq \epsilon \bigr].
\end{aligned}
\]

Полученное выражение буквально означает <<долю разбиений выборки на~обучение и~контроль,
при которых выбранный алгоритм $a=\mu(A,X)$ оказался переобученным>>.

\begin{Def}
Методы минимизации эмпирического риска
\begin{align*}
    \mu_o \Xl &= \arg\!\!\min\limits_{a\in A(\Xl)} n(a,\Xk); \\
    \mu_p \Xl &= \arg\!\!\max\limits_{a\in A(\Xl)} n(a,\Xk);
\end{align*}
называются, соответственно, \emph{оптимистичным} и~\emph{пессимистичным}.
\end{Def}

\begin{Theorem}
Путь $\mu$ "--- рандомизированный метод минимизации эмпирического риска.
\mbox{Тогда} для произвольного
множества алгоритмов $A \subseteq \AA$ и каждого $\epsilon \in (0, 1]$ справедлива цепочка неравенств:
\begin{equation}
    \label{eq:sortedMethods}
    Q_{\mu_o}(\epsilon, A) \leq Q_{\mu}(\epsilon, A) \leq Q_{\mu_p}(\epsilon, A).
\end{equation}
\end{Theorem}
Эта теорема позволяет называть методы $\mu$, $\mu_p$ и~$\mu_o$ соответственно
выбором случайного, худшего и~лучшего алгоритма из~лучших на~обучении.

$\square$ \textbf{Доказательство.}
Для краткости обозначений будем опускать аргумент $A$ у отображений $\mu_o$ и~$\mu_p$.
Покажем, что утверждение верно для каждого разбиения выборки:
\[
        \bigl[ \delta(\mu_o(\Xl), \Xl) \geq \epsilon \bigr]
    \leq
        \sum_{a\in A(\Xl)} \frac 1{|A(\Xl)|}
        \bigl[ \delta(a, \Xl) \geq \epsilon \bigr]
    \leq
        \bigl[ \delta(\mu_p(\Xl), \Xl) \geq \epsilon \bigr].
\]

Введем обозначения:
\begin{align*}
    F_o &\equiv \bigl[ \delta(\mu_o(\Xl), \Xl) \geq \epsilon \bigr];\\
    F_p &\equiv \bigl[ \delta(\mu_p(\Xl), \Xl) \geq \epsilon \bigr];\\
    F\; &\equiv \frac 1{|A(\Xl)|} \sum \limits_{a\in A(\Xl)}
                \bigl[ \delta(a, \Xl) \geq \epsilon \bigr].
\end{align*}

Рассмотрим неравенство $F_o \leq F$. Заметим, что $F_o$ может принимать
только два значения "--- $0$ и~$1$, а~значение выражения $F$
ограничено отрезком $[0, 1]$. Следовательно, если $F_o = 0$ неравенство выполнено
автоматически.

Докажем, что из~$F_o = 1$ следует $F = 1$.
Обозначим $a_o \equiv \mu_o(\Xl)$.
По определению $\mu_o$ это значит, что
$a_o \in A(\Xl)$ и~$\forall a \in A(\Xl)$ выполнено
$n(a_o, \Xk) \leq n(a, \Xk)$.
Следовательно, $\forall a \in A(\Xl)$ выполнено
$\delta(a, \Xl) \geq \delta(a_o, \Xl) \geq \epsilon$.
Значит $F = \sum \limits_{a\in A(\Xl)} \frac 1{|A(\Xl)|} = 1$.

Для доказательства утверждения $F \leq F_p$ достаточно рассмотреть два случая: $F_p = 0$ и~$F_p = 1$
и провести аналогичные рассуждения.
$\blacksquare$

\section{Симметрия множества алгоритмов}
Введённые выше понятия позволяют определить группу симметрии множества алгоритмов
и~с~её помощью получать вычислительно эффективные формулы вероятности переобучения.

\subsection{Инвариантность вероятности переобучения к~действию группы $S_L$}

Определения рассмотренных выше функционалов $P_\mu(a, A)$, $Q_\mu(\epsilon, a, A)$ и~$Q_\mu(\epsilon, A)$
опирались на~упорядоченность объектов в~генеральной выборке $\XX$.
Докажем инвариантность указанных функционалов к~изменению
нумерации объектов~в~$\XX$.

Для краткости обозначений будем опускать аргумент $\epsilon$ у функции $Q_\mu(\epsilon, a, A)$.

\begin{Lemma}
    \label{Lem:PQ_invariance}
    Вероятность $P_\mu(a, A)$ получить алгоритм~$\,a$ в~результате обучения,
    а~также вклад $Q_\mu(a, A)$ алгоритма $a$  вероятность переобучения
    сохраняются при одновременном применении произвольной перестановки
    $\pi \in S_L$ к~множеству~$A$ и~алгоритму~$a$:
    \begin{align}
        P_\mu(a, A) &= P_\mu(\pi a, \pi A), \\
        Q_\mu(a, A) &= Q_\mu(\pi a, \pi A).
    \end{align}
\end{Lemma}
$\square$
    \textbf{Доказательство.}
    Заметим, что для произвольной функции $f(\Xl)$ от~разбиения выборки
    $\Xl \sqcup \Xk$ на~обучение и~контроль выполнено
    $\textbf{E} f(\Xl) = \textbf{E} f(\pi \Xl)$.
    Воспользуемся также свойством $\delta(\pi a, \pi \Xl) = \delta(a, \Xl)$,
    которое следует из~леммы \ref{lem:errorCountInvariance} и~определения
    уклонения частот ошибок алгоритма.
    Тогда
    \[
        \begin{aligned}
        Q_\mu(\pi a, \pi A)
        &= \textbf{E}%\frac 1{C_L^\ell} \sum_{\Xl \in \XXell}
            \mu(\pi A, \Xl, \pi a) \left[ \delta (\pi a, \Xl) \geq \epsilon \right] = \\
        &= \textbf{E}%\frac 1{C_L^\ell} \sum_{\Xl \in \XXell}
            \mu(\pi A, \pi \Xl, \pi a) \left[ \delta (\pi a, \pi \Xl)
            \geq \epsilon \right] = \\
        &= \textbf{E}%\frac 1{C_L^\ell} \sum_{\Xl \in \XXell}
            \mu(A, \Xl, a) \left[ \delta (a, \Xl) \geq \epsilon \right]
        = Q_\mu(a, A).
        \end{aligned}
    \]
    Равенство $P_\mu(\pi a, \pi A) = P_\mu(a, A)$  получается из
    выражения $Q_\mu(a, A) = Q_\mu(\pi a, \pi A)$ подстановкой $\epsilon = -1$.
$\blacksquare$

\begin{Corollary}
Вероятность переобучения сохраняется при применении произвольной перестановки $\pi \in S_L$ к множеству алгоритмов:
\begin{equation}
    Q_\mu(A) = Q_\mu(\pi A).
\end{equation}
\end{Corollary}
$\square$
    \textbf{Доказательство.}
\[
    Q_\mu(\pi A) =
    \sum_{a \in \pi A}Q_\mu(a, \pi A) =
    \sum_{a \in A}Q_\mu(\pi a, \pi A) =
    \sum_{a \in A}Q_\mu(a, A) =
    Q_\mu(A).
    \;\;\blacksquare
\]

Последнее утверждение выглядит очень естественно, поскольку
в большинстве задач обучения по~прецедентам порядок объектов в~выборке
не имеет значения.

\subsection{Группа симметрии множества алгоритмов}

Напомним, что выше было определено действие группы $S_L$ на~множестве
всех возможных наборов алгоритмов $2^\AA$.

\begin{Def}
    \label{def:symmetryGroup}
    \emph{Группой симметрий} $\Sym(A)$ множества алгоритмов $A\in 2^\AA$
    будем называть его стационарную подгруппу:
    \[
        \Sym(A) = \{\pi \in S_L \colon \pi A = A\}.
    \]
\end{Def}

\begin{Example}
Рассмотрим множество алгоритмов,
заданное следующей матрицей ошибок:
\[
    \bordermatrix{& a_1 & a_2 & a_3 & a_4 & a_5 \cr
        x_1 & 1 & 1 & 1 & 0 & 0 \cr
        x_2 & 0 & 1 & 1 & 1 & 0 \cr
        x_3 & 0 & 0 & 1 & 1 & 1 \cr
        x_4 & 1 & 0 & 0 & 1 & 1 \cr
        x_5 & 1 & 1 & 0 & 0 & 1 \cr
    }
\]
Строки матрицы соответствуют объектам генеральной выборки $\XX$,
столбцы --- алгоритмам $a \in A$.
Группа симметрии данного множества алгоритмов является диэдральной группой:
$\Sym(A) \cong S_2 \ltimes \mathbb{Z} \slash 5\, \mathbb{Z}$.
Образующими элементами группы являются циклическая перестановка
$\pi_{{}_\circlearrowright} = (x_1, x_2, x_3, x_4, x_5) \in S_5$ и~пара транспозиций
$\pi_{\!{}_\leftrightarrow} = (x_2, x_5)(x_3, x_4)$.
\end{Example}

Важно отметить, что группа симметрии $\Sym(A)$ \emph{действует} на~множестве алгоритмов~$A$.
Действительно, каждый элемент группы симметрий $\pi \in \Sym(A)$
переставляет алгоритмы $a$ только \emph{внутри }множества $A$.
Значит, для любого $a\in A$ и~любого $\pi \in \Sym(A)$ выполнено $\pi a \in A$.
Поэтому для группы $\Sym(A)$, в~отличии от~всей группы $S_L$,
естественным образом определено действие на~множестве $A$.

\emph{Орбитой} элемента $m$ множества $M$, на~котором действует группа $G$,
называется подмножество $Gm = \{g m \colon g \in G\} \subseteq M$.
Орбиты двух элементов $m_1$ и~$m_2$ либо не~пересекаются, либо совпадают.
Это позволяет говорить о разбиении множества $M$ на~непересекающиеся орбиты:
$M = G m_1 \sqcup \ldots \sqcup G m_k$.

В дальнейшем будут рассматриваться орбиты действия группы симметрии $\Sym(A)$
на множестве алгоритмов.
Совокупность всех орбит множества алгоритмов $A$ обозначим через $\Omega(A)$.
Представителя орбиты $\omega~\in~\Omega(A)$ обозначим через $a_\omega \in A$.

В теории групп точки одной орбиты принято называть эквивалентными.
Однако~в~\cite{vapnik74rus} \emph{эквивалентными алгоритмами} называют
алгоритмы с равными векторами ошибок на~генеральной выборке~$\XX$.
Поэтому различных представителей одной и~той же орбиты будем называть
\emph{идентичными алгоритмами}.

\begin{Lemma}
    \label{lemEqualErrorsCount}
    \emph Идентичные алгоритмы имеют равное число ошибок на~полной выборке.
\end{Lemma}
$\square$ Доказательство утверждения автоматически следует из~леммы \ref{lem:errorCountInvariance}:
\[n(a, \XX) = n(\pi a, \pi \XX) = n(\pi a, \XX).\;\;\blacksquare\]

Согласно данному выше определению \emph{алгоритм}
$a \equiv \bigl( a(x_i) \bigr){}_{i=1}^L$ является вектором,
следовательно, зависит от~нумерации объектов выборки.
Однако ни~группа симметрий~$\Sym(A)$, ни~разбиение на~классы идентичных алгоритмов~$\Omega(A)$,
уже не~зависят от~этой нумерации.

\begin{Lemma}
    \label{lem:SymGroupIsimorphism}
    Для любого множества алгоритмов ${A\in 2^\AA}$
    и~любой перестановки $\pi \in S_L$ группы $\Sym(A)$ и~$\Sym(\pi A)$ сопряжены:
    $\Sym(\pi A) = \pi \circ \Sym(A) \circ \pi^{-1}$.
\end{Lemma}

Эта лемма эквивалентна известному утверждению из~теории групп:
стационарные подгруппы точек, лежащих на
одной орбите действия, получаются друг из~друга сопряжением \cite{vinberg2001}.

\begin{Lemma}
    Пусть алгоритмы $a_1$ и~$a_2$ идентичны в~множестве алгоритмов $A$.
    Тогда $\forall \pi \in S_L$ алгоритмы $\pi a_1$ и~$\pi a_2$ идентичны
    в~множестве алгоритмов $\pi A$.
\end{Lemma}

$\square$ Пусть $\gamma \in \Sym(A)$ "--- перестановка, такая что $a_2 = \gamma a_1$.
Тогда $\pi a_2 = \pi \gamma a_1 = (\pi \gamma \pi^{-1}) \pi a_1$ = $\tilde \gamma \pi a_1$.
Из леммы \ref{lem:SymGroupIsimorphism} получаем, что
$\tilde\gamma = \pi \gamma \pi^{-1}$ "--- элемент $\Sym(\pi A)$. $\blacksquare$

\subsection{Теоремы о равном вкладе идентичных алгоритмов в~вероятность переобучения}

Теоремы, приведенные в~данном параграфе, позволяют в~ряде случаев существенно упростить
получение явных формул для вероятности переобучения.

\begin{Theorem}
    \label{th:equalContribution}
    Идентичные алгоритмы имеют равную вероятность реализоваться в~результате обучения,
    а~также дают равный вклад в~вероятность переобучения:
    \begin{align}
        P_\mu(a, A) &= P_\mu(\pi a, A), \\
        Q_\mu(a, A) &= Q_\mu(\pi a, A),
    \end{align}
    где $\pi \in \Sym(A)$.
\end{Theorem}
$\square$
    Доказательство автоматически следует из~леммы \ref{Lem:PQ_invariance} и~определения
    группы симметрии: $P_\mu(\pi a, A) = P_\mu(\pi a, \pi A) = P_\mu(a, A)$,
    и~аналогично для $Q_\mu(a, A)$. $\blacksquare$

\begin{Corollary}
    Пусть группа симметрии действует на~множестве алгоритмов транзитивно:
    $A = \{\pi a_0, \, \pi \in \Sym(A)\}$, где $a_0 \in A$ "--- произвольный алгоритм множества $A$.
    Тогда все алгоритмы множества имеют равную вероятность реализоваться в~результате обучения.
\end{Corollary}
%\REVIEWERNOTE{А если не транзитивно, то что будет? И~возможны ли такие случаи?}

Теорема \ref{th:equalContribution} позволяет перейти от~суммирования по~всем
алгоритмам множества к~суммированию по~орбитам действия группы $\Sym(A)$.

\begin{Theorem}
\label{th:equalContributionERM}
Вероятность переобучения $Q_\mu(A)$
для рандомизированного метода минимизации эмпирического риска
можно записать в~следующем виде:
\begin{equation}
\label{eq:MainInstrument}
    Q_\mu(A) =
        %\frac 1{C_L^\ell}
        \sum_{\omega \in \Omega(A)}\!\! |\omega| \,
        %\sum_{\substack{
        %        \Xl \in \XXell\colon \\
        %        a_\omega \in  A(\Xl)
        %}}
        \mathbf{E}
        \frac {\bigl[a_\omega \in  A(\Xl)\bigr]}{|A(\Xl)|}
        %\frac 1{|A(\Xl)|}
        \left[ \delta(a_\omega, \Xl) \geq \epsilon \right].
\end{equation}
\end{Theorem}

$\square$
Воспользуемся теоремой о равном вкладе идентичных алгоритмов в~вероятность переобучения,
затем определениями~\eqref{eq:algContribution} и~\eqref{eq:randomizedRiskMinimization}:
\[
    \begin{aligned}
    Q_\mu(A) & =
        \sum_{a \in A} Q_\mu(a, A) =
        \sum_{\omega \in \Omega(A)}\!\! |\omega| \,
        Q_\mu(a_\omega, A)
        =
    \\
        & =
        %\frac 1{C_L^\ell}
        \sum_{\omega \in \Omega(A)}\!\! |\omega| \,
        %\sum_{\substack{
        %        \Xl \in \XXell \colon \\
        %        a_\omega \in  A(\Xl)
        %}}
        %\frac 1{|A(\Xl)|}
        \mathbf{E}
        \frac {\bigl[a_\omega \in  A(\Xl)\bigr]}{|A(\Xl)|}
        \left[ \delta(a_\omega, \Xl) \geq \epsilon \right].
        \quad\blacksquare
    \end{aligned}
\]

%В сумме по~разбиениям достаточно суммировать только по~таким $\Xl$,
%что представитель орбиты $a_\omega$ лежит в~$A(\Xl)$.
%Остальные слагаемые равны нулю по~определению рандомизированного метода минимизации эмпирического риска:
%$\mu(A, \Xl, a) = 0$ для всех $a \not\in A(\Xl)$.
%$\blacksquare$

Формула~\eqref{eq:MainInstrument} является основным инструментом вывода точных оценок
вероятности переобучения для рандомизированного метода
минимизации эмпирического \mbox{риска}.

\section{Точные оценки вероятности переобучения}

В данном параграфе будут получены явные комбинаторные формулы
для функционала $Q_\mu(\epsilon, A)$ для некоторых множеств алгоритмов $A$,
обладающих свойством симметрии.

\subsection{Полный слой алгоритмов}

\emph{Полным $m$-слоем} алгоритмов будем называть множество,
состоящее из~всех алгоритмов $a\in\AA$ с~фиксированным числом ошибок:
$n(a, \XX) = m$.

\begin{Theorem}
\label{th:fullSliceFormula}
При обучении рандомизированным методом минимизации эмпирического риска вероятность
переобучения для полного $m$-слоя алгоритмов есть
\begin{equation}
    \label{formula:fullSliceFormula}
    Q_\mu(\epsilon, A)
    =
    \bigl[
        \epsilon k \leq m \leq L - \epsilon \ell
    \bigr].
\end{equation}
\end{Theorem}

$\square$ \textbf{Доказательство.}

В рассматриваемом случае группой симметрии $\Sym(A)$ будет вся симметрическая группа $S_L$.
Следовательно, действие группы симметрии на~множестве алгоритмов транзитивно, и
в рассматриваемом множестве есть только один класс из~$C_L^m$ идентичных алгоритмов.
Согласно теореме \ref{th:equalContributionERM} запишем:
\[
    Q_\mu(\epsilon, A) =
%        \frac {C_L^m}{C_L^\ell}
%        \sum_{\substack{
%                \Xl \in \XXell \,\colon \\
%                a_0 \in  A(\Xl)
%        }}
        C_L^m
        \mathbf{E}
        \frac {\bigl[ a_0 \in  A(\Xl) \bigr]}{|A(\Xl)|} \left[ \delta(a_0, \Xl) \geq \epsilon \right].
\]
где $a_0$ "--- произвольный алгоритм рассматриваемого семейства.

Алгоритм $a_0$ будет выбран только если он~имеет минимальное число ошибок на~обучении.
Рассмотрим два случая.

Случай 1, $m \leq k$. Все ошибки $a_0$ помещаются в~контроль,
и переобучение наступает при условии $m \geq \epsilon k$.
Этим фиксируются $m$ объектов контроля, следовательно число слагаемых в~сумме по~разбиениям $\Xl$
определяется числом способов выбрать $k-m$ объектов, на~которых алгоритм $a_0$ не~ошибается.
Это число равно $C_{L-m}^{k-m}$.

Мощность множества лучших на~обучении алгоритмов $A(\Xl)$
не~зависит от~$\Xl$ и~равна $C_k^m$ "---
числу способов расставить $m$ ошибок алгоритма
на $k$ позициях контрольной выборки. Таким образом,
\[
    Q_\mu(\epsilon, A) =
        \frac{C_L^m}{C_L^\ell}
        \frac{C_{L-m}^{k-m}}{C_k^m}
        \bigl[ m \geq \epsilon k\bigr],
        \text { при } m \leq k.
\]

Случай 2, $m > k$. Контрольная выборка должна содержать только объекты, на~которых $a_0$ ошибается.
Тогда в~обучении останется $m-k$ ошибок, а~условие переобучения примет вид
$1 - \frac{m-k}{\ell} \geq \epsilon$, откуда $m \leq L - \epsilon \ell$.

Число разбиений выборки, при которых $a_0 \in A(\Xl)$, равно $C_m^k$ "---
числу способов выбрать $k$ ошибок алгоритма $a_0$ в~контрольную выборку.
Мощность множества $A(\Xl)$ вновь не~зависит от~$\Xl$, и~равна $C_\ell^{m-k}$ "---
числу способов отобрать $m-k$ ошибок в~обучающую выборку.
\[
    Q_\mu(\epsilon, A) =
        \frac{C_L^m}{C_L^\ell}
        \frac{C_{\ell}^{m-k}}{C_m^k}
        \bigl[m \leq L - \epsilon \ell\bigr],
        \text { при } m > k.
\]

Записав для каждого комбинаторного коэффициента тождество
$C_L^k = \frac {L!}{k!(L-k)!}$,
убеждаемся, что в~обеих формулах комбинаторные множители равны единице.
Соединяя вместе условия
$\epsilon k \leq m \leq k$ и~$k < m \leq L =\epsilon \ell$,
получаем утверждение теоремы.
$\blacksquare$

\subsection{Куб алгоритмов}
Кубом алгоритмов $\AA$ называется множество, содержащее все возможные $a \in \{0, 1\}^L$.

\begin{Theorem}
Вероятность переобучения для куба алгоритмов дается формулой:
\[
    Q_\mu(\epsilon, \AA) =
    \frac 1{2^k}
    \sum_{m = \lceil \epsilon k \rceil}^k
    C_k^m.
\]
\end{Theorem}

$\square$ \textbf{Доказательство.}

Очевидно, что в~данном случае группа симметрии "--- это вся $S_L$.
Тогда орбитами ее действия будут слои алгоритмов с~одинаковым числом ошибок.
Поэтому, согласно теореме~\ref{th:equalContributionERM},
\[
    Q_\mu(\epsilon, \AA) =
        %\frac 1{C_L^\ell}
        \sum_{m=0}^L C_L^m
%        \sum_{\substack{
%                \Xl \in \XXell \,\colon \\
%                a_m \in A(\Xl)
%        }}
        \mathbf{E}
        \frac {\bigl[ a_m \in A(\Xl) \bigr]}{|A(\Xl)|} \left[ \delta(a, \Xl) \geq \epsilon \right].
\]

Алгоритм может быть выбран в~результате обучения только в~том случае, когда
он не~допускает ошибок на~обучении. Поэтому все его ошибки должны помещаться в~контрольную
выборку, значит можно ограничить индекс суммирования $m \leq k$.

Раз все ошибки выбранного алгоритма расположены в~контрольной выборке, то,~вне зависимости от
разбиения, уклонение частот равно $\delta(a, \Xl) = \frac mk$.
Следовательно, переобучение наступает при $m \geq \lceil \epsilon k \rceil$.

В множестве $A(\Xl)$ всегда $2^k$ алгоритмов. Это алгоритмы с~нулевым числом ошибок на~обучении
и~всеми возможными векторами ошибок на~контрольной выборке.

Собирая вместе установленные выше факты, получаем формулу
\[
    Q_\mu(\epsilon, \AA) =
        %\frac 1{C_L^\ell}
        \sum_{m = \lceil \epsilon k \rceil}^k C_L^m
%        \sum_{\substack{
%                \Xl \in \XXell \,\colon \\
%                a_m \in A(\Xl)
%        }}
        \frac {\mathbf{E}\bigl[ a_m \in A(\Xl) \bigr]}{2^k}.
\]

Осталось вычислить число разбиений, на~которых алгоритм $a_m$ будет выбран методом обучения.
Этих разбиений столько, сколько способов выбрать $\ell$ объектов обучающей выборки из
$L-m$ правильных ответов алгоритма $a_m$. Итого получаем
\[
    Q_\mu(\epsilon, \AA) =
        \sum_{m = \lceil \epsilon k \rceil}^k C_L^m
        \frac {C_{L-m}^\ell}{C_L^\ell 2^k}
    =
%%%%\]
%%%%Расписывая биномиальные коэффициенты, получаем окончательную формулу:
%%%%\[
%%%%    Q_\mu(\epsilon, \AA) =
%%%%    \frac 1{2^k}
%%%%    \sum_{m = \lceil \epsilon k \rceil}^k
%%%%    \frac {
%%%%        \frac{L!}{m! \, (L-m)!} \frac{(L-m)!}{\ell! \,(k-m)!}
%%%%    }{
%%%%        \frac {L!}{\ell! \, k!}
%%%%    } =
%%%%    \frac 1{2^k}
%%%%    \sum_{m = \lceil \epsilon k \rceil}^k
%%%%    \frac{k!}{m! \, (k-m)!} =
    \frac 1{2^k}
    \sum_{m = \lceil \epsilon k \rceil}^k
    C_k^m.
    \;\;\; \blacksquare
\]

\subsection{Унимодальная цепочка}

Определим расстояние между алгоритмами $\rho(a, a')$ как
расстояние Хэмминга между их векторами ошибок:
\[
    \rho(a, a') = \sum_{x \in \XX} |a(x) - a'(x)|.
\]

\begin{Def}
Множество алгоритмов $\{a_0, \dots, a_D\}$ называется
\emph{монотонной цепочкой}, если выполнены два условия:
\begin{itemize}
    \item[1)]
        монотонность числа ошибок:
        $n(a_i, \XX) = m + i$,\; $i = 0, \dots, D$ при некотором фиксированном~$m$;
    \item[2)]
        поглощение ошибок предыдущего алгоритма:
        $\rho(a_{i}, a_{i-1}) = 1$,\; $i = 1, \dots, D$.
\end{itemize}
\end{Def}
Таким образом, в монотонной цепочке каждый следующий алгоритм ошибается на тех же объектах,
что и предыдущий, и допускает еще одну дополнительную ошибку.

Монотонная цепочка алгоритмов "--- это простейшая модель однопараметрического \emph{связного семейства алгоритмов},
предполагающая, что при непрерывном удалении некоторого параметра от оптимального значения число ошибок на полной выборке только увеличивается.

\begin{Def}
Множество алгоритмов $\{a_0, a_1, \dots, a_D, a'_1, \dots, a'_D\}$ называется
унимодальной цепочкой, если выполнены два условия:
\begin{itemize}
  \item[1)]  левая ветвь $\{a_0, a_1, \dots, a_D\}$ и
        правая ветвь $\{a_0, a'_1, \dots, a'_D\}$
        являются монотонными цепочками.
  \item[2)]  пересечение множества ошибок алгоритмов $a_D$ и $a'_D$ равно
        множеству ошибок алгоритма $a_0$.
\end{itemize}
\end{Def}

Унимодальная цепочка является более реалистичной моделью однопараметрического \emph{связного семейства},
по сравнению с монотонной цепочкой. Если мы имеем лучший алгоритм $a_0$ c оптимальным значением
некоторого вещественного параметра, то отклонение значения этого параметра как в~б\'ольшую, так и в меньшую,
сторону приводит к~увеличению числа ошибок.

\begin{Theorem}
    \label{th:unimodalChain}
    Для унимодальной цепочки с~ветвями длины~$D$ вероятность переобучения
    рандомизированного метода минимизации эмпирического риска равна
    \begin{equation}
        \label{formula:unimodalChain}
        Q_\mu(\epsilon, A) =
            %\frac{1}{C_L^\ell}
            \sum_{h=0}^{D} \sum_{t_1=h}^D \sum_{t_2 = 0}^{D}
            \frac{|\omega_h|}{1 + t_1 + t_2}
            \frac{C_{L'}^{\ell'}}{C_L^\ell}
            H_{L'}^{\ell', m}(s(\epsilon)),
    \end{equation}
    где
        $L' = L {-} t_1 {-} t_2 {-} F$,\;
        $F = [t_1{\neq}D] + [t_2{\neq}D]$,\;
        $\ell' = \ell {-} F$,\;
        $s(\epsilon) = \bigl\lfloor \frac{\ell}L (m {+} h {-} \epsilon k) \bigr\rfloor$;\;
        $|\omega_h| = 1$ при $h = 0$ и~$|\omega_h| = 2$ при ${h \geq 1}$;\;
        $H_{L'}^{\ell', m}(z) = \frac {1}{C_{L'}^{\ell'}}\sum \limits_{s=0}^{\lfloor z \rfloor} C_m^s C_{L'-m}^{\ell' - s}$ "--- функция гипергеометрического распределения \cite{voron09mmro}.
\end{Theorem}
$\square$ \textbf{Доказательство.}

Пронумеруем объекты генеральной выборки $\XX$ таким образом, как показано в следующей таблице:
\[
    \bordermatrix{
         & a_0 & a_1 & a_2 & \cdots & a_D & a'_1 & a'_2 & \cdots & a'_D \cr
    x_1  & 0 & 1 & 1 & \cdots & 1 & 0 & 0 & \cdots & 0 \cr
    x_2  & 0 & 0 & 1& \cdots  & 1 & 0 & 0& \cdots  & 0 \cr
         & \cdots & \cdots & \cdots & \cdots & \cdots & \cdots & \cdots& \cdots  & \cdots \cr
    x_D  & 0 & 0 & 0 & \cdots & 1 & 0 & 0& \cdots  & 0 \vspace{-1.5ex}\cr\cline{2-10}
    x'_1 & 0 & 0 & 0 & \cdots & 0 & 1 & 1 & \cdots & 1 \cr
    x'_2 & 0 & 0 & 0 & \cdots & 0 & 0 & 1& \cdots  & 1 \cr
         & \cdots & \cdots & \cdots & \cdots & \cdots & \cdots & \cdots& \cdots  & \cdots \cr
    x'_D & 0 & 0 & 0 & \cdots & 0 & 0 & 0 & \cdots & 1 \cr
    }
\]

Перестановками объектов выборки
(${x_1{\,\leftrightarrow\,}x'_1}, \dots, x_D{\,\leftrightarrow\,}x'_D$)
можно поменять левую и~правую ветви местами.
Поэтому идентичные алгоритмы в~унимодальной цепочке "---
это пары алгоритмов с~равным числом ошибок на~полной выборке.

Согласно теореме \ref{th:equalContributionERM} вероятность переобучения записывается в виде:
\[
    Q_\mu(\epsilon, A) = \sum_{h=0}^{D} |\omega_h| \sum_{t_1=h}^D \sum_{t_2 = 0}^{D} \frac1{C_L^\ell} \sum_{\Xl \in N(t_1, t_2)}
                    \frac 1{|A(\Xl)|} \left[ \delta(a_h, \Xl) \geq \epsilon \right].
\]

Здесь индекс $h$ обозначает номер класса идентичных алгоритмов
(таким образом, что все алгоритмы класса $\omega_h$ имеют $m+h$ ошибок);
$|\omega_0| = 1$, и~$|\omega_h| = 2$ при $h \geq 1$.
Для определенности будем брать представителя $a_h$ класса $\omega_h$ из левой ветви цепочки.

Индексы $t_1$ и~$t_2$ параметризуют состав множества $A(\Xl)$.
Для произвольного разбиения $\Xl \in \XXell$ определим $t_1$ как максимальное число,
для которого все объекты $x_1, x_2, \dots, x_t$ находятся в~контроле, а~$x_{t_1+1}$ (при его наличии) --- в~обучении.
Индекс $t_2$ определяется аналогично для объектов правой ветви.
Множество $N(t_1, t_2) \subset \XXell$ есть множество всех разбиений выборки с параметрами $t_1$ и $t_2$.

Из определения $t_1$ и~$t_2$ следует, что $|A(\Xl)| = \frac{1}{1 + t_1 + t_2}$.
Индексы $t_1$ и~$t_2$ при суммировании пробегают разные множества значений,
поскольку рассматриваются только разбиения, при которых выбранный из левой ветви представитель $a_h$
лежит в $A(\Xl)$.

Обозначим $F = [t_1{\neq}D] + [t_2{\neq}D]$, $L' = L {-} t_1 {-} t_2 {-} F$, $\ell' = \ell - F$.
Параметр $F$ позволяет учитывать вклад последних алгоритмов $a_D$ и $a'_D$ цепочки.

Вычислим мощность подмножества тех разбиений из $N(t_1, t_2)$,
на которых алгоритм $a_h$ оказывается переобученным.
Пусть $s_0(\epsilon)$ --- максимальное число ошибок на~обучении,
при котором наблюдается переобучение.
По определению уклонения частот находим
$s_0(\epsilon) = \lfloor \frac{\ell}L (m + h - \epsilon k) \rfloor$.
Нам необходимо из~$L'$ объектов выбрать $\ell'$ для обучения таким образом,
что бы из~$m$ свободных ошибок алгоритма $a_h$ в~обучении оказалось не~более $s_0(\epsilon)$ ошибок.
Это число способов дается выражением
$   %H_{L'}^{\ell',\, m}(s_0(\epsilon))
    %=
    \sum \limits_{s = 0}^{s_0(\epsilon)}
    C_{m}^{s}C_{L'-m}^{\ell'-s}$.

Собирая все результаты, приходим к~окончательной формуле:
\[
    Q_\mu(\epsilon, A) =
        \sum_{h=0}^{D} |\omega_h| \sum_{t_1=h}^D \sum_{t_2 = 0}^{D}
        \frac{1}{1 + t_1 + t_2} \frac {C_{L'}^{\ell'} } {C_L^\ell} H_{L'}^{\ell', \, m}(s_0(\epsilon)). \;\;\blacksquare
\]

\subsection{Связка из монотонных цепочек}

\emph{Связкой из~$p$ монотонных цепочек} называется множество алгоритмов,
полученное объединением $p$ монотонных цепочек равной длины,
с~общим первым алгоритмом. Как и в случае унимодальной цепочки, предполагается,
что множества объектов, на которых ошибаются алгоритмы ветвей, не~пересекаются.

Группа симметрии связки~из~$p$ монотонных цепочек является
симметрической группой $S_p$, действующей на~ветви связки всевозможными перестановками.
Таким образом, классы идентичных алгоритмов
"--- это подмножества алгоритмов с~одинаковым числом ошибок на~полной выборке,
называемые \emph{слоями}~\cite{voron09mmro}.

В следующей теореме будет дана явная формула вероятности переобучения
для связки из~$p$~монотонных цепочек.
Введём \emph{комбинаторный коэффициент}
$R_{D,p}^h(S,F)$, который зависит от~параметров $S$~и~$F$,
от числа монотонных цепочек~$p$ и~от их длины~$D$,
а также от~$h$ "--- минимального значения параметра~$S$.
Коэффициент $R_{D,p}^h(S,F)$ равен числу способов представить число~$S$
в виде суммы $p$~неотрицательных слагаемых, $S = t_1+ \ldots + t_p$,
каждое из~которых не~превосходит~$D$.
При этом ровно $F$~слагаемых не~должно равняться~$D$,
а на~первое слагаемое накладывается дополнительное ограничение $t_1 \geq h$.

\begin{Theorem}
\label{th:pMonot}
    Пусть в~связке из~$p$ монотонных цепочек
    лучший алгоритм допускает $m$~ошибок на~полной выборке,
    длина каждой ветви без учета лучшего алгоритма равна~$D$.
    \mbox{Тогда} при обучении рандомизированным методом
    вероятность переобучения может быть записана в~виде:
    \begin{equation}
    \label{formula:pChainsUnion}
            Q_\mu(\epsilon, A) =
                \sum_{h=0}^{D}
                \sum_{S=h}^{p D}
                \sum_{F = 0}^{p}
                \frac{|\omega_h| R_{D, p}^h(S, F)}{1 + S}
                \frac{C_{L'}^{\ell'}}{C_L^\ell}
                H_{L'}^{\ell', m}(s(\epsilon)),
    \end{equation}
    где
        $L' = L {-} S {-} F$,\;
        $\ell' = \ell {-} F$,\;
        $s(\epsilon) = \bigl\lfloor \frac{\ell}L (m {+} h {-} \epsilon k) \bigr\rfloor$;\;
        $|\omega_h| = 1$ при $h = 0$ и~$|\omega_h| = p$ при ${h \geq 1}$;\;
        $H_{L'}^{\ell', m}(s)$ "--- функция гипергеометрического распределения \cite{voron09mmro}.
\end{Theorem}


\begin{figure}[t]
    \begin {multicols}{2}
    \centering
    \hfill
    \includegraphics[width=84mm,height=63mm]{frey_monot.eps}
    \hfill
    \caption{Зависимость $Q_\mu(\epsilon, A)$ от~$\epsilon$ для монотонной цепочки при $L=100$, $\ell=60$, $D=40$, $m=20$.}
    \label{fig:Monot}
    \medskip
    \hfill
    \includegraphics[width=84mm,height=63mm]{frey_unit.eps}
    \hfill
    \caption{Зависимость $Q_\mu(\epsilon, A)$ от~$\epsilon$ для единичной окрестности при $L=100$, $\ell=60$, $p=10$, $m=20$.}
    \label{fig:Unit}
    \end {multicols}
\end{figure}

$\square$ \textbf{Доказательство.}
Естественным образом обобщая рассуждения, приведенные для унимодальной цепочки, получаем формулу
\[
    Q_\mu(\epsilon, A) =
        \sum_{h=0}^{D} |\omega_h| \sum_{t_1=h}^D \sum_{t_2 = 0}^{D} \ldots \sum_{t_p = 0}^{D}
        \frac{1}{1 + t_1 + t_2 + \ldots + t_p} \frac {C_{L'}^{\ell'}} {C_L^\ell} H_{L'}^{\ell', m}(s(\epsilon)),
\]
где
$L' = L - \sum\limits_{i=1}^{p}t_i - \sum\limits_{i=1}^{p}[t_i \neq D]$,\;
$\ell' = \ell - \sum\limits_{i=1}^{p}[t_i \neq D]$,\;
$s_0(\epsilon) = \lfloor \frac{\ell}L (m + h - \epsilon k) \rfloor$.

Упростим запись, введя дополнительные обозначения
${S = \sum\limits_{i=1}^{p}t_i}$,\;
${F = \sum\limits_{i=1}^{p}[t_i \neq D]}$.
Параметр~$S$ определяет мощность множества $A(\Xl)$.
\[
    Q_\mu(\epsilon, A) =
        %\frac{1}{C_L^\ell}
        \sum_{h=0}^{D} |\omega_h| \sum_{t_1=h}^D \sum_{t_2 = 0}^{D} \ldots \sum_{t_p = 0}^{D}
        \frac{1}{1 + S}
        \frac {C_{L'}^{\ell'}}{C_L^\ell}
        H_{L'}^{\ell', m}(s_0(\epsilon)),
\]
где
$L' = L - S - F$,\;
$\ell' = \ell - F$,\;
$s_0(\epsilon) = \lfloor \frac{\ell}L (m + h - \epsilon k) \rfloor$.

Теперь от суммирования по параметрам $t_i$
можно перейти к~суммированию по~множеству возможных значений $S$~и~$F$:
\[
    Q_\mu(\epsilon, A) =
        %\frac{1}{C_L^\ell}
        \sum_{h=0}^{D} |\omega_h| \sum_{S=h}^{p D} \sum_{F = 0}^{p}
        \frac{R_{D,p}^h(S, F)}{1 + S}
        \frac {C_{L'}^{\ell'}}{C_L^\ell}
        H_{L'}^{\ell', m}(s_0(\epsilon)),
\]
где $R_{D,p}^h(S, F)$ "--- определенный выше комбинаторный коэффициент. $\blacksquare$

% \REVIEWERNOTE{Он был определён не в~формулировке теоремы, а перед ней}

Связка из~$2p$ монотонных цепочек является
моделью $p$"~параметрического семейства алгоритмов,
в~котором разрешено изменять любой из~$p$ параметров при фиксированных остальных,
а~одновременное изменение нескольких параметров не~допускается.
Данное семейство можно также рассматривать как обобщение трёх частных случаев,
рассмотренных в~\cite{voron09dan}:
монотонной цепочки ($p=1$),
унимодальной цепочки ($p=2$)
и~единичной окрестности лучшего алгоритма ($D=1$).

Формула для вероятности переобучения унимодальной цепочки уже была получена в~теореме~\ref{th:unimodalChain}.
Для получения явных формул для двух оставшихся семейств достаточно найти явное выражение для комбинаторного коэффициента $R_{D, p}^h(S, F)$.

\begin{Corollary}
    Для монотонной цепочки длины $D+1$ вероятность переобучения равна
    \begin{equation}
    \label{formula:monotonicChain}
        Q_\mu(\epsilon, A)=
            \frac 1{C_L^\ell}
            \sum_{h=0}^{D} \sum_{S=h}^D
            \frac{1}{1 + S}
%            \frac{C_{L'}^{\ell'}}{C_L^\ell}
            H_{L'}^{\ell', m}(s(\epsilon)),
    \end{equation}
    где
    $L' = L - S - [S{\neq}D]$,\;
    $\ell' = \ell - [S{\neq}D]$.
\end{Corollary}

\begin{Corollary}
    Для единичной окрестности из~${p+1}$ алгоритма вероятность переобучения равна
    \begin{equation}
    \label{formula:unitVicinity}
        Q_\mu(\epsilon, A) =
            \frac 1{C_L^\ell}
            \sum_{h=0}^{1}
            \sum_{S=h}^{p}
            \frac{|\omega_h| C_{p-h}^{S-h}}{1 + S}
%            \frac{C_{L'}^{\ell'}}{C_L^\ell}
            H_{L'}^{\ell', m}(s(\epsilon)),
    \end{equation}
    где
    $L' = L {-} p$,\;
    $\ell' = \ell {+} S {-} p$.
\end{Corollary}

\subsection{Численный эксперимент}

\begin{figure}[t]
    \begin {multicols}{2}
    \centering
    \hfill
    \includegraphics[width=84mm,height=63mm]{frey_p.eps}
    \hfill
    \caption{Зависимость $Q_\mu(\epsilon, A)$ от~$p$ для связки
             из монотонных цепочек
             при $L=300$, $\ell=150$, $m=15$, $D = 1, 2, 3, 5, 10$, $\epsilon = 0.05$.}
    \label{fig:pBinding}
    \medskip
    \hfill
    \includegraphics[width=84mm,height=63mm]{frey_D.eps}
    \hfill
    \caption{Зависимость $Q_\mu(\epsilon, A)$ от~$D$ для связки
            из $p = 1, 2, 3, 5, 10$ монотонных цепочек
            при $L=300$, $\ell=150$, $m=15$, $\epsilon = 0.05$.}
    \label{fig:dBinding}
    \end {multicols}
\end{figure}

На~рис.\,\ref{fig:Monot}~и~рис.\,\ref{fig:Unit} представлены результаты численных экспериментов,
в~которых сравнивались вероятности переобучения для различных вариантов минимизации эмпирического риска.
Из~четырех кривых на~каждом графике верхняя (жирная) соответствует пессимистической минимизации эмпирического риска~\cite{voron09dan,voron09mmro},
нижняя "--- оптимистической.
Две почти сливающиеся кривые между ними соответствуют рандомизированной минимизации эмпирического риска.
\mbox{Одна из~них} вычислена по~доказанным формулам,
вторая построена методом Монте-Карло по~$10^5$ случайных разбиений,
при равновероятном выборе лучшего алгоритма в~случаях неопределенности.
Различия этих двух кривых находятся в~пределах погрешности метода Монте"=Карло.

%\REVIEWERNOTE{Значения $p=1,2,5,15$ выбраны довольно странно. Я бы взял $1,2,10,20$.}

%\REVIEWERNOTE{Значения $D=1,2,3$ выбраны довольно странно. Я бы взял $1,2,10,20$.}

На~рис.\,\ref{fig:pBinding}~и~рис.\,\ref{fig:dBinding} представлены зависимости вероятности переобучения
от~числа~$p$ ветвей в~связке и~от их~длины~$D$.
Графики построены для рандомизированного метода минимизации эмпирического риска.
Рис.\,\ref{fig:dBinding} показывает, что при увеличении длин цепочек~$D$ вероятность переобучения
практически перестаёт расти уже при $D=7$.
Это~связано с~\emph{эффектом расслоения} "--- лишь алгоритмы из нижних слоёв
имеют существенно отличную от~нуля вероятность быть выбранными
методом минимизации эмпирического риска.
Добавление <<слишком плохих>> алгоритмов не~увеличивает вероятность переобучения.
Рис.\,\ref{fig:pBinding} показывает, что
при увеличении числа~$p$ цепочек в~связке вероятность переобучения продолжает расти.
Однако скорость роста сублинейна по~$p$, благодаря \emph{эффекту связности} "---
все алгоритмы находятся на~хэмминговом расстоянии не~более~$D$ от~лучшего алгоритма.

\section{Заключение}

Свойство симметрии семейств алгоритмов позволяет получать
вычислительно эффективные формулы вероятности переобучения.
Для~монотонной цепочки, унимодальной цепочки и~единичной окрестности
такие формулы получены как следствие одной теоремы,
в~то~время как ранее аналогичные оценки доказывались независимо
и~при неестественном предположении об~априорной упорядоченности алгоритмов в~семействе~\cite{voron09dan}.
Примененный подход позволяет получать оценки для семейств с экспоненциально растущим числом алгоритмов
(полный слой алгоритмов, куб алгоритмов).

Работа поддержана РФФИ (проект \No\,08-07-00422) и~программой ОМН~РАН
<<Алгебраические и~комбинаторные методы математической кибернетики
и~информационные системы нового поколения>>.

\def\BibAuthor#1{\emph{#1}}
\def\BibTitle#1{#1}
\def\BibUrl#1{{\small\url{#1}}}
\def\BibHttp#1{{\small\url{http://#1}}}
\def\BibFtp#1{{\small\url{ftp://#1}}}
\def\typeBibItem{\small\sloppy}

\begin{thebibliography}{1}
\bibitem{vapnik74rus}
    \BibAuthor{Вапник\;В.\,Н., Червоненкис\;А.\,Я.}
    \BibTitle{Теория распознавания  образов}. "---
    М.:~Наука, 1974.
\bibitem{vapnik98stat}
    \BibAuthor{Vapnik~V.}
    \BibTitle{Statistical Learning Theory}. "---
    New York: Wiley, 1998.
\bibitem{voron09dan}
    \BibAuthor{Воронцов\;К.\,В.}
    \BibTitle{Точные оценки вероятности переобучения}~//
    Доклады РАН, 2009. "--- Т.\,429, \No\,1.  "--- С.\,15--18.
\bibitem{voron09mmro}
    \BibAuthor{Воронцов\;К.\,В.}
    \BibTitle{Комбинаторный подход к~проблеме переобучения}~//
    Всеросс. конф. ММРО-14 "--- М.:~МАКС Пресс, 2009. "---  \mbox{С.\,18--21}.
\bibitem{botov09mmro}
    \BibAuthor{Ботов\;П.\,В.}
    \BibTitle{Точные оценки вероятности переобучения для монотонных и~унимодальных семейств алгоритмов}~//
    Всеросс. конф. ММРО-14 "--- М.:~МАКС Пресс, 2009.  "---  \mbox{С.\,7--10}.
\bibitem{frey09mmro}
    \BibAuthor{Фрей\;А.\,И.}
    \BibTitle{Точные оценки вероятности переобучения для симметричных семейств алгоритмов}~//
    Всеросс. конф. ММРО-14 "--- М.:~МАКС Пресс, 2009.  "---  \mbox{С.\,66--69}.
\bibitem{vinberg2001}
    \BibAuthor{Винберг\;Э.\,Б.}
    \BibTitle{Курс алгебры}~//
    М.:~Факториал Пресс, 2001. "--- 544~с.
\end{thebibliography}

\end{document}

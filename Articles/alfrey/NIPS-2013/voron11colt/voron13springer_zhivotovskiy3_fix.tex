\documentclass{article}

\usepackage{colt11e}
%\usepackage[round,comma]{natbib}
\usepackage{amssymb,amsmath,mathrsfs}
\usepackage{graphicx}
\usepackage[all]{xy}
\usepackage[ruled,section]{algorithm}
\usepackage[noend]{algorithmic}
\bibliographystyle{plainnat}
\let\cite\citep

\makeatletter
\def\cL{{\mathscr L}}
\def\cB{{\mathscr B}}
\def\cK{{\mathscr K}}
\def\cR{{\mathscr R}}
\def\cN{{\mathcal N}}
\def\cM{{\mathcal M}}
\def\RC{{\mathcal R}}
\def\fF{\mathfrak{F}}
\def\fI{\mathfrak{I}}
\def\fM{\mathfrak{M}}
\def\AA{A}
\def\RR{\mathbb{R}}
\def\NN{\mathbb{N}}
\def\ZZ{\mathbb{Z}}
\def\DD{\mathbb{D}}
\def\LL{\mathbb{L}}
\def\YY{\mathbb{Y}}
\def\XX{\mathbb{X}}
\newcommand{\XXX}{{\mathscr X}}
\newcommand{\XXell}{[\XX]^\ell}
\newcommand{\X}{\bar X}
\newcommand{\x}{\bar x}
\renewcommand{\geq}{\geqslant}
\renewcommand{\leq}{\leqslant}
\renewcommand{\emptyset}{\varnothing}\newcommand{\emset}{\varnothing}
\renewcommand{\kappa}{\varkappa}
\renewcommand{\phi}{\varphi}
\renewcommand{\epsilon}{\varepsilon}\newcommand{\eps}{\varepsilon}
\renewcommand{\lim}{\mathop{\operator@font lim}\limits}
\renewcommand{\limsup}{\mathop{\operator@font lim\,sup}\limits}
\renewcommand{\liminf}{\mathop{\operator@font lim\,inf}\limits}
\renewcommand{\max}{\mathop{\operator@font max}\limits}
\renewcommand{\min}{\mathop{\operator@font min}\limits}
\renewcommand{\sup}{\mathop{\operator@font sup}\limits}
\renewcommand{\inf}{\mathop{\operator@font inf}\limits}
\newcommand{\argmin}{\mathop{\operator@font arg\,min}\limits}
\newcommand{\argmax}{\mathop{\operator@font arg\,max}\limits}
\newcommand{\Arg}{\mathop{\rm Arg}\limits}
\newcommand{\Argmin}{\mathop{\rm Arg\,min}\limits}
\newcommand{\Argmax}{\mathop{\rm Arg\,max}\limits}
\newcommand{\diag}{\mathop{\mathrm{diag}}}
\newcommand{\sign}{\mathop{\rm sign}\limits}
\newcommand{\const}{\mathrm{const}}
\newcommand{\conv}{\mathrm{conv}}
\newcommand{\KL}{\mathrm{KL}}
\newcommand{\VCdim}{\mathop{\mathrm{VCdim}}\nolimits}
\newcommand{\scal}[2]{\left\langle #1,#2 \right\rangle}
\newcommand{\what}{\widehat}
\newcommand{\wtil}{\widetilde}
\newcommand{\eqdef}{\equiv}
\def\CC_#1^#2{\tbinom{#1}{#2}}
%\def\CC_#1^#2{C_{#1}^{#2}}
\providecommand{\Prob}{\mathsf{P}}
\def\Pr[#1]{\Prob\left[#1\right]}
\def\Prbig[#1]{\Prob\bigl[#1\bigr]}
\def\PrBig[#1]{\Prob\Bigl[#1\Bigr]}
\newcommand{\Expect}{\mathsf{E}}
\newcommand{\Var}{\mathsf{D}}
\newcommand{\bin}{\mathop{\rm bin}\nolimits}
\newcommand{\Bin}{\mathop{\rm Bin}\nolimits}
\newcommand{\hypergeom}[5]{{#1}_{#2}^{#4,\:#3}\left(#5\right)}
\newcommand{\hyper}[4]{\hypergeom{h}{#1}{#2}{#3}{#4}}
\newcommand{\Hyper}[4]{\hypergeom{H}{#1}{#2}{#3}{#4}}
\newcommand{\HyperR}[4]{\hypergeom{\bar{H}}{#1}{#2}{#3}{#4}}

% for algorithms
\newcommand{\IFTHEN}[1]{\STATE\algorithmicif\ #1 {\algorithmicthen}}
\newcommand{\REMARK}[1]{\item[]\textsl{#1}}
\newcommand{\BEGIN}{\\[1ex]\hrule\vskip 1ex}
\newcommand{\END}{\vskip 1ex\hrule\vskip 1ex}
\newcommand{\EXIT}{\STATE\textbf{exit}}
\newcommand{\vkID}[1]{\text{\sf #1}}
\newcommand{\PROCEDURE}[1]{\medskip\STATE\textbf{Procedure} \vkID{#1}}

\def\XYtext(#1,#2)#3{\rlap{\kern#1\lower-#2\hbox{#3}}}
\newcommand{\TODO}[1]{\par\smallskip\noindent\fbox{\parbox{150mm}{\textsf{\textbf{~~TO DO:} #1}}}\par\smallskip}
\makeatother

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Author's hacking for SLANTED THEOREMS -- may be removed
\makeatletter
\def\@begintheorem#1#2{\trivlist
   \item[\hskip \labelsep{\bfseries #1\ #2}]\slshape}
\def\@opargbegintheorem#1#2#3{\trivlist
      \item[\hskip \labelsep{\bfseries #1\ #2\ (#3)}]\slshape}
\def\@endtheorem{\endtrivlist}
\renewcommand{\emph}[1]{\textit{#1}}
\makeatother
% The END of "Author's hacking"
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{remark}[theorem]{Remark}
\newenvironment{proofsketch}{\noindent{\bf Proof sketch:}}{\qed\medskip}

\newenvironment{network}%
    {\begin{xy}<1ex,0ex>:}%
    {\end{xy}}
\def\nnNode[#1](#2)#3{\POS(#2)*#3="#1"}
\def\nnLink[#1,#2]#3{\POS"#1"\ar #3 "#2"}

\begin{document}

\section{Necessary and sufficient conditions for exactness of SC-bound}
In this chapter we study necessary and sufficient conditions for exactness of SC-bound.
To formulate our main result we have to first introduce the concept of boolean cube.

Let's fix a set of classifiers $A$.
Consider a classifier~$a \in A$ with protective set~$X_a$.
Then the~\emph{boolean cube generated by~$a$}
is defined as a set of all classifiers whose error vectors differ
from~$a$ only on objects from~$X_a$:
\[
    B(a) =
    \Bigl\{
        a^\prime \in \{0, 1\}^L
        \colon
        n(a, x) = n(a^\prime, x) \
        \forall x \notin X_a
    \Bigr\}.
\]
Boolean cube $B(a)$ consists of $2^{|X_a|}$ classifiers identical to $a$ in $\XX \backslash X_a$ and having all feasible combinations of errors in $X_a$.

\begin{theorem}
\label{th-exactSC-1}
Let $A$ be a set of classifiers and suppose that learning algorithm $\mu$ is a PessERM.
Then SC-bound for $A$ is exact whenever both of the following conditions are satisfied simultaneously:
\begin{itemize}
\item there is exactly one classifier $a \in A$ with $d(a) = 0$ (source), and exactly one classifier $b \in A$ with $u(b) = 0$ (sink);
\item together with each $a \in A$ the set $A$ contains boolean cube $B(a)$.
\end{itemize}
\end{theorem}

It will be also proven that under some additional restrictions the statement of theorem~\ref{th-exactSC-1}
gives necessary and sufficient conditions for exactness of SC-bound.

We start the proof with the following simple lemma. 
Note that in this lemma and further in this chapter by $X_a$ and $X'_a$ 
we denote protective and prohibitive subsets for $a$, defined in the same way as in SC-bound:
\begin{align*}
    X _a &= \bigl\{ x_{ab}\in\XX \bigm| a\prec b\bigr\}
            \text{~ is the protective subset};\\
    X'_a &= \bigl\{ x\in\XX \bigm| \exists b\in A\colon b\leq a,\; I(b,x)<I(a,x) \bigr\}
            \text{~ is the prohibitive subset}.
\end{align*}

\begin{lemma}
\label{lemma2}
Let $A$ be a set of classifiers and suppose that learning algorithm $\mu$ is a PessERM.
Then for any $\eps \in (0,1)$ the SC-bound of $A$ is exact iff
for each $a \in A$ and for each $X \in \XXell$ at least one of the following two conditions is satisfied:

    \medskip
    1)~ $\bigl[\mu X = a\bigr] = \bigl[X_{a} \subset X\bigr]\bigl[X'_{a} \subset \X\bigr]$;

    2)~ $\nu(a,\X) - \nu(a, X) < \eps$.
\end{lemma}

\begin{proof}
Let's revisit the proof of SC-bound:
\begin{align*}
    Q_\eps & =    \Prob\bigl[\mu X = a\bigr]\bigl[ \nu(a,\X) - \nu(a,X) \geq \eps \bigr] \leq \\
           & \leq \Prob\bigl[X_{a} \subset X\bigr]\bigl[X'_{a} \subset \X\bigr]\bigl[ \nu(a,\X) - \nu(a,X) \geq \eps \bigr] = \tilde Q_\eps.
\end{align*}
Then the difference $\tilde Q_\eps - Q_\eps$ can be written as a sum of non-negative summands:
\[
    \tilde Q_\eps - Q_\eps =
        \sum_{X \in \XXell}
                    \Big(\bigl[X_{a} \subset X\bigr]\bigl[X'_{a} \subset \X\bigr] - \bigl[\mu X = a\bigr]\Big)
                    \cdot \bigl[ \nu(a,\X) - \nu(a,X) \geq \eps \bigr].
\]
Therefore, SC-bound is exact iff each summand is zero, which is equivalent to the statement of the lemma.
\end{proof}

From now we will focus on the first condition of lemma \ref{lemma2}. If first condition is satisfied for all $a \in A$ then SC-bound is exact.
The main advantage of this condition is that it only relies on the structure of the set $A$, but doesn't depend on $\eps$.

\begin{lemma}
   \label{lemma3}
   Let $A$ be a set of classifiers and suppose that learning algorithm $\mu$ is a PessERM.
   Consider arbitrary $a \in A$.
   Then equality $\bigl[\mu X = a\bigr] = \bigl[X_{a} \subset X\bigr]\bigl[X'_{a} \subset \X\bigr]$
   holds for all $X \in \XXell$ whenever for each $b \in A$, $b \neq a$ at least one of the following two conditions is satisfied:
    \begin{equation}
        \label{lemma3cond}
        \bigl( X_{a} \cap X'_{b} \neq \emptyset \bigr)
        \text{~or~}
        \bigl( X'_{a} \cap X_{b} \neq \emptyset \bigr).
    \end{equation}
    If, in addition, the length parameters of train and test subsamples satisfy $\ell \ge 2\max\limits_{a \in A}u(a)$ and $k \ge 2\max\limits_{a \in A}q(a)$,
    then~\eqref{lemma3cond} also gives necessary condition for $\bigl[\mu X = a\bigr] = \bigl[X_{a} \subset X\bigr]\bigl[X'_{a} \subset \X\bigr]$.
\end{lemma}
\begin{proof}
Let $X \in \XXell$ be an arbitrary partitioning of $\XX$ into train and test subsamples $X$ and $\X$.
Let $a = \mu X$.
To prove the lemma we have to consider arbitrary $b \in A$, $b \neq a$, and prove the following:
\[
\bigl[X_{b} \subset X\bigr]\bigl[X'_{b} \subset \X\bigr] = 0.
\]
From $\mu X = a$ we conclude that $X_{a} \subset X$ and $X'_{a} \subset \X$.
From the conditions of the lemma either $X_{a} \cap X'_{b} \neq \emptyset$ or $X'_{a} \cap X_{b} \neq \emptyset$.
If the former is true than there is an object from $X'_b$ belonging to $X_a$, and hence belonging to $X$. Therefore $[X'_b \subset \X] = 0$.
If the later is true than there is an object from $X_b$ belonging to $\X$, therefore $[X_b \subset \X] = 0$.
In both cases $\bigl[X_{b} \subset X\bigr]\bigl[X'_{b} \subset \X\bigr] = 0$, which proves the first part of the lemma.

To prove the second part of the lemma let's assume the opposite and
consider a pair of different $a, b$ from $A$ with $X_{a} \cap X'_{b} = \emptyset$ and $X'_{a} \cap X_{b} = \emptyset$.
Then $(X_{a}\cup X_{b}) \cap (X'_{a}\cup X'_{b}) = \emptyset$, and from the conditions of lemma $|X_{a}\cup X_{b}| \le \ell, |X'_{a}\cup X'_{b}| \le k$.
Then there is a partition of $\XX$ into train set $X$ and test set $\X$ with $X_{a}\cup X_{b} \subset X, X'_{a}\cup X'_{b} \subset \X$.
But this implies $\bigl[X_{a} \subset X\bigr]\bigl[X'_{a} \subset \X\bigr] = \bigl[X_{b} \subset X\bigr]\bigl[X'_{b} \subset \X\bigr] = 1$.
This contradiction proves the second part of the lemma.
\end{proof}

The next lemma studies properties of a set $A$ when it is closed with respect to completion by boolean cubes.

A \emph{chain} $a_0 \rightarrow a_n$ from classifier $a_0$ to $a_n$ is defined as a sequences $a_0 \prec a_1 \prec \dots \prec a_n$.
We say that $n$ is the \emph{length }of this chain.

\begin{lemma}
\label{chainLemma}
Suppose that set $A$ together with each classifier $a \in A$ contains boolean cube $B(a)$.
Consider two classifiers $a_0$ and $a_n$ such that there is a chain $a_0 \prec a_1 \prec \dots \prec a_n$ belonging to $A$,
and some classifier $b_0$ such that $a_0 \prec b_0$.
Let $X'_i \equiv X'_{a_i}$ be a prohibitive set for $a_i$,
and, for $i > 0$, let $x_i = X'_i \backslash X'_{i - 1}$ be an object that differentiate $a_i$ from $a_{i-1}$,
$x_b = X'_{b_0} \backslash X'_0$ be an object that differentiate $b_0$ from $a_0$. Then
\begin{enumerate}
    \item if $x_b \in \{x_1, \dots, x_n\}$, then there exist a chain from $b_0$ to $a_n$;
    \item if $x_b \not\in \{x_1, \dots, x_n\}$, then $x_b$ must be in protective set for $a_n$.
\end{enumerate}
\end{lemma}
\begin{proof}
Consider first case when $x_b = x_p$ for some $p \in 1, \dots, n$ (this is illustrated on the figure below, for $p=4$).
Note that both $x_1$ and $x_b$ belong to protective set of $a_0$, therefore set $A$ contains certain classifier $b_1$ such that $b_0 \prec b_1$ and $a_1 \prec b_1$.
This argument can be iterated to deduce classifiers $b_2, \dots, b_{p-2}$. Then one can easily see that $b_{p-2} \prec a_p$, because they differ by object $x_{p-1}$.
Hence we have built the chain $b_0 \prec b_1 \prec \dots \prec b_{p-2} \prec a_p \dots \prec a_n$.

The case when $x_b \not\in \{x_1, \dots, x_n\}$ is also illustrated below. Then one can iterate the same arguments as before to build classifier $b_n$, such that $a_n \prec b_n$.
This proves that $x_b$ is in protective set for $a_n$.

\begin{center}
    \begin{network}
        \nnNode[a0_pic2](0,0)      {+[o][F]{a_{\scriptscriptstyle 0}}}
        \nnNode[a1_pic2](-3,5)     {+[o][F]{a_{\scriptscriptstyle 1}}}
        \nnNode[b0_pic2](3,5)      {+[o][F]{b_{\scriptscriptstyle 0}}}
        \nnNode[a2_pic2](-6,10)    {+[o][F]{a_{\scriptscriptstyle 2}}}
        \nnNode[b1_pic2](0,10)     {+[o][F]{b_{\scriptscriptstyle 1}}}
        \nnNode[a3_pic2](-9,15)    {+[o][F]{a_{\scriptscriptstyle 3}}}
        \nnNode[b2_pic2](-3,15)     {+[o][F]{b_{\scriptscriptstyle 2}}}
        \nnNode[a4_pic2](-12,20)    {+[o][F]{a_{\scriptscriptstyle 4}}}

        \nnLink[a0_pic2,a1_pic2] {@{->}^{x_1}}
        \nnLink[a1_pic2,a2_pic2] {@{->}^{x_2}}
        \nnLink[a2_pic2,a3_pic2] {@{->}^{x_3}}
        \nnLink[a3_pic2,a4_pic2] {@{->}^{x_4}}
        \nnLink[a0_pic2,b0_pic2] {@{->}_{x_4}}
        \nnLink[a1_pic2,b1_pic2] {@{->}}
        \nnLink[a2_pic2,b2_pic2] {@{->}}
        \nnLink[b0_pic2,b1_pic2] {@{->}_{x_1}}
        \nnLink[b1_pic2,b2_pic2] {@{->}_{x_2}}
        \nnLink[b2_pic2,a4_pic2] {@{.}_{x_3}}

        \nnNode[a0](20,0)      {+[o][F]{a_{\scriptscriptstyle 0}}}
        \nnNode[a1](17,5)     {+[o][F]{a_{\scriptscriptstyle 1}}}
        \nnNode[b0](23,5)      {+[o][F]{b_{\scriptscriptstyle 0}}}
        \nnNode[a2](14,10)    {+[o][F]{a_{\scriptscriptstyle 2}}}
        \nnNode[b1](20,10)     {+[o][F]{b_{\scriptscriptstyle 1}}}
        \nnNode[an](11,15)    {+[o][F]{a_{\scriptscriptstyle n}}}
        \nnNode[b2](17,15)    {+[o][F]{b_{\scriptscriptstyle 2}}}
        \nnNode[bn](14,20)    {+[o][F]{b_{\scriptscriptstyle n}}}

        \nnLink[a0,a1] {@{->}^{x_1}}
        \nnLink[a1,a2] {@{->}^{x_2}}
        \nnLink[a2,an] {@{->}^{...}}
        \nnLink[a0,b0] {@{->}_{x_b}}
        \nnLink[a1,b1] {@{->}}
        \nnLink[a2,b2] {@{->}}
        \nnLink[an,bn] {@{->}_{x_b}}
        \nnLink[b0,b1] {@{->}_{x_1}}
        \nnLink[b1,b2] {@{->}_{x_2}}
        \nnLink[b2,bn] {@{->}_{...}}
    \end{network}
\end{center}

\end{proof}

% Corollary ChainExistsForComparableClassifiers is not used anywhere in this text.
%\begin{corollary}
%\label{ChainExistsForComparableClassifiers}
%Suppose that set $A$ has a unique source $s \in A$, and together with each classifier $a \in A$ the set $A$ contains boolean cube $B(a)$.
%Let $a$ and $b$ be two classifiers from $A$ such that $a < b$.
%Then there exist a chain $a \rightarrow b$ belonging to $A$.
%\end{corollary}
%\begin{proof}
%Since $A$ has a unique source $s \in A$ then moving on SC-graph from $a$ or $b$ downwards we are guarantied to reach the source.
%This builds chains $s \rightarrow a$ and $s \rightarrow b$.
%Since $a < b$ all objects in the chain $s \rightarrow a$ also occur in chain $s \rightarrow b$.
%Applying lemma~\ref{chainLemma} several times we each time adjust the chain $s \rightarrow b$ until
%it passes through $a$. This last chain contains a subchain $a \rightarrow b$.
%\end{proof}

We are now finally ready to prove our two main theorems.

\begin{theorem}
\label{preciseSC_sufficient}
Let $A$ be a set of classifiers and suppose that learning algorithm $\mu$ is a PessERM.
Then equality $\bigl[\mu X = a\bigr] = \bigl[X_{a} \subset X\bigr]\bigl[X'_{a} \subset \X\bigr]$ holds for all $X \in \XXell$
whenever both of the following conditions are satisfied simultaneously:
\begin{enumerate}
\item there is exactly one classifier $a \in A$ with $d(a) = 0$ (source), and exactly one classifier $b \in A$ with $u(b) = 0$ (sink);
\item together with each $a \in A$ the set $A$ contains boolean cube $B(a)$.
\end{enumerate}
\end{theorem}
\begin{proof}
To conduct the proof we assume that set $A$ has exactly one source and sink, and together with each $a \in A$ it contains boolean cube $B(a)$.
We will now utilize lemma~\ref{lemma3}, and show that for every $a \in A$ and $b \in A, b \neq a$ either
$X_{a} \cap X'_{b} \neq \emptyset$, or
$X'_{a} \cap X_{b} \neq \emptyset$.
Given that last two conditions are symmetric with respect to swapping $a \leftrightarrow b$,
we will assume that $n(a, \XX) \leq n(b, \XX)$.

Let's build some chains $s \prec a_1 \prec \dots \prec a_n \equiv a$ and $s \prec b_1 \prec \dots \prec b_p \equiv b$ from global source $s \in A$ to classifiers $a$ and $b$.
Here $n$ is the length of chain $s \rightarrow a$, and $p$ is the length of the chain $s \rightarrow b$.
These chains exist due to uniqueness of source $s$ (indeed, one may start from $a$ or $b$ and move downwards in SC-graph until he reaches source $s$).
Denote objects, corresponding to these chains, by $X'_a = \{x^a_1, \dots, x^a_n\}$ and $X'_b = \{x^b_1, \dots, x^b_p\}$
(in the same order as classifiers from the chains make errors on these objects).

Let's select the smallest $t \in 1, \dots, p$ such that $x^{b}_{t}\not\in X'_a$, and prove that object $x^{b}_{t}$ belongs to $X_{a}$.
This object exists either because $p > n$ and then the set $X'_b$ is simply larger than $X'_a$, or, if $n = p$,
because non-existance of such object would imply $X'_b = X'_a$, and therefore $a = b$ (which violates our assumptions).

Consider objects $x_1^b, \dots, x_{t-1}^b$.
By definition of $t$ they all belong to $X'_a$, therefore
applying lemma~\ref{chainLemma} $t - 1$ times we conclude that there exist a chain from classifier $b_{t - 1}$ to $a$.
Now we again apply lemma~\ref{chainLemma} to chain $b_{q-1} \rightarrow a$ and classifier $b_t$.
Since $x^b_t$ doesn't occur in chain $b_{t-1} \rightarrow a$ we conclude that $x^b_t \in X_a$.
As the result $X_{a} \cap X'_{b} \neq \emptyset$, and then by lemma~\ref{lemma3} the theorem is proved.
\end{proof}

\begin{theorem}
\label{preciseSC_necessary}
Theorem \ref{preciseSC_sufficient} also gives necessary conditions for $\bigl[\mu X = a\bigr] = \bigl[X_{a} \subset X\bigr]\bigl[X'_{a} \subset \X\bigr]$
whenever length parameters $\ell$ and $k$ of training and testing sample satisfy $\ell \ge 2\max\limits_{a \in A}u(a)$ and $k \ge 2\max\limits_{a \in A}q(a)$.
\end{theorem}

\begin{proof}
We only study the case $|A| > 1$ (if $|A| = 1$ then the theorem is trivial).
Note that there exist at least one source and one sink because any classifier from the lowest / the highest layer of SC-graph is a source / a sink.
Therefore it is sufficient to prove that under conditions of this theorem they are unique. 
Consider the opposite, and let $s_1$ and $s_2$ be two sinks. 
Then $X_{s_1} = X_{s_1} = \emptyset$, and this violates conditions~\eqref{lemma3cond} of lemma~\ref{lemma3}.
Note that the same argument fails to work for sources, because $X'(a) = \emptyset$ doesn't automatically follow from $d(a) = 0$.
To prove that source is unique we take any classifier $a$ from the lowest layer of $A$, 
consider any other $b \in A$ such that $d(b) = 0$ and $b \neq a$, and show contradiction.
Indeed, if $X'(b) = \emptyset$ then we've again got a contradiction with \eqref{lemma3cond} of lemma \ref{lemma3}.
Otherwise, if $X'(b) \neq \emptyset$, there exist some $c \in A$, $c < b$.
Due to lemma \ref{lemma3} we have $X_c \cap X'_b \neq \emptyset$,
hence there exist certain classifier $c'$ such that $c \prec c'$ and still $c' < b$.
By applying last arguments several times we build a chain $c \prec c' \prec \dots \prec b$,
causing $b$ to have an incoming edge in SC-graph, and therefore contradicting $d(b) = 0$.

Now we turn to the second part and prove that together with each $a$ the set $A$ contains boolean cube $B(a)$.
Suppose the opposite, then there exists a classifier $b \in A$ such that~$B(b) \nsubseteq A$,
i.e.~$A$ doesn't fully contain boolean cube generated by object $b$.
Let~$b^\prime$ be the classifier from~$B(b) \setminus A$ with minimal number of errors.
Since all classifiers from~$B(b)$ whose number of errors smaller than~$m(b^\prime)$
are contained in~$A$, we can construct a chain
$b \equiv b_0 \prec b_1 \prec \ldots \prec b_{p} \prec b_{p + 1} \equiv b^\prime$
such that all classifiers except the last lie in~$A$.
For every $i = 1, \dots, (p+1)$ denote by~$x_i$ an object that corresponds to the edge between~$b_{i - 1}$ and~$b_i$.
We also denote protective and prohibitive sets of~$b_0, b_1, \ldots, b_{p + 1}$
by~$X_0, X_1, \ldots, X_{p + 1}$ and $X'_0, X'_1, \ldots, X'_{p + 1}$ respectively.

\begin{center}
    \begin{network}
        \nnNode[b0](0, 0) {+[o][F]{b}}
        \nnNode[u1](-3, 5) {+[o][F]{...}}
        \nnNode[bj](0, 10) {+[o][F]{b_{\scriptscriptstyle j}}}
        \nnNode[bj1](-3, 15) {+[o][F]{b_{\scriptscriptstyle j+1}}}
        \nnNode[u2](0, 20) {+[o][F]{...}}
        \nnNode[bp](-3, 25) {+[o][F]{b_{\scriptscriptstyle p}}}
        \nnNode[bp1](0, 30) {+[o][F]{b^\prime}}
        \nnNode[a](3, 15) {+[o][F]{a}}
        \nnNode[c](6, 20) {+[o][F]{c}}        

        \nnLink[b0,u1] {@{->}}
        \nnLink[u1,bj] {@{->}}
        \nnLink[bj,bj1] {@{->}^{x_{j+1}}}
        \nnLink[bj,a] {@{->}_{x_{p+1}}}
        \nnLink[bj1,u2] {@{->}}
        \nnLink[u2,bp] {@{->}}
        \nnLink[bp,bp1] {@{->}_{x_{p+1}}}
        \nnLink[a,c] {@{->}_{x_{j+1}}}        
    \end{network}
\end{center}

Note that~$x_{p + 1} \notin X_{p}$ because~$b_{p + 1} \notin A$.
Now consider all classifiers~$b_i$ from the constructed chain
such that~$x_{p + 1} \in X_i$.
Note that there is at least one such classifier because~$x_{p + 1} \in X_0$
by definition of boolean cube generated by~$b_0$.
Among those classifiers we choose the one with the largest number of errors,
and denote it by~$b_j$.

Since~$x_{p + 1}$ is contained in~$X_j$ then there is such~$a \in A$
that~$b_j \prec a$~(see a figure above).
Note that sets~$X_{j + 1}^\prime$ and~$X_a^\prime$ differ only in two objects:
$X_{j + 1}^\prime$ contains~$x_{j + 1}$, and~$X_a^\prime$ contains~$x_{p + 1}$
instead~(it follows from the fact
that~$|X_a^\prime| = |X_{j + 1}^\prime| = |X_j^\prime| + 1$).
Now, applying lemma~\ref{lemma3} to classifiers~$b_{j + 1}$ and~$a$,
either~$X_{j+1} \cap X'_{a} \neq \emptyset$
or~$X'_{j+1} \cap X_{a} \neq \emptyset$
must be true.
These statements are equivalent
to~$x_{p + 1} \in X_{j + 1}$
and~$x_{j + 1} \in X_a$
accordingly.
First suppose that~$x_{p + 1} \in X_{j + 1}$;
this is impossible because~$b_j$
by our choice has the largest number of errors
among all classifiers whose protective sets contain~$x_{p + 1}$.
Now suppose that~$x_{j + 1} \in X_a$;
then there exists a classifier~$c \in A$ with the same error vector as~$b_j$
except that~$I(c, x_{j + 1}) = 1$ and~$I(c, x_{p + 1}) = 1$~(again, see the figure above).
But~$b_{j + 1}$ also has the same error vector as~$b_j$
except that~$I(b_{j + 1}, x_{j + 1}) = 1$.
This means that~$b_{j + 1}$ and~$c$ are connected by an edge in SC-graph
that corresponds to~$x_{p + 1}$.
Then~$x_{p + 1} \in X_{j + 1}$, which again contradicts to our choice of~$b_j$.

These two contradictions conclude the proof of the theorem.
\end{proof}

Finally we present two examples of SC-graphs that satisfy conditions of theorem~\ref{th-exactSC-1} and therefore have an exact SC-bound.

       \begin{center} \begin{network}

            %\nnNode[m](-16,16)    {+{\text{???? s}}}
            %\nnNode[h](0,16)      {+{\text{two-dimensional lattice, } h=2}}
            \nnNode[00](0,0)      {+[o][F]{a_{\scriptscriptstyle 00}}}
            \nnNode[01](-3,5)     {+[o][F]{a_{\scriptscriptstyle 01}}}
            \nnNode[10](3,5)      {+[o][F]{a_{\scriptscriptstyle 10}}}
            \nnNode[02](-6,10)    {+[o][F]{a_{\scriptscriptstyle 02}}}
            \nnNode[11](0,10)     {+[o][F]{a_{\scriptscriptstyle 11}}}
            \nnNode[20](6,10)     {+[o][F]{a_{\scriptscriptstyle 20}}}
            \nnNode[03](-9,15)   {+[o][F]{a_{\scriptscriptstyle 03}}}
            \nnNode[12](-3,15)    {+[o][F]{a_{\scriptscriptstyle 12}}}
            \nnNode[21](3,15)     {+[o][F]{a_{\scriptscriptstyle 21}}}
            \nnNode[30](9,15)    {+[o][F]{a_{\scriptscriptstyle 30}}}

				\nnNode[31](6,20)      {+[o][F]{a_{\scriptscriptstyle 31}}}
            \nnNode[22](0,20)     {+[o][F]{a_{\scriptscriptstyle 22}}}
            \nnNode[13](-6,20)      {+[o][F]{a_{\scriptscriptstyle 13}}}
            \nnNode[32](3,25)    {+[o][F]{a_{\scriptscriptstyle 32}}}
            \nnNode[23](-3,25)     {+[o][F]{a_{\scriptscriptstyle 23}}}
            \nnNode[33](0,30)     {+[o][F]{a_{\scriptscriptstyle 33}}}

            \nnLink[00,01] {@{->}^{x_1}}
            \nnLink[01,02] {@{->}^{x_3}}
            \nnLink[02,03] {@{->}^{x_5}}
            \nnLink[00,10] {@{->}_{x_2}}
            \nnLink[10,20] {@{->}_{x_4}}
            \nnLink[20,30] {@{->}_{x_6}}

				\nnLink[30,31] {@{->}^{x_1}}
            \nnLink[31,32] {@{->}^{x_3}}
            \nnLink[32,33] {@{->}}
            \nnLink[03,13] {@{->}_{x_2}}
            \nnLink[13,23] {@{->}_{x_4}}
            \nnLink[23,33] {@{->}}


            \nnLink[01,11] {@{->}}
            \nnLink[10,11] {@{->}}
            \nnLink[02,12] {@{->}}
            \nnLink[11,12] {@{->}}
            \nnLink[11,21] {@{->}}
            \nnLink[20,21] {@{->}}

				\nnLink[21,22] {@{->}}
            \nnLink[12,22] {@{->}}
            \nnLink[22,23] {@{->}}
            \nnLink[12,13] {@{->}}
            \nnLink[21,31] {@{->}}
            \nnLink[22,32] {@{->}}

            \nnNode[m0](-15,0)  {+{\scriptstyle m=0}}
            \nnNode[m1](-15,5)  {+{\scriptstyle m=1}}
            \nnNode[m2](-15,10) {+{\scriptstyle m=2}}
            \nnNode[m3](-15,15) {+{\scriptstyle m=3}}
				\nnNode[m4](-15,20)  {+{\scriptstyle m=4}}
            \nnNode[m5](-15,25)  {+{\scriptstyle m=5}}
            \nnNode[m6](-15,30) {+{\scriptstyle m=6}}

            \nnLink[m0,00] {@{.}}
            \nnLink[m1,01] {@{.}}
            \nnLink[m2,02] {@{.}}
            \nnLink[m3,03] {@{.}}

				\nnLink[m4,13] {@{.}}
            \nnLink[m5,23] {@{.}}
            \nnLink[m6,33] {@{.}}

            \nnLink[01,10] {@{.}}
            \nnLink[02,11] {@{.}}
            \nnLink[11,20] {@{.}}
            \nnLink[03,12] {@{.}}
            \nnLink[12,21] {@{.}}
            \nnLink[21,30] {@{.}}

				\nnLink[13,22] {@{.}}
            \nnLink[22,31] {@{.}}
            \nnLink[23,32] {@{.}}


%second graph

				\nnNode[44](25,0)      {+[o][F]{b_{\scriptscriptstyle 00}}}
            \nnNode[45](22,5)     {+[o][F]{b_{\scriptscriptstyle 01}}}
            \nnNode[54](28,5)      {+[o][F]{b_{\scriptscriptstyle 10}}}
            \nnNode[55](25,10)     {+[o][F]{b_{\scriptscriptstyle 11}}}
            \nnNode[66](25,20)     {+[o][F]{b_{\scriptscriptstyle 22}}}
            \nnNode[76](28,25)    {+[o][F]{b_{\scriptscriptstyle 32}}}
            \nnNode[67](22,25)     {+[o][F]{b_{\scriptscriptstyle 23}}}
            \nnNode[77](25,30)     {+[o][F]{b_{\scriptscriptstyle 33}}}
				 \nnNode[65](28,15)     {+[o][F]{b_{\scriptscriptstyle 21}}}
					\nnNode[64](31,10)     {+[o][F]{b_{\scriptscriptstyle 20}}}

				\nnLink[44,45] {@{->}^{x_1}}
            \nnLink[65,66] {@{->}^{x_4}}
            \nnLink[66,67] {@{->}^{x_5}}
            \nnLink[44,54] {@{->}_{x_2}}
            \nnLink[54,64] {@{->}_{x_3}}
            \nnLink[67,77] {@{->}_{x_6}}
				
				\nnLink[45,55] {@{->}}
            \nnLink[54,55] {@{->}}
            \nnLink[64,65] {@{->}}
            \nnLink[76,77] {@{->}}
            \nnLink[66,76] {@{->}}
				\nnLink[55,65] {@{->}}
				\nnLink[00,44] {@{.}}
            \nnLink[10,45] {@{.}}
            \nnLink[20,55] {@{.}}
            \nnLink[30,65] {@{.}}
            \nnLink[31,66] {@{.}}
            \nnLink[32,67] {@{.}}

				\nnLink[33,77] {@{.}}
            \nnLink[45,54] {@{.}}
            \nnLink[55,64] {@{.}}
				\nnLink[67,76] {@{.}}
        \end{network}
    \end{center}

\begin{thebibliography}{27}

\end{thebibliography}

\end{document}

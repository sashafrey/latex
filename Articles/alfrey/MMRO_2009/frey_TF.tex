\documentclass[twoside]{article}
\usepackage{mmro14}
\NOREVIEWERNOTES

\newcommand{\XX}{\mathbb{X}}
\newcommand{\X}{\bar X}
\newcommand{\XXell}{[\XX]^\ell}
\renewcommand{\AA}{\mathbb{A}}
\newcommand{\fA}{\mathfrak{A}}
\newcommand{\Argmin}{\mathop{\rm Argmin}\limits}

\begin{document}

\title{Точные оценки вероятности переобучения для симметричных семейств алгоритмов}
\author{Фрей~А.\,И.}
\email{frey@forecsys.ru}
\organization{Московский Физико-технический институт}
\thanks{Работа поддержана РФФИ (проект \No\,08-07-00422) и~программой ОМН~РАН
    <<Алгебраические и~комбинаторные методы математической кибернетики
    и~информационные системы нового поколения>>.}
\abstract{
    В комбинаторном подходе к проблеме переобучения основной задачей является
    получение вычислительно эффективных формул для вероятности переобучения
    и~вероятности получить каждый из имеющихся алгоритмов в~результате обучения.
    %Под вероятностью понимается доля разбиений выборки на обучающую и контрольную подвыборки фиксированной длины.
    %Эта задача не может быть решена полным перебором разбиений за приемлемое время,
    %следовательно речь идёт о получении вычислительно эффективных формул.
    Предлагается подход, который позволяет проще выводить такие формулы в~тех случаях,
    когда множество алгоритмов наделено некоторой группой симметрий.
    Приводятся примеры подобных ситуаций.
    Даётся определение рандомизированного метода обучения,
    для которого доказывается общая оценка вероятности переобучения.
}
\maketitle

\section{Введение}

При обучении алгоритмов классификации и~прогнозирования по конечным выборкам
часто возникает проблема переобучения, когда
качество алгоритма, построенного по~наблюдаемой обучающей выборке,
оказывается значительно хуже на скрытой контрольной выборке.

В~работах~\cite{vapnik74rus,vapnik98stat,voron09mmro} рассматривался
метод \emph{минимизации эмпирического риска}.
Он~заключается в~том, что
из~заданного множества (семейства) алгоритмов выбирается алгоритм,
допускающий наименьшее число ошибок на~обучающей выборке.

В~следующей таблице показан пример, когда минимизация эмпирического риска приводит к~переобучению.
Столбцы таблицы соответствуют алгоритмам,
строки "--- объектам генеральной выборки,
единица в~$[i,d]$-й ячейке таблицы означает, что
алгоритм~$a_d$ допускает ошибку на объекте~$x_i$.
Первые три объекта составляют обучающую выборку, оставшиеся три "--- контрольную.
\begin{center}
\vskip-2ex
\begin{tabular}[t]{|c|llllll|}
\hline
      & $a_1$ & $a_2$ & \dots & $a_d$ & \dots & $a_D$ \\
\hline
$x_1$ & 0 & 1 & \dots & \textbf{0} & \dots & 1 \\
$x_2$ & 1 & 1 & \dots & \textbf{0} & \dots & 0 \\
$x_3$ & 0 & 0 & \dots & \textbf{0} & \dots & 0 \\
\hline
$x_4$ & 1 & 1 & \dots & \textbf{1} & \dots & 1 \\
$x_5$ & 1 & 0 & \dots & \textbf{1} & \dots & 0 \\
$x_6$ & 0 & 0 & \dots & \textbf{1} & \dots & 0 \\
\hline
\end{tabular}
\end{center}

В данном примере переобучение могло быть следствием <<неудачного>> разбиения
генеральной выборки на обучение и контроль.
Поэтому вводится функционал \emph{вероятности переобучения},
равный доле разбиений выборки, при которых возникает переобучение~\cite{voron09mmro,voron09dan}.
Этот функционал инвариантен относительно выбора разбиения
и~характеризует качество данного метода обучения на~данной генеральной выборке.

Для некоторых семейств простой структуры
(монотонных и~унимодальных цепочек и~$h$-мерных сеток)
в~\cite{voron09dan,botov09mmro} найдены точные выражения вероятности переобучения.

В~данной работе вводится понятия группы симметрий множества алгоритмов
и~рандомизированного метода обучения,
позволяющие обобщить эти оценки для тех случаев,
когда семейство алгоритмов наделено определённой симметрией.


\section{Группа симметрий\\ множества алгоритмов}

Пусть задана генеральная выборка $\XX=\bigl( x_i \bigr){}_{i=1}^L$, состоящая из~$L$ объектов.
Произвольный бинарный вектор $a \equiv \bigl( a(x_i) \bigr){}_{i=1}^L$ длины~$L$
будем называть \emph{алгоритмом},
и~в~случае $a(x_i)=1$ говорить, что алгоритм~$a$ допускает ошибку на~объекте~$x_i$.

Обозначим
через $\AA = \{0, 1\}^L$ множество всех возможных алгоритмов,
через $\fA = 2^{\AA}$ "--- множество всех возможных подмножеств (семейств) алгоритмов.
Заметим, что $|\AA|=2^L$,\; $|\fA|=2^{2^L}$.

Для большей наглядности дальнейших определений проведем следующую аналогию:
пусть алгоритмы соответствуют точкам плоскости, множества алгоритмов "--- плоским фигурам.
Зафиксируем некоторую группу преобразований плоскости (например, группу всевозможных движений).
\mbox{Тогда} группа симметрии произвольной фигуры определяется как подгруппа,
не изменяющая фигуру как множество точек плоскости.

В большинстве задач обучения по~прецедентам порядок объектов в~выборке не имеет значения.
\mbox{Поэтому} в качестве исходной группы преобразований мы возьмем
симметрическую группу $S_L$, элементы которой очевидным образом действуют как перестановки объектов
и~на~генеральную выборку~$\XX$,
и~на~произвольный алгоритм~$a\in\AA$,
и~(поэлементно) на~произвольное множество алгоритмов~$A\in\fA$.

%Это позволит нам наделить произвольное множество алгоритмов $A \in \fA$
%некоторой структурой "--- \emph{группой симметрий} $S(A)$ и разбиением $A$ на непересекающиеся
%\emph{классы идентичных алгоритмов}.

\begin{Def}
    \emph{Группой симметрий} $S(A)$ множества алгоритмов $A\in\fA$
    будем называть его стационарную подгруппу:
    \[
        S(A) = \{\pi \in S_L \colon \pi(A) = A\}.
    \]
\end{Def}

Каждый элемент группы симметрий $\pi \in S(A)$
переставляет алгоритмы $a$ внутри множества $A$.
Значит, для любого $a\in A$ и любого $\pi \in S(A)$ выполнено $\pi(a) \in A$.
Поэтому для группы $S(A)$, в отличии от всей группы $S_L$,
естественным образом определено действие на множестве $A$.

\emph{Орбитой} элемента $m$ множества $M$, на котором действует группа $G$,
называется подмножество $Gm = \{g m \colon g \in G\} \subset M$.
Орбиты двух элементов $m_1$ и $m_2$ либо не пересекаются, либо совпадают.
Это позволяет говорить о разбиении множества $M$ на непересекающиеся орбиты:
$M = G m_1 \sqcup \ldots \sqcup G m_k$.
\begin{Def}
    Орбиты действия группы симметрий $S(A)$ на множестве алгоритмов $A$
    будем называть \emph{классами идентичных алгоритмов.}
\end{Def}

Совокупность всех орбит множества алгоритмов $A$ обозначим через $\Omega(A)$.
Представителя орбиты $\omega~\in~\Omega(A)$ будем обозначать через $a_\omega \in A$.
Различных представителей одной и той же орбиты будем называть \emph{идентичными алгоритмами}.

Согласно данному выше определению \emph{алгоритм}
$a \equiv \bigl( a(x_i) \bigr){}_{i=1}^L$ является вектором,
следовательно, зависит от нумерации объектов выборки.
Однако ни группа симметрий~$S(A)$, ни~разбиение на классы идентичных алгоритмов~$\Omega(A)$,
уже не~зависят от этой нумерации.

\begin{Theorem}
    Для любого множества алгоритмов ${A\in\fA}$
    и любой перестановки $\pi \in S_L$ группы $S(A)$ и~$S(\pi(A))$ сопряжены:
    $S(\pi(A)) = \pi \circ S(A) \circ \pi^{-1}$.
\end{Theorem}

%В теории групп этот факт формулируется следующим образом:
%стационарные подгруппы точек, лежащих на
%одной орбите действия, получаются друг из друга сопряжением.
Сопряжение устанавливает изоморфизм групп $S(A)$ и $S(\pi(A))$.
Остается лишь проверить, что действие изоморфных групп на множествах $A$ и $\pi(A)$
действительно приведет к <<одинаковому>> разбиению на орбиты.

В следующей таблице приведен пример унимодальной цепочки~\cite{botov09mmro}.
Алгоритм $a_0$ является первым (и~наилучшим) в~цепочке;
$a_1, a_2, a_3$ составляют левую ветвь;
$a_4, a_5, a_6$ "--- правую.
\begin{center}
\vskip-2ex
\begin{tabular}[t]{|c|l|lll|lll|}
\hline
      & $a_0$ & $a_1$ & $a_2$ & $a_3$ & $a_4$ & $a_5$ & $a_6$ \\
\hline
$x_1$ & 0 & 1 & 1 & 1 & 0 & 0 & 0 \\
$x_2$ & 0 & 0 & 1 & 1 & 0 & 0 & 0 \\
$x_3$ & 0 & 0 & 0 & 1 & 0 & 0 & 0 \\
\hline
$x_4$ & 0 & 0 & 0 & 0 & 1 & 1 & 1 \\
$x_5$ & 0 & 0 & 0 & 0 & 0 & 1 & 1 \\
$x_6$ & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
\hline
\end{tabular}
\end{center}

Перенумерацией объектов выборки
(${x_1{\,\leftrightarrow\,}x_4}$, $x_2{\,\leftrightarrow\,}x_5$, $x_3{\,\leftrightarrow\,}x_6$)
можно поменять левую и правую ветвь местами.
Поэтому группой симметрии данного семейства является группа перестановок из двух элементов~$S_2$.
Идентичные алгоритмы в унимодальной цепочке "--- это пары алгоритмов с равным числом ошибок на полной выборке.

Естественно потребовать, чтобы
идентичные алгоритмы имели равные шансы реализоваться при обучении
и~давали равный вклад в~вероятность переобучения.
В~следующем параграфе мы обсудим связанные с~этим требованием ограничения
и~предложим рандомизированный метод обучения, при котором это действительно так.

\section{Рандомизированный метод обучения}

При минимизации эмпирического риска может возникать неоднозначность "---
несколько алгоритмов могут иметь одинаковое число ошибок на~обучающей выборке.
В~\cite{voron09mmro}
для устранения неоднозначности и~получения точных верхних оценок вероятности переобучения
использовалась \emph{пессимистичная} минимизация эмпирического риска "---
предполагалось, что в~случае неоднозначности выбирается алгоритм с~наибольшим числом ошибок на~генеральной выборке~$\XX$.
Это не устраняет неоднозначность окончательно.
Возможны ситуации, когда несколько алгоритмов имеют
наименьшее число ошибок на~обучающей выборке~$X$
и~одинаковое число ошибок на генеральной выборке~$\XX$.
\mbox{В~таких} случаях на множестве алгоритмов вводился линейный порядок,
и~среди неразличимых алгоритмов выбирался алгоритм с~б\'ольшим номером.
Введение приоритетности алгоритмов является искусственным приёмом,
не~имеющим адекватных аналогов среди известных методов обучения.

Ниже вводится рандомизированный метод обучения, лишенный этого недостатка.

Обычно метод обучения "--- это отображение, которое произвольной
выборке~$X$ ставит в~соответствие определённый алгоритм~$a\in A$.
Рандомизированный метод произвольной
выборке~$X$ ставит в~соответствие функцию распределения весов на~множестве~$A$.
Эта функция нормирована так, что
её~можно интерпретировать как вероятность получить данный алгоритм в~результате обучения.

Обозначим через $\XXell$ множество всех $\ell$"=элементных подмножеств $\XX$.
Каждый $X \in \XXell$
фиксирует разбиение генеральной выборки~$\XX$
на обучающую выборку~$X$
и~контрольную выборку~${\bar X = \XX{\setminus}X}$.
\mbox{Через} $n(a, X) = \sum\limits_{x \in X}a(x)$ обозначим
число ошибок алгоритма~$a\in \AA$ на множестве $X \subset \XX$.
Под~действием $\pi(X)$ понимается поэлементное действие отображения
$\pi \colon \XX \rightarrow \XX$
на каждый объект обучающей выборки:
$ \pi(X) = \{ \pi(x) \colon x \in X\}$.

\begin{Def}\label{searchMethod}
 \underline{}   \emph{Рандомизированным методом обучения }будем называть отображение вида
    \[
        \mu : \fA \times \XXell \times \AA \rightarrow [0, 1],
    \]
    удовлетворяющее при любых
    $A \in \fA$,\; ${X \in \XXell}$,\; $a,\, b \in A$ и~$\pi \in S_L$
    следующим условиям:
    \begin{enumerate*}
    \item $\sum\limits_{a \in A} \mu(A, X, a) = 1$;
    \item $n(a, X) = n(b, X) \;\to\; \mu(A, X, a) = \mu(A, X, b)$;
    \item $\mu(A, X, a) = \mu \bigl( \pi(A), \pi(X), \pi(a) \bigr)$.
    \end{enumerate*}
\end{Def}

Первое условие означает <<вероятностную>> нормировку весов алгоритмов.
Кроме того, оно обеспечивает нулевую <<вероятность>> алгоритмам, не принадлежащих множеству~$A$.

Второе условие означает, что при любом разбиении $\XX = X \sqcup \bar X$
вероятность получить алгоритм в~результате обучения
зависит только от количества ошибок алгоритма на обучении.

Третье условие означает, что метод обучения не~учитывает порядок объектов в выборке.

Частотой ошибок алгоритма~$a$ на выборке ${X \subset \XX}$ называется величина
$\nu(a, X) = \frac{1}{|X|}n(a,X)$.
Введем обозначение для разности частот ошибок алгоритма на контрольной и обучающей выборке:
$\delta(a, X) = \nu(a, \bar{X}) - \nu(a, X)$.

Вероятностью получить алгоритм~$a\in A$ в результате обучения назовем величину
\[
    P(a,A) = \frac1{C_L^\ell} \sum_{X \in \XXell} \mu(A, X, a).
\]

Для произвольного  $\epsilon \in [0, 1]$ определим
\emph{вклад} алгоритма $a\in A$ в~вероятность переобучения:
\[
    Q_\epsilon(a,A)
    =
    \frac1{C_L^\ell}
        \sum_{X \in \XXell}
            \mu(A, X, a)
            \bigl[ \delta(a, X) \geq \epsilon \bigr].
\]
и~саму \emph{вероятность переобучения}:
\[
    Q_\epsilon(A)
    =
    \sum_{a\in A} Q_\epsilon(a,A).
\]

%Напомним, что группы симметрий двух множеств алгоритмов, отличающихся нумерацией объектов,
%оказались изоморфны $S(A) \cong S(\pi(A))$.
Следующая теорема утверждает, что функционалы $Q(A)$ и $P(A, a)$
не зависят от нумерации объектов выборки.
\begin{Theorem}
    Вероятность получить алгоритм~$a$ в~результате обучения, а~также вероятность
    переобучения сохраняются при одновременном применении произвольной перестановки $\pi \in S_L$
    к множеству~$A$ и алгоритму~$a$:
    \begin{align*}
        Q(\pi(A)) &= Q(A), \\
        P(\pi(A), \pi(a)) &= P(A, a).
    \end{align*}
\end{Theorem}

Теперь можно сформулировать в виде двух теорем основной результат данного раздела:

\begin{Theorem}
    Вероятность получить идентичные алгоритмы в результате обучения одинакова:
    \[
         \forall \pi \in S(A) \text{ выполнено } P( \pi(a), A ) = P( a, A ).
    \]
\end{Theorem}

Напомним, что $\Omega(A)$ "--- множество классов идентичных алгоритмов,
$a_\omega \in A$ "--- произвольный представитель класса $\omega \in \Omega(A)$.

\begin{Theorem}
    Идентичные алгоритмы дают равный вклад в вероятность переобучения:
    \[
        Q_\epsilon(A) =
            \sum_{\omega \in \Omega(A)} |\,\omega| \,
            Q_\epsilon(A, a_\omega).
    \]
\end{Theorem}

\section{Вероятность переобучения\\ для семейств простой структуры}

Определим метод минимизации эмпирического риска,
удовлетворяющий определению~\ref{searchMethod}.
Выделим множество алгоритмов, допускающих  минимальное число ошибок на обучающей выборке:
\[
    E_{A,X} = \Argmin_{a\in A} n(a, X).
\]

В результате обучения методом минимизации эмпирического риска
все алгоритмы вне этого множества получают нулевой вес:
\[
    \mu(A, X, a)
    =
    \begin{cases}
        \frac1{|E_{A,X}|}, &  a     \in E_{A,X}; \\
        0,                 &  a \not\in E_{A,X}.
    \end{cases}
\]

%\emph{Цепочкой} будем называть линейно упорядоченное множество алгоритмов, в~котором вектор ошибок каждого следующего алгоритма отличается от~предыдущего только на~одном каком-то объекте.

\emph{Монотонной цепочкой} называется последовательность алгоритмов,
в~которой каждый следующий алгоритм допускает
ошибки на~тех же объектах, что предыдущий, и~ещё на~каком-то одном объекте.

\emph{Связкой из $p$ монотонных цепочек} называется множество алгоритмов,
полученное объединением $p$ штук монотонных цепочек равной длины (<<ветвей>>),
с~общим первым алгоритмом, при условии, что множества объектов,
на которых ошибаются алгоритмы ветвей, не пересекаются.

Связка из двух ветвей называется \emph{унимодальной цепочкой}.
Заметим, что монотонные и~унимодальные цепочки можно рассматривать как модели
однопараметрических семейств алгоритмов классификации
с~непрерывной по~параметру разделяющей поверхностью~\cite{voron09mmro,voron09dan}.

Нетрудно установить, что группа симметрии связки из $p$ монотонных цепочек является
симметрической группой $S_p$, действующей на ветви связки всевозможными перестановками.
Таким образом, классы идентичных алгоритмов
"--- это подмножества алгоритмов с~одинаковым числом ошибок на полной выборке,
называемые \emph{слоями}~\cite{voron09mmro}.

В следующей теореме мы получим явную формулу вероятности переобучения
для связки из~$p$~монотонных цепочек.
При этом нам понадобится комбинаторный коэффициент
$R_{D,p}^h(S,F)$, который зависит от параметров $S$~и~$F$,
от числа монотонных цепочек~$p$ и от их длины~$D$,
а также от $h$ "--- минимального значения параметра~$S$.
Коэффициент $R_{D,p}^h(S,F)$ равен числу способов представить число~$S$
в виде суммы $p$~неотрицательных слагаемых, $S = t_1+ \ldots + t_p$,
каждое из которых не превосходит~$D$.
При этом ровно $F$~слагаемых не должно равняться~$D$,
а на первое слагаемое накладывается дополнительное ограничение $t_1 \geq h$.

\begin{Theorem}
\label{th:pMonot}
    Рассмотрим связку из $p$ монотонных цепочек,
    в которой лучший алгоритм допускает $m$ ошибок на полной выборке,
    длина каждой ветви без учета лучшего алгоритма "--- $D$.
    Тогда при обучении рандомизированным методом
    вероятность переобучения может быть записана в виде:
    \[
            Q_\epsilon(A) =
                \sum_{h=0}^{D}
                \sum_{S=h}^{p D}
                \sum_{F = 0}^{p}
                \frac{|\omega_h| R_{D, p}^h(S, F)}{1 + S}
                \frac{C_{L'}^{\ell'}}{C_L^\ell}
                H_{L'}^{\ell', m}(s(\epsilon)),
    \]
    где
        $L' = L {-} S {-} F$,\;
        $\ell' = \ell {-} F$,\;
        $s(\epsilon) = \bigl\lfloor \frac{\ell}L (m {+} h {-} \epsilon k) \bigr\rfloor$;\;
        $|\omega_h| = 1$ при $h = 0$ и $|\omega_h| = p$ при ${h \geq 1}$;\;
        $H_{L'}^{\ell', m}(s)$ "--- функция гипергеометрического распределения \cite{voron09mmro}.
\end{Theorem}

Связка из $p$ монотонных цепочек является обобщением трёх частных случаев, рассмотренных в~\cite{voron09dan}:
монотонной цепочки ($p=1$),
унимодальной цепочки ($p=2$)
и~единичной окрестности лучшего алгоритма ($D=1$).
Вычисляя конкретные выражения комбинаторного коэффициента $R_{D, p}^h(S, F)$
для этих трех случаев, получим три следствия.

\begin{Corollary}
    Для монотонной цепочки длины $D+1$ вероятность переобучения равна
    \[
        Q_\epsilon =
            \sum_{h=0}^{D} \sum_{S=h}^D
            \frac{1}{1 + S}
            \frac{C_{L'}^{\ell'}}{C_L^\ell}
            H_{L'}^{\ell', m}(s(\epsilon)),
    \]
    где
    $L' = L - S - [S{\neq}D]$,\;
    $\ell' = \ell - [S{\neq}D]$.
\end{Corollary}

\begin{Corollary}
    Для унимодальной цепочки с~ветвями длины~$D$ вероятность переобучения равна
    \[
        Q_\epsilon =
            \sum_{h=0}^{D} \sum_{t_1=h}^D \sum_{t_2 = 0}^{D}
            \frac{|\omega_h|}{1 + S}
            \frac{C_{L'}^{\ell'}}{C_L^\ell}
            H_{L'}^{\ell', m}(s(\epsilon)),
    \]
    где
    $S = t_1 + t_2$,\;
    $F = [t_1{\neq}D] + [t_2{\neq}D]$,
    остальные обозначения те~же, что в~теореме~\ref{th:pMonot}.
\end{Corollary}

\begin{Corollary}
    Для единичной окрестности из ${p+1}$ алгоритма вероятность переобучения равна
    \[
        Q_\epsilon(A) =
            \sum_{h=0}^{1}
            \sum_{S=h}^{p}
            \frac{|\omega_h| C_{p-h}^{S-h}}{1 + S}
            \frac{C_{L'}^{\ell'}}{C_L^\ell}
            H_{L'}^{\ell', m}(s(\epsilon)),
    \]
    где
    $L' = L {-} p$,\;
    $\ell' = \ell {+} S {-} p$.
\end{Corollary}

\section{Численный эксперимент}

На~рис.\,\ref{fig:Monot}~и~\ref{fig:Unit} представлены результаты численных экспериментов.
Из~четырех кривых на~каждом графике верхняя (жирная) соответствует пессимистической минимизации эмпирического риска~\cite{voron09dan,voron09mmro},
нижняя "--- оптимистической.
Две почти сливающиеся кривые между ними соответствуют рандомизированной минимизации эмпирического риска.
\mbox{Одна из них} вычислена по доказанным формулам,
вторая построена методом Монте-Карло по~$10^5$ случайных разбиений,
при равновероятном выборе лучшего алгоритма в~случаях неопределённости.
Совпадение этих двух кривых подтверждает справедливость развитой выше теории.
\begin{figure}[t]
    \centering
    \includegraphics[width=70mm,height=45mm]{frey_monot.eps}
    \caption{Зависимость $Q_\epsilon$ от~$\epsilon$ для монотонной цепочки при $L=100$, $\ell=60$, $D=40$, $m=20$.}
    \label{fig:Monot}
    \medskip
    \includegraphics[width=70mm,height=45mm]{frey_unit.eps}
    \caption{Зависимость $Q_\epsilon$ от~$\epsilon$ для единичной окрестности при $L=100$, $\ell=60$, $p=10$, $m=20$.}
    \label{fig:Unit}
\end{figure}

\section{Выводы}

Свойство симметрии семейств алгоритмов позволяет упрощать получение
вычислительно эффективных формул вероятности переобучения.
В~частности, удалось вывести оценки
для монотонной и~унимодальной цепочек, а~также для единичной окрестности лучшего алгоритма
как следствия одной общей теоремы,
в~то~время как ранее аналогичные оценки доказывались независимо
и~при неестественном предположении об~априорной упорядоченности алгоритмов в~семействе.

\begin{thebibliography}{1}
\bibitem{vapnik74rus}
    \BibAuthor{Вапник\;В.\,Н., Червоненкис\;А.\,Я.}
    \BibTitle{Теория распознавания  образов}. "---
    М.:~Наука, 1974.
\bibitem{vapnik98stat}
    \BibAuthor{Vapnik~V.}
    \BibTitle{Statistical Learning Theory}. "---
    New York: Wiley, 1998.
\bibitem{voron09dan}
    \BibAuthor{Воронцов\;К.\,В.}
    \BibTitle{Точные оценки вероятности переобучения}~//
    Доклады РАН, 2009 (в~печати).
\bibitem{voron09mmro}
    \BibAuthor{Воронцов\;К.\,В.}
    \BibTitle{Комбинаторный подход к~проблеме переобучения}~//
    Всеросс. конф. ММРО-14 "--- М.~МАКС Пресс, 2009 "---
    C.\,\globalpageref{Vorontsov_TF:begin}--\globalpageref{Vorontsov_TF:end}  (в~настоящем сборнике).
\bibitem{botov09mmro}
    \BibAuthor{Ботов\;П.\,В.}
    \BibTitle{Точные оценки вероятности переобучения для монотонных и унимодальных семейств алгоритмов}~//
    Всеросс. конф. ММРО-14 "--- М.~МАКС Пресс, 2009 "---
    C.\,\globalpageref{Botov_TF:begin}--\globalpageref{Botov_TF:end}  (в~настоящем сборнике).
\bibitem{vinberg2001}
    \BibAuthor{Винберг\;Э.\,Б.}
    \BibTitle{Курс алгебры}~//
    М.:~Факториал Пресс, 2001. "--- 544~с.
\end{thebibliography}

\end{document}

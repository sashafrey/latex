BigARTM --- библиотека тематического моделирования, реализующая концепцию аддитивной регуляризации. На данный момент библиотека поддерживает многопроцессорный паралеллизм. Основным алгоритмом является описанный в \ref{plsa_alg} Online Batch PLSA.

\paragraph{Protocol buffers}
\footnote{Подробнее о том, что такое Google Protocol Buffers и как с ними работать, можно прочесть в \cite{protobuf}}
Рассмотрим кратко эту технологию, поскольку в BigARTM она используется очень интенсивно. Protocol Buffers позволяет описывать proto-сообщения на псевдоязыке, которые затем можно преобразовать специальным компилятором (protoc) в структуры данных со всеми необходимыми методами на С++, Python и Java. Ключевой особенностью является возможность обмена сообщениями между этими языками программирования посредством механизма serializer/deserializer, переводящего сообщения в байт-массив и обратно. Данное решение является максимально переносимым и унифицированным.

Все конфигурации библиотеки, такие как настройки тематической модели, параметры регуляризаторов и т.п., определяются и передаются только посредством proto-сообщений. Результирующая модель также описывается соответствующим сообщением. 

{\bf Замечание:} Все необходимые для работы с библиотекой сообщения будут описаны при дальнейшем изложении.

\subsection{Краткое описание}

\paragraph{Представление коллекции} Коллекция представляется в виде <<мешка слов>> (Bag of words). Поскольку библиотека предназначена для обработки больших массивов текстовой информации, она является онлайновой. Механизм потоковой загрузки и обработки информации реализуется разделением коллекции на пакеты (\verb|Batch|), которые обрабатываются по очереди. Каждый \verb|Batch| имеет свой словарь, который может быть как локальным (что предпочтительнее), так и совпадающим со всем словарём коллекции. 

Приведём здесь соответствующее proto-сообщение:

\vspace{4pt}
\noindent
\verb|message Batch {| \\
\verb|  repeated string token = 1;| \\
\verb|  repeated Item item = 2;| \\
\verb|}|
\vspace{4pt}

Первое поле --- набор терминов (словарь), второе --- набор документов (см. \ref{item_label}).

{\bf Замечание:} В силу внутренних особенностей работы BigARTM, оптимальное число \verb|Batches| --- в 4-5 раз больше, чем число используемых процессоров. Этот параметр не повлиет на качество результирующей модели, но скажется на производительности.

\paragraph{Представление документов}\label{item_label}
 В BigARTM реализована гибкая концепция представления данных. Каждый документ является экземпляром класса \verb'Item'. Этот объект, помимо самого документа (хранимого в виде последовательности терминов и их счётчиков), \verb'Item' может содержать произвольные метаданные, связанные с ним. К таким данным относятся информация об авторе, дате публикации, ссылках на документ и из него, тегах и т.п. Всё это может оказаться крайне полезным при использовании тех или иных регуляризаторов.
 
 Рассмотрим proto-сообщение для \verb|Item|
   
 \vspace{4pt}
 \noindent
 \verb|message Item {| \\
 \verb|  optional int32 id = 1;| \\
 \verb|  repeated Field field = 2;| \\
 \verb|}|
 \vspace{4pt} 
 
 Здесь \verb|id| --- идентификатор документа, второе поле --- набор всевозможных объектов в тексте. Объектом может быть сам текст документа, строка с авторами, список тегов и т.п. Работа механизма становится ясной, если взглянуть на определение сообщения для \verb|Field|
 
 \vspace{4pt}
 \noindent
 \verb|message Field {| \\
 \verb|  optional string field_name = 1 [default = "@body"];| \\
 \verb|  repeated int32 token_id = 2;| \\
 \verb|  repeated int32 token_count = 3;| \\
 \verb|}|
 \vspace{4pt} 
 
 Первое поле сообщает о том, что это за объект (по-умолчанию --- основной текст документа). Второе поле содержит список идентификаторов терминов, встречающихся в этом тексте. В третьем находятся соответствующие этим терминам счётчики встречаемости в этом документе.

\paragraph{Входные и выходные данные}
На вход функциям библиотеки могут подаваться как исходные тексты, так и коллекция в виде пакетов. Это крайне удачное решение, так как, во-первых, коллекция в пакетном виде занимает более чем в два раза меньше памяти
\footnote{Никакой архивации при этом не производится. Каждый Batch представляет собой набор Item в виде сериализованных proto-сообщений. Это было сделано из соображений удобства использования, а объём уменьшается в виде побочного эффекта.}
, чем в исходном текстовом, во-вторых, библиотеке не придётся производить процедуру преобразования, что сэкономит время. 
На выходе пользователь получает собственно тематическую модель (матрицу $\Phi$).

\paragraph{Особенности архитектуры} Рассмотрим архитектуру библиотеки на концептуальном уровне.
Для каждого участвующего в работе алгоритма процессора создаётся соответствующий ему объект класса \verb|Processor|. Процессоры взаимодействуют независимо друг от друга. Задача процессора --- производить собственно вычисления. У процессорного элемента имеется своя копия матрицы $\Phi$, которую он использует. Также у каждого \verb|Processor| имеется т.н. очередь процессора, в которую поступают пакеты данных. Процессор анализирует их, выводя матрицу $\Theta$ (сама матрица при этом явным образом в памяти не хранится). После  полученные результаты (счётчики статистик) отправляются в виде блоков в т.н. очередь слияния. Очередь слияния --- это место, откуда получает информацию экземпляр класса \verb|Merger|. Этот объект отвечает за объединение результатов, полученных от всех процессоров, в одно целое и обновление матрицы $\Phi$. Эта матрица используется в работе процессоров. При этом хранится две копии матрицы $\Phi$ --- новая и старая. Старая матрица является доступной для чтения всем процессорам, новая доступна в режиме read-write только \verb|Merger|. В неё записываются обновления статистик, полученные во время очередного прохода по коллекции. После окончания прохода старая матрица замещается новой (операция дешёвая, происходит простое копирование указателей), а под следующую новую матрицу выделяется память.

\paragraph{Ключевые отличия и заимствования}
Обращаясь к разделу \ref{overview}, сравним кратко архитектуру BigARTM с существующими реализациями.
Некоторые идеи, использованные при создании BigARTM, были позаимствованы из ранних работ по схожей тематике~(\cite{smola}, \cite{ad_lda}).
сравнения не было, но будет, как только получим кластерное рапраллеливание

Далее будут рассмотрены основные шаги по настройке и использованию существующей версии BigARTM, а также список нововведений, которые будут в неё внесены в будущем (либо уже внесены, но требуют доработки).

{\bf Замечание:} На данный момент единственным поддерживаемым библиотекой языком является Python, все выкладки будут производится на нём.

{\bf Замечание:} Здесь и далее под внешней итерацией работы алгоритма понимается один проход по всей коллекции, а под внутренней --- один проход по одному документу (\verb|Item|). 

\subsection{Установка}

Для установки библиотеки необходимо выполнить следующую последовательность действий:

\begin{enumerate}
	\item Установить и распаковать boost 1.55, после чего присвоить системной переменной \verb|BOOST\_ROOT| путь к корню распакованной папки (если переменная не существует, необходимо создать её).
	\item Скачать по адресу \url{https://s3-eu-west-1.amazonaws.com/artm/libs_win32_v110.7z} 
	статические библиотеки, необходимые для работы, и распаковать в папку \verb|libs| в корневой директории BigARTM. 
	\item Скачать по адресу
	\url{http://miru.hk/archive/ZeroMQ-4.0.3~miru1.0-x86.exe}
	библиотеку ZeroMQ, распаковать её, и присвоить системной переменной \verb|ZEROMQ32\_ROOT| путь к корневой директории ZeroMQ (если переменная не существует, необходимо создать её).
	\item Установить Python 2.7 (x32)
	\item Добавить корневую папку Python в переменную окружения \verb|PATH|.
	\item Следуйте инструкциям, описанным в файле
	
	\vspace{5pt}
	\verb|BigARTM_ROOT_DIRECTORY\3rdparty\protobuf\python\README.txt| 
\end{enumerate}

\subsection{Работа с библиотекой}

\paragraph{Запуск обучения} Основным классом, обеспечивающем пользовательский API, является \verb|MasterComponent|. Объект данного класса содержит в себе все созданные тематические модели и регуляризаторы, через него производится управление процессом обучения. 

Для того, чтобы запустить обучение тематической модели, требуется пошаговое выполнение следующей инструкции:

\begin{enumerate}
	\item Ядро библиотеки представляет собой скомпилированный модуль \verb|artm.dll|. Прежде всего требуется подключить его. Чтобы это сделать, необходимо поместить в программу следующие строки:
	
	\vspace{5pt}
	
	\verb|  address = os.path.abspath(os.path.join(os.curdir, os.pardir))| \\
	\verb|  os.environ['PATH'] = ';'.join([address + | \\
	\verb|    '\\Win32\\Release', os.environ['PATH']])| \\
	\verb|  library = ArtmLibrary(address + '\\Win32\\Release\\artm.dll')|
	
	\vspace{5pt}
	
	\item Необходимо создать объект класса \verb|MasterComponent|. Для этого нужно описать соответствующее proto-сообщение, которое (в базовой конфигурации) требует заполнения следующих полей:
	
	\vspace{5pt}
	
	\verb|  optional int32 processors_count = 2 [default = 1];| \\
	\verb|  optional string disk_path = 3;|
	
	\vspace{5pt}
	
	Первое поле представляет собой число процессоров, в рамках которых будет производится распараллеливание алгоритма. Второе поле описывает путь к папке, в которую будут сохранятся данные, преобразованные в \verb|Batches| (кроме того, именно в этой папке библиотека будет искать пакеты для своей работы). Создание и описание этого сообщения может иметь следующий вид:
	
	\vspace{5pt}
	
	\verb|  master_config = messages_pb2.MasterComponentConfig()| \\
	\verb|  master_config.processors_count = 1| \\
	\verb|  master_config.disk_path = 'disk_path'|	
	
	\vspace{5pt}
	
	После того, как конфигурационное сообщение сформировано, можно создать сам объект \verb|MasterComponent|:
	
	\vspace{5pt}
	
	\verb|  master_component = library.CreateMasterComponent(master_config)|
	
	\vspace{5pt}
	
	\item Следующим шагом требуется загрузить коллекцию и словарь для неё. Данное действие является техническим, в качестве базового примера можно использовать считывание, описанное в \verb|python_client.py|. 
	
	\item
	\label{step_1}
	 Теперь в \verb|master_component| нужно добавить тематические модели для обучения. Допустим, что требуется обучить одну модель. Для её создания необходимо заполнить соответствующее proto-сообщение. Оно будет выглядеть так:

	\vspace{5pt}

	\verb|  optional string name = 1 [default = ""];| \\
	\verb|  optional int32 topics_count = 2 [default = 32];| \\	
	\verb|  optional int32 inner_iterations_count = 4 [default = 10];| \\
	\verb|  repeated Score score = 7;|
	
	\vspace{5pt}
	
	Параметры имеют следующие назначения: 	\verb|name| --- имя тематической модели; \verb|topic_counts| --- число тем, которые будет искать в коллекции данная модель; третий  параметр назначает модели число внутренних итераций; в последнем поле указываются функционалы качества, которые наобходимо рассчитывать для данной модели в ходе её работы
	\footnote{На данный момент в библиотеке реализована только перплексия.}
	. Создать конфигурацию модели можно так:
	
	\vspace{5pt}
	
	\verb|  model_config = messages_pb2.ModelConfig()| \\
	\verb|  model_config.topics_count = 20| \\
	\verb|  model_config.inner_iterations_count = 10| \\	
	\verb|  score_ = model_config.score.add()| \\
	\verb|  score_.type = 0|
	        
	\vspace{5pt}
	
	\verb|score_.type = 0| соответствует добавлению модель требование подсчёта перплексии на каждой итерации. Теперь можно создать саму модель, отнеся её к созданному ранее объекту \verb|MasterComponent|, после чего активировать:
	
	\vspace{5pt}
	
	\verb|	model = master_component.CreateModel(master_component, model_config)| \\
	
	\vspace{5pt}
	
	\item 
	\label{step_2}
	После того, как модель была создана, необходимо запустить работу алгоритма
	\footnote{Вообще говоря, прежде, чем начинать счёт, в модель стоит добавить регуляризаторы. О том, как это сделать, подробно написано в соответствующем разделе.}
	. Для этого нужно описать цикл по числу внешних итераций (это число определяется пользователем), внутри которого должны быть такие строки кода:
	
	\vspace{5pt}
	
	\verb|  master_component.InvokeIteration(1)| \\
	\verb|  master_component.WaitIdle();|
	        
	\vspace{5pt}	
	
	Первая строка производит вызов одной внешней итерации работы алгоритма, вторая --- ожидание завершения выполнения это итерации.
	
	Этого достаточно для запуска алгоритма, однако в большинстве случаев требуется контролировать его работу (в т.ч. и следить за перплексией на данной итерации). Для этого следует выгрузить посчитанную на данный момент модель и просмотреть её параметры. Выгрузить модель можно, добавив ещё одну строку под предыдущими:
	
	\vspace{5pt}

	\verb|  topic_model = master_component.GetTopicModel(model)|
	        
	\vspace{5pt}		 
	
	Как было указано ранее, сама модель описывается proto-сообщением. Это сообщение имеет такой вид:

	\vspace{5pt}		 

	\verb|  optional string name = 1 [default = ""];| \\
	\verb|  optional int32 topics_count = 2;| \\
	\verb|  optional int32 items_processed = 3;| \\
	\verb|  repeated string token = 4;| \\
	\verb|  repeated FloatArray token_weights = 5;| \\
	\verb|  optional DoubleArray scores = 6;|	
	
	\vspace{5pt}
	
	Первые два поля были описаны ранее и имеют тот же смысл. Третье содержит число обработанных на данный момент документов (учитываются все проходы по каждому документу, включая повторные). В четвёртом поле лежит словарь для данной модели. В пятом --- веса каждого термина, полученные в результате работы алгоритма (матрица $\Phi$). Последнее поле содержит значения счётчиков на данной итерации (в описываемом примере --- значение перплексии). Данную информацию можно извлекать после каждой итерации и использовать для оценивания качества обучения.
	
	Выгруженная после последней внешней итерации тематическая модель является финальным результатом работы алгоритма.
	
	\item В случае необходимости перенастройки \verb|master_component| или \verb|model| используется функция \verb|Reconfigure()|:
	
	\vspace{5pt}

	\verb|  master_component.Reconfigure(new_master_config)| \\
	\verb|  model.Reconfigure(new_model_config)| 
	        
	\vspace{5pt}
	
	\item После окончания работы модели удалять её не нужно. Все модели будут автоматически удалены при вызове деструктора \verb|MasterComponent|.	
	
\end{enumerate}

{\bf Замечание:} Базовых типов \verb'DoubleArray' и \verb'FloatArray' в protocol buffers нет, это пользовательские тип, эквивалентные вещественному массиву (работать с ними нужно по тем же правилам, что и остальными сообщениями --- через создаваемый protocol buffers интерфейс).

{\bf Замечание:} Все функции типа \verb|Reconfigure()| являются не до конца тестированными, поэтому должны использоваться с осторожностью.

{\bf Замечание:} Пример пользовательского приложения над BigARTM можно найти в файле \verb|BigARTM\_ROOT\_DIRECTORY\src\python_client\python_client|. Выдержки кода, указанные в вышеописанной инструкции, заимствованы оттуда.

\subsection{Планируемые нововведения}

Ниже приведён список различных модификаций, которые появятся в release-версии библиотеки:

\begin{itemize}
	\item Кластерный параллелизм.
	\item Возможность работы в Linux.
	\item Интерфейсы на C++ и Java.
	\item Коллекция регуляризаторов.
	\item Поддержка 64-битной архитектуры.
	\item Усовершенствованный механизм хранения данных, необходимых для работы регуляризаторов.
	\item Коллекция функционалов качества.
	\item Хранение матриц $\Phi$ и $\Theta$ в разреженном виде.
\end{itemize}
BigARTM --- библиотека тематического моделирования, реализующая концепцию аддитивной регуляризации. На данный момент библиотека поддерживает многопроцессорный параллелизм. Основным алгоритмом является описанный в \ref{plsa_alg} Online Batch PLSA.

\paragraph{Protocol buffers.}
\footnote{Подробнее о том, что такое Google Protocol Buffers и как с ними работать, можно прочесть в \cite{protobuf}}
Рассмотрим кратко эту технологию, поскольку в BigARTM она используется очень интенсивно. Protocol Buffers позволяет описывать proto-сообщения на псевдоязыке, которые затем можно преобразовать специальным компилятором (protoc) в структуры данных со всеми необходимыми методами на С++, Python и Java. Ключевой особенностью является возможность обмена сообщениями между этими языками программирования посредством механизма serializer/deserializer, переводящего сообщения в байт-массив и обратно. Данное решение является максимально переносимым и унифицированным.

Все конфигурации библиотеки, такие, как настройки тематической модели, параметры регуляризаторов и т.п., определяются и передаются только посредством proto-сообщений. Результирующая модель также описывается соответствующим сообщением. 

{\bf Замечание:} Все необходимые для работы с библиотекой сообщения будут описаны при дальнейшем изложении.

Далее будет рассмотрено краткое описание библиотеки, основные шаги по настройке и использованию существующей версии BigARTM, а также список нововведений, которые будут в неё внесены в будущем (либо уже внесены, но требуют доработки).

\subsection{Краткое описание}

\subsubsection{Представление коллекции} 
$\quad\;\:$Коллекция представляется в виде <<мешка слов>> (Bag of words). Поскольку библиотека предназначена для обработки больших массивов текстовой информации, она является онлайновой. Механизм потоковой загрузки и обработки информации реализуется разделением коллекции на пакеты (\verb|Batch|), которые обрабатываются по очереди. Каждый \verb|Batch| имеет свой словарь, который может быть как локальным (что предпочтительнее), так и совпадающим со всем словарём коллекции. 

Приведём здесь соответствующее proto-сообщение:

\vspace{4pt}
\noindent
\verb|message Batch {| \\
\verb|  repeated string token = 1;| \\
\verb|  repeated Item item = 2;| \\
\verb|}|
\vspace{4pt}

Первое поле --- набор терминов (словарь), второе --- набор документов (см. \ref{item_label}).

{\bf Замечание:} В силу внутренних особенностей работы BigARTM, оптимальное число \verb|Batches| --- в 4-5 раз больше, чем число используемых процессоров. Этот параметр не повлиет на качество результирующей модели, но скажется на производительности.

\subsubsection{Представление документов}\label{item_label}
 $\quad\;\:$В BigARTM реализована гибкая концепция представления данных. Каждый документ является экземпляром класса \verb'Item'. Этот объект, помимо самого документа (хранимого в виде последовательности терминов и их счётчиков), может содержать произвольные метаданные, связанные с ним. К таким данным относятся информация об авторе, дате публикации, ссылках на документ и из него, тегах и т.п. Всё это может оказаться крайне полезным при использовании тех или иных регуляризаторов.
 
 Рассмотрим proto-сообщение для \verb|Item|
   
 \vspace{4pt}
 \noindent
 \verb|message Item {| \\
 \verb|  optional int32 id = 1;| \\
 \verb|  repeated Field field = 2;| \\
 \verb|}|
 \vspace{4pt} 
 
 Здесь \verb|id| --- идентификатор документа, второе поле --- набор всевозможных объектов в тексте. Объектом может быть сам текст документа, строка с авторами, список тегов и т.п. Работа механизма становится ясной, если взглянуть на определение сообщения для \verb|Field|
 
 \vspace{4pt}
 \noindent
 \verb|message Field {| \\
 \verb|  optional string field_name = 1 [default = "@body"];| \\
 \verb|  repeated int32 token_id = 2;| \\
 \verb|  repeated int32 token_count = 3;| \\
 \verb|}|
 \vspace{4pt} 
 
 Первое поле сообщает о том, что это за объект (по-умолчанию --- основной текст документа). Второе поле содержит список идентификаторов терминов, встречающихся в тексте этого объекта. В третьем находятся соответствующие этим терминам счётчики встречаемости в данном документе.

\subsubsection{Входные и выходные данные}
$\quad\;\:$На вход функциям библиотеки могут подаваться как исходные тексты, так и коллекция в виде пакетов. Это крайне удачное решение, поскольку, во-первых, коллекция в пакетном виде занимает более чем в два раза меньше памяти
\footnote{Никакой архивации при этом не производится. Каждый Batch представляет собой набор Item в виде сериализованных proto-сообщений. Это было сделано из соображений удобства использования, а объём уменьшается в виде побочного эффекта.}
, чем в исходном текстовом, во-вторых, библиотеке не придётся производить процедуру преобразования, что сэкономит время. 
На выходе пользователь получает собственно тематическую модель (матрицу $\Phi$).

\subsubsection{Архитектура библиотеки} 
$\quad\;\:$Для начала рассмотрим на концептуальном уровне параллелизм в рамках одной машины. На каждый процессор, участвующий в работе, создаётся экземпляр класса \verb|Processor|. Объекты этого класса отвечают за вывод столбцов матрицы $\Theta$, каждый из них работает независимо от других и обрабатывает свой пакет документов. Для процессоров имеется т.н. очередь процессоров, откуда \verb|Processor| извлекает очередной блок документов, закончив обработку предыдущего. Кроме того, существует т.н. очередь слияния, куда все процессоры отправляют полученные результаты. Сама матрица $\Theta$ при этом в явном виде нигде не хранится. Важно заметить, что у процессоров нет никакого <<шага синхронизации>>, вся обработка и отправка результатов осуществлется асинхронно.

В рамках компьютера создаётся единственный объект класса \verb|Merger|. Он играет роль мастера при межпроцессорном параллелизме. Его задача --- извлекать из очереди слияния данные, полученные процессорами, и обновлять матрицу $\Phi$. \verb|Merger| в явном виде хранит две версии матрицы $\Phi$ --- <<активную>> и <<базовую>>. К первой обращаются во время своей работы процессоры, вторую \verb|Merger| может безопасно обновлять. \verb|Merger| определяет, когда нужно переключиться на новую <<активную>> матрицу. Тем не менее, все процессоры, начавшие обработку очередного пакета со старой матрицей, с ней и будут работать. Доступ к новой матрице они получат, начав обработку нового блока документов. Все операции с матрицами $\Phi$ не затратные --- удаления, замены, отсылка данных производятся посредством работы с указателями. Все используемые данные хранятся в оперативной памяти, новые пакеты документов подгружаются с жёсткого диска.

{\bf Замечание:} На самом деле, нет строгого запрета задавать функциям библиотеки большее число процессоров, чем их фактически существует. Однако это увеличит нагрузку на \verb|Merger|, что приведёт к снижению эффективности работы. Рекомендация --- указывать число используемых процессоров не превосходящим числа физических процессоров.

Кластерный параллелизм находится в данный момент на стадии разработки. Ноды будут работать по принципу, описанному выше. На мастере будет создан экземпляр класса \verb|NetworkMerger|, отвечающий за слияние данных, полученных на локальных \verb|Merger|, а также за предоставление им актуальной информации о матрице $\Phi$.

\subsection{Установка}

$\quad\;\:$Для установки библиотеки необходимо выполнить следующую последовательность действий:

\begin{enumerate}
	\item Скачать по адресу
	\url{http://miru.hk/archive/ZeroMQ-4.0.3~miru1.0-x86.exe}
	библиотеку ZeroMQ, распаковать её, и присвоить системной переменной \verb|ZEROMQ32\_ROOT| путь к корневой директории ZeroMQ (если переменная не существует, необходимо создать её).
	\item Установить Python 2.7 (x32)
	\item Добавить корневую папку Python в переменную окружения \verb|PATH|.
	\item Следовать инструкциям, описанным в файле
	
	\vspace{5pt}
	\verb|BigARTM_ROOT_DIRECTORY\protobuf\python\README.txt| 
\end{enumerate}

\subsection{Работа с библиотекой}

$\quad\;\:${\bf Замечание:} На данный момент единственным поддерживаемым библиотекой языком является Python, все выкладки будут производится на нём.

{\bf Замечание:} Здесь и далее под внешней итерацией работы алгоритма понимается один проход по всей коллекции, а под внутренней --- один проход по одному документу (\verb|Item|). 

\paragraph{Запуск обучения.} Основным классом, обеспечивающем пользовательский API, является \verb|MasterComponent|. Объект данного класса содержит в себе все созданные тематические модели и регуляризаторы, через него производится управление процессом обучения. 

Для того, чтобы запустить обучение тематической модели, требуется пошаговое выполнение следующей инструкции:

\begin{enumerate}
	\item Ядро библиотеки представляет собой скомпилированный модуль \verb|artm.dll|. Прежде всего, требуется подключить его. Чтобы это сделать, необходимо поместить в программу следующие строки:
	
	\vspace{5pt}
	
	\verb|  os.environ['PATH'] = ';'.join([address + | \\
	\verb|    '\\Win32\\Release', os.environ['PATH']])| \\
	\verb|  library = ArtmLibrary(address + '\\artm.dll')|
	
	\vspace{5pt}
	
	Здесь \verb|address| --- местоположение модуля библиотеки.
	
	\item Необходимо создать объект класса \verb|MasterComponent|. Для этого опишем соответствующее proto-сообщение, которое (в базовой конфигурации) требует заполнения следующих полей:
	
	\vspace{5pt}
	
	\verb|  optional int32 processors_count = 2 [default = 1];| \\
	\verb|  optional string disk_path = 3;|
	
	\vspace{5pt}
	
	Первое поле представляет собой число процессоров, в рамках которых будет производится распараллеливание алгоритма. Второе поле описывает путь к папке, в которую будут сохранятся данные, преобразованные в \verb|Batches| (кроме того, именно в этой папке библиотека будет искать пакеты для своей работы). Создание и описание этого сообщения может иметь следующий вид:
	
	\vspace{5pt}
	
	\verb|  master_config = messages_pb2.MasterComponentConfig()| \\
	\verb|  master_config.processors_count = 1| \\
	\verb|  master_config.disk_path = 'disk_path'|	
	
	\vspace{5pt}
	
	После того, как конфигурационное сообщение сформировано, можно создать сам объект \verb|MasterComponent|:
	
	\vspace{5pt}
	
	\verb|  master_component = library.CreateMasterComponent(master_config)|
	
	\vspace{5pt}
	
	\item Следующим шагом требуется загрузить коллекцию и словарь для неё. Данное действие является техническим, в качестве базового примера можно использовать считывание, описанное в \verb|python_client.py|. 
	
	\item
	\label{step_1}
	 Теперь в \verb|master_component| нужно добавить тематические модели для обучения. Допустим, что требуется обучить одну модель. Для её создания необходимо заполнить соответствующее proto-сообщение. Оно будет выглядеть так:

	\vspace{5pt}

	\verb|  optional string name = 1 [default = ""];| \\
	\verb|  optional int32 topics_count = 2 [default = 32];| \\	
	\verb|  optional int32 inner_iterations_count = 4 [default = 10];| \\
	\verb|  repeated Score score = 7;| \\
    \verb|  repeated string regularizer_name = 10;| \\
    \verb|  repeated double regularizer_tau = 11;|	
	
	\vspace{5pt}
	
	Параметры имеют следующие назначения: 	\verb|name| --- имя тематической модели; \verb|topic_counts| --- число тем, которые будет искать в коллекции данная модель; третий  параметр назначает модели число внутренних итераций; в поле \verb|score| указываются функционалы качества, которые наобходимо рассчитывать для данной модели в ходе её работы
	\footnote{На данный момент в библиотеке реализована только перплексия.}
	. Последние два поля будут рассмотрены в разделе \ref{regularizers}. Создать конфигурацию модели можно так:
	
	\vspace{5pt}
	
	\verb|  model_config = messages_pb2.ModelConfig()| \\
	\verb|  model_config.topics_count = 20| \\
	\verb|  model_config.inner_iterations_count = 10| \\	
	\verb|  score_ = model_config.score.add()| \\
	\verb|  score_.type = 0|
	        
	\vspace{5pt}
	
	\verb|score_.type = 0| соответствует добавлению модель требование подсчёта перплексии на каждой итерации. Теперь можно создать саму модель, отнеся её к созданному ранее объекту \verb|MasterComponent|:
	
	\vspace{5pt}
	
	\verb|	model = master_component.CreateModel(master_component, model_config)| \\
	
	\vspace{5pt}
	
	\item 
	\label{step_2}
	После того, как модель была создана, необходимо запустить работу алгоритма
	\footnote{Вообще говоря, прежде, чем начинать счёт, в модель стоит добавить регуляризаторы. О том, как это сделать, подробно написано в соответствующем разделе.}
	. Для этого нужно описать цикл по числу внешних итераций (это число определяется пользователем), внутри которого должны быть такие строки кода:
	
	\vspace{5pt}
	
	\verb|  master_component.InvokeIteration(1)| \\
	\verb|  master_component.WaitIdle();|
	        
	\vspace{5pt}	
	
	Первая строка производит вызов одной внешней итерации работы алгоритма, вторая --- ожидание завершения выполнения это итерации.
	
	Этого достаточно для запуска алгоритма, однако в большинстве случаев требуется контролировать его работу (в т.ч. и следить за перплексией на данной итерации). Для этого следует выгрузить посчитанную на данный момент модель и просмотреть её параметры. Выгрузить модель можно, добавив ещё одну строку под предыдущими:
	
	\vspace{5pt}

	\verb|  topic_model = master_component.GetTopicModel(model)|
	        
	\vspace{5pt}		 
	
	Как было указано ранее, сама модель описывается proto-сообщением. Это сообщение имеет такой вид:

	\vspace{5pt}		 

	\verb|  optional string name = 1 [default = ""];| \\
	\verb|  optional int32 topics_count = 2;| \\
	\verb|  optional int32 items_processed = 3;| \\
	\verb|  repeated string token = 4;| \\
	\verb|  repeated FloatArray token_weights = 5;| \\
	\verb|  optional DoubleArray scores = 6;|	
	
	\vspace{5pt}
	
	Первые два поля были описаны ранее и имеют тот же смысл. Третье содержит число обработанных на данный момент документов (учитываются все проходы по каждому документу, включая повторные). В четвёртом поле лежит словарь для данной модели. В пятом --- веса каждого термина, полученные в результате работы алгоритма (матрица $\Phi$). Последнее поле содержит значения счётчиков на данной итерации (в описываемом примере --- значение перплексии). Данную информацию можно извлекать после каждой итерации и использовать для оценивания качества обучения.
	
	Выгруженная после последней внешней итерации тематическая модель является финальным результатом работы алгоритма.
	
	\item В случае необходимости перенастройки \verb|master_component| или \verb|model| используется функция \verb|Reconfigure()|:
	
	\vspace{5pt}

	\verb|  master_component.Reconfigure(new_master_config)| \\
	\verb|  model.Reconfigure(new_model_config)| 
	        
	\vspace{5pt}
	
	\item После окончания работы модели удалять её не нужно. Все модели будут автоматически удалены при вызове деструктора \verb|MasterComponent|.В случае, когда необходимо прекратить счёт модели до завершения работы с библиотекой, можно деактивировать её вызовом:
	
	\vspace{5pt}

	\verb|  model.Disabled()| 
	        
	\vspace{5pt}
	
	Если нужно снова активировать --- описать вызов:	
	
	\vspace{5pt}

	\verb|  model.Enabled()| 
	        
	\vspace{5pt}	
	
\end{enumerate}

{\bf Замечание:} Базовых типов \verb'DoubleArray' и \verb'FloatArray' в protocol buffers нет, это пользовательские тип, эквивалентные вещественному массиву (работать с ними нужно по тем же правилам, что и остальными сообщениями --- через создаваемый protocol buffers интерфейс).

{\bf Замечание:} Все функции типа \verb|Reconfigure()| являются не до конца тестированными, поэтому должны использоваться с осторожностью.

{\bf Замечание:} Пример пользовательского приложения над BigARTM можно найти в файле \verb|BigARTM_ROOT_DIRECTORY\python_client|. Выдержки кода, указанные в вышеописанной инструкции, заимствованы оттуда.

\subsection{Планируемые нововведения}

$\quad\;\:$Ниже приведён список различных модификаций, которые появятся в release-версии библиотеки:

\begin{itemize}
	\item Кластерный параллелизм.
	\item Возможность работы в Linux.
	\item Интерфейсы на C++ и Java.
	\item Коллекция регуляризаторов.
	\item Поддержка 64-битной архитектуры.
	\item Усовершенствованный механизм хранения данных, необходимых для работы регуляризаторов.
	\item Коллекция функционалов качества.
	\item Хранение матриц $\Phi$ и $\Theta$ в разреженном виде.
	\item Возможность классификации новых документов построенной тематической моделью.
\end{itemize}

\subsection{Описание экспериментов}

В данном разделе будет рассмотрен модельный эксперимент с использованием регуляризаторов в BigARTM. Его задачей является демонстрация использования реализованного механизма регуляризаторов, от него не ожидается получения ответов на какие-либо исследовательские вопросы.

\subsubsection{Описание эксперимента} 
Производится обучение двух тематических моделей --- с регуляризатором и без. Для регуляризации модели используется регуляризатор сглаживания/разреживания. Параметры эксперимента следующие:

\begin{enumerate}
	\item Обучающая коллекция документов --- NIPS ($\approx$ 1600 документов).
	\item Объём словаря --- $\approx$ 13000 терминов.
	\item Число внешних итераций --- 12, внутренних --- 10.
	\item Число процессоров --- 2.
	\item Общее число тем --- 18, фоновых тем --- 3 (для модели без регуляризатора все темы равнозначны).
\end{enumerate} 

Регуляризация имеет следующую траекторию:
\begin{itemize}
	\item 1 --- 4 итерации: 
	\item 5 --- 8 итерации: 
	\item 9 --- 12 итерации:  
\end{itemize}
\marginpar{ToDO}

\subsubsection{Результаты эксперимента}

Сравнение качества моделей производилось по перплексии на обучающей выборке. Соответствующие графики построены на рис ... Из них видно, что регуляризация влияет на конечный результат. То, что это влияние не столь существенно --- вина неаккуратной настройки параметров модели и регуляризатора (они неоптимизированные, не учитывают текущего состояния модели). Кроме того, перплексия на обучающей выборке --- не лучший функционал качества. Существенно более важны такие параметры, как различность тем, разреженность матриц $\Phi$ и $\Theta$ (без учёта фоновых тем), объём ядер тем (т.е. слов, характеризующих данную тему). Регуляризация имеет перед собой задачу оптимизировать именно эти величины, не ухудшив при этом переплексию по сравнению с нерегуляризованной моделью.